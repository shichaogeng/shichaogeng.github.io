<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[zookeeper-分布式的关键]]></title>
    <url>%2F2017%2F10%2F24%2Fzookeeper-%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%85%B3%E9%94%AE%2F</url>
    <content type="text"><![CDATA[感觉这篇要写的太多了，没法写，不用看了，没什么价值 安装配置下载地址 下载1$ wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz 解压1234$ tar xvzf zookeeper-3.4.9.tar.gz$ mv ./zookeeper-3.4.9 /lab/dev/zookeeper$ cd /lab/dev/zookeeper$ ln -s zookeeper-3.4.9 zookeeper 修改配置文件配置文件位置：${ZOOKEEPER_HOME}/conf/zoo_sample.cfg 分布式配置dataDir指定当前服务器数据存放的路径(目录)clientPort 指定当前服务器服务器的端口server.1/server.2/server.3 指定服务器的集群情况（有几台服务器） myid必须手动建立且指定在zk数据目录，也就是dataDir指定的路径123$ echo 1 &gt;&gt; /lab/dev/zookeeper/zk1/myid$ echo 2 &gt;&gt; /lab/dev/zookeeper/zk2/myid$ echo 3 &gt;&gt; /lab/dev/zookeeper/zk3/myid 在{ZOOKEEPER_HOME}/conf下拷贝zoo_sample.cfg出三个配置文件zoo1.cfg zoo2.cfg zoo3.cfg zoo1.cfg配置123456789tickTime=2000initLimit=10syncLimit=5dataDir=/lab/dev/zookeeper/zk1(这个目录可以自行指定)clientPort=2181server.1=127.0.0.1(ip):2888(通讯端口):3888（选举端口）server.2=127.0.0.1127.0.0.1:2889:3889server.3=127.0.0.1:2890:3890 zoo2.cfg配置123456789tickTime=2000initLimit=10syncLimit=5dataDir=/lab/dev/zookeeper/zk2clientPort=2182server.1=127.0.0.1:2888:3888server.2=127.0.0.1:2889:3889server.3=127.0.0.1:2890:3890 zoo3.cfg配置123456789tickTime=2000initLimit=10syncLimit=5dataDir=/lab/dev/zookeeper/zk3clientPort=2183server.1=127.0.0.1:2888:3888server.2=127.0.0.1:2889:3889server.3=127.0.0.1:2890:3890 Zookeeper及其API的使用启动Zookeeper我把三个启动做成个脚本start.sh1234567ZOO_HOME=/lab/dev/zookeeper/zookeeper$ZOO_HOME/bin/zkServer.sh start $ZOO_HOME/conf/zoo1.cfg$ZOO_HOME/bin/zkServer.sh start $ZOO_HOME/conf/zoo2.cfg$ZOO_HOME/bin/zkServer.sh start $ZOO_HOME/conf/zoo3.cfg# 运行start.shsh start.sh 停止Zookeeper三个停止也做成脚本stop.sh123456$ zkServer.sh stop /usr/local/zookeeper-3.4.6/conf/zoo1.cfg$ zkServer.sh stop /usr/local/zookeeper-3.4.6/conf/zoo2.cfg$ zkServer.sh stop /usr/local/zookeeper-3.4.6/conf/zoo3.cfg# 运行脚本sh stop.sh 查看zookeeper状态查看状态脚本12345678ZOO_HOME=/lab/dev/zookeeper/zookeeper$ZOO_HOME/bin/zkServer.sh status $ZOO_HOME/conf/zoo"$1".cfg# 查看zk2的运行状态,它是leader$ sh status.sh 2ZooKeeper JMX enabled by defaultUsing config: /lab/dev/zookeeper/zookeeper/conf/zoo2.cfgMode: leader ZK SHELL使用zkCli.sh [-server ip:port]进入命令行shell 进入之后可以用help命令查看帮助信息，并选择你要使用的命令1234567891011121314151617181920212223[zk: localhost:2181(CONNECTED) 1] helpZooKeeper -server host:port cmd args stat path [watch] set path data [version] ls path [watch] delquota [-n|-b] path ls2 path [watch] setAcl path acl setquota -n|-b val path history redo cmdno printwatches on|off delete path [version] sync path listquota path rmr path get path [watch] create [-s] [-e] path data acl addauth scheme auth quit getAcl path close connect host:port Zookeeper使用–命令行 ephemeralOwner = 0x15f4d0ecaf60002判断是否临时节点 setquota -n|-b val path 某个Znode指定多少存储空间或者允许创建多少个节点n 指定可以设置多少个子节点b 指定可以设置多大空间（byte） listquota path对于配额不是硬性的提示，超过配额还是可以继续创建，只不过在日志里面有提示 错误日志122017-10-24 16:33:08,151 [myid:1] - WARN [CommitProcessor:1:DataTree@301] - Quota exceeded: /zk-123 count=6 limit=52017-10-24 16:33:13,958 [myid:1] - WARN [CommitProcessor:1:DataTree@301] - Quota exceeded: /zk-123 count=7 limit=5 stat path查看节点的状态]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试问题整理]]></title>
    <url>%2F2017%2F10%2F23%2F%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[对一些常见的面试题的总结 数据结构&amp;算法JAVA开发中常用的数据结构有哪些？快速排序 广度优先搜索（队列实现） 谈谈对HashMap的理解，底层的基本实现。HashMap怎么解决碰撞问题的？数据结构是线程安全的吗？加入你回答HashMap不是线程安全的，HashTabl是线程安全的，有没有线程安全的Map，concurrent包concurrentmap的机制 treemap JVM对JVM熟不熟悉？简单说说类加载过程，里面执行的哪些操作？问了GC和内存管理，平时在tomcat里面有没有进行过相关配置JVM内存模型JVM新生代和老年代的比例YFC和FGC的具体场景jstack，jmap，jutil分别的意义，如何排查线上相关问题 通信协议http协议 get和post区别 tcp/ip协议 三次握手 窗口滑动机制 接口如何处理重复请求，具体的处理方案是什么。如何保障请求执行顺序设计一个对外接口实现类，在三个主机ip上实现轮循和负载均衡（考虑并发） 数据库开发中用了哪些数据库？mysql存储引擎有哪些？悲观锁和乐观锁问题使用场景、分布式集群实现原理数据库垂直和水平拆分 redis基本存储类型 事物 使用场景 框架spring和mybatis实现原理 底层源码Mybatis如何分页；如何设置缓存；Mysql分页执行某操作，前50次成功，51次失败，a全回滚b前50次提交51次抛出异常 ab场景如何设置spring传播行为 分布式Dubbo超时重试 超时时间设置dubbo的底层原理，zookeeper是什么zookeeper作用分布式事物和分布式锁（扣款不要出现负数）分布式session设置分布式session一致性分布式接口的幂等设计[不能重复扣款] 业务最近做的比较熟悉的项目技术架构图 并发如何设置线程池的大小123cpu核数 内存大小 cpu密集型还是io密集型 有没有其他的资源限制 比如说数据库连接池 任务是同构还是异构 是独立的还是相互依赖的计算越密集 线程数设的越小 io越密集 为了防止线程在阻塞时cpu空闲造成资源的浪费 应加大线程池数量 让cpu忙碌起来 线程池的构造类的五个参数的具体意义是什么？1234567corePoolSize 线程池的线程数量maximumPoolSize 允许的最大线程数keepAliveTime 超过coreSize的线程空闲的最大时间unit 时间单位workQueue 工作队列初始化无限程，然后创建线程直到线程池满，然后放入工作队列，工作队列满，然后创建线程直到最大线程数，线程闲置超时即销毁直到核心线程数。 单机上一个线程池突然断电的处理机制（正在处理的请求和阻塞队列里的请求如何处理）12shutdown方法，平滑的关闭，不再接受新的任务，同时等待提交任务完成。shutdownNow方法，粗暴的关闭，尝试取消实行的任务，并不再启动未开始执行的任务。返回等待执行的任务。 栅栏机制1所有线程必须到达栅栏的位置才能继续执行，等待其他线程到达之前一直阻塞。 使用无界阻塞队列会出现什么问题1newFixedThreadPool 使用的是无界LinkedBlokingQueue 如果任务到达速率高于处理速度,那么工作队列会无限制的增减,最终导致内存耗尽 有界队列1234567在使用有界队列时,可以解决资源耗尽的问题,然而,队列满了之后如何处理就要看[饱和策略了].而且,使用有界队列时,线程池大小要与队列大小一同调节,如果线程池小而队列大,那么可以节省内存,降低cpu的使用率,减少上下文切换,但是也限制了服务器的吞吐量newCachedThreadPool使用Synchrnous Queue作为工作队列 synchrnous不是一个真正的队列,他用于把一个任务从一个线程移交到另外一个线程.synchrnous比LinkedBlokingQueue有更好的性能 设置有界的队列不适合相互依赖的任务,会导致线程"饥饿"死锁问题另一种解决方式是用Synchrnous Queue有界队列,并使用caller-runs饱和策略(不懂) 如何保证共享变量修改时的原子性1synchronized lock volatile1234567891011121314151617181. 先介绍JMM 主内存 各个线程的工作内存2. 然后是原子性 可见性(把修改立即刷新到主内存) 有序性(指令重排 为何提高工作效率 单线程无问题 但多线程并发容易产生问题）3. volatile语义：（1）可见性线程修改之后更新到主内存线程修改之后其他线程缓存无效 CPU L1 &amp; L2（2）禁止指令重排（3）不保证原子性4.原理JVM会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写会到系统内存5.应用状态标识double check为什么要使用volatile 修饰instance？主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情:1.给 instance 分配内存2.调用 Singleton 的构造函数来初始化成员变量3.将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了）。但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。 atomic是利用CAS来实现原子性操作的（Compare And Swap） Locksynchronized无法中断一个等待锁的线程。lock要在finally中主动释放锁。 同步工具类信号量SemaphoreSemaphore用来控制某个特定资源的数量。 Semaphore管理这一批管理许可，由构造函数来指定。执行操作之前可以获得许可，使用之后释放许可。acquire讲阻塞直到有许可，release方法将返回一个许可。 使用Semaphore为容器设置边界，可以将容器变成有界阻塞队列。12345678910111213141516171819202122232425262728293031323334353637383940package com.gsc.tools;import java.util.Collections;import java.util.HashSet;import java.util.Set;import java.util.concurrent.Semaphore;public class BoundedHashSet&lt;T&gt; &#123; private final Set&lt;T&gt; set; private final Semphore sem; public BoundedHashSet(int bound) &#123; this.set = Collections.synchronizedSet(new HashSet&lt;T&gt;()); this.sem = new Semaphore(bound); &#125; public boolean add(E e) throws InterruptedException &#123; sem.acquire(); boolean wasAdded = false; try &#123; wasAdded =set.add(e); return wasAdded; &#125; finally &#123; if (!wasAdded) &#123; sem.release(); &#125; &#125; &#125; public boolean remove(Object o) &#123; boolean wasRemoved = set.remove(o); if (wasRemoved) &#123; sem.release(); &#125; return wasRemoved; &#125;&#125; 栅栏Barrier栅栏CyclicBarrier 闭锁LatchCountDownLatchLockCountDownLatchLock是一种灵活的闭锁实现，可以使一个或多个线程等待一组事物完成。维护一个计数器，初始化一个整数表示事物的数量，countDown事物完成减1，await阻塞等待直到计数器归零。12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.gsc.tools;import java.util.concurrent.CountDownLatch;/** * 闭锁CountDownLatch * 计算并发执行某个任务所需时间 * * @author shichaogeng * * 2017年9月27日 */public class TestHarness &#123; public long TimeTask(int nThread, final Runnable task) throws InterruptedException &#123; final CountDownLatch startGate = new CountDownLatch(1); final CountDownLatch endGate = new CountDownLatch(nThread); for (int i = 0; i &lt; nThread; i++) &#123; new Thread()&#123; public void run() &#123; try &#123; //线程阻塞等待所有线程准备完成 startGate.await(); try &#123; task.run(); &#125; finally &#123; //表示当前线程执行结束 endGate.countDown(); &#125; &#125; catch (InterruptedException e) &#123;&#125; &#125;; &#125;.start(); &#125; long start = System.nanoTime(); //准备完成，开始所有线程，await阻塞消失 startGate.countDown(); //等待所有线程释放完毕 endGate.await(); long end = System.nanoTime(); return end -start; &#125;&#125; FutureTask#get()FutureTask听过callable来实现，get()方法会阻塞直到任务走到完成状态，就获取callable的结果。参见Java Concurrency in Practise page 80。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA使用简记]]></title>
    <url>%2F2017%2F10%2F19%2FIntelliJ-IDEA%E4%BD%BF%E7%94%A8%E7%AE%80%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[感觉IntelliJ IDEA现在比较流行的开发ide，同事大部分也使用这个，只有我用eclipse有点low，打算学习下，把常用的配置记录下，把常用配置放到github上，以后直接使用就可以了。 下载地址 破解：（切换license server 然后输入网址：http://idea.iteblog.com/key.php即可） JVM配置文件idea64.exe.vmoptions是 64 位可执行文件的 JVM 配置文件内容 使用 IDEA 自带菜单中的 Help -&gt; Edit Custom VM Options 来进行个性化配置，而不是直接修改安装目录中的该文件！ -Xms128m，16 G 内存的机器可尝试设置为 -Xms512m -Xmx750m，16 G 内存的机器可尝试设置为 -Xmx1500m -XX:MaxPermSize=350m，16G内存的机器可尝试设置为-XX:MaxPermSize=500m -XX:ReservedCodeCacheSize=225m，16G内存的机器可尝试设置为-XX:ReservedCodeCacheSize=500m 属性配置文件idea.properties是 IntelliJ IDEA 一些属性配置，修改原则主要根据个人对 IntelliJ IDEA 的个性化配置情况来分析。 在阅读了安装目录中的带注释的配置文件后，使用 IDEA 自带菜单中的 Help -&gt; Edit Custom Properties 来进行个性化配置！常修改的就是下面 4 个参数： idea.config.path=${user.home}/.IntelliJIdea/config，该属性主要用于指向 IntelliJ IDEA 的个性化配置目录，默认是被注释，打开注释之后才算启用该属性，这里需要特别注意的是斜杠方向，这里用的是正斜杠。 idea.system.path=${user.home}/.IntelliJIdea/system，该属性主要用于指向 IntelliJ IDEA 的系统文件目录，默认是被注释，打开注释之后才算启用该属性，这里需要特别注意的是斜杠方向，这里用的是正斜杠。如果你的项目很多，则该目录会很大，如果你的 C 盘空间不够的时候，还是建议把该目录转移到其他盘符下。 idea.max.intellisense.filesize=2500，该属性主要用于提高在编辑大文件时候的代码帮助。IntelliJ IDEA 在编辑大文件的时候还是很容易卡顿的。 idea.cycle.buffer.size=1024，该属性主要用于控制控制台输出缓存。有遇到一些项目开启很多输出，控制台很快就被刷满了没办法再自动输出后面内容，这种项目建议增大该值或是直接禁用掉，禁用语句 idea.cycle.buffer.size=disabled。 必要配置ToolBarView-&gt;ToolBar/Tool Buttons EncodingFile-&gt;Setting-&gt;Editor-&gt;File Encoding设置Project Encoding别忘了下面的properties Encoding 并勾选后面的选项（能查看中文） Compiler Heap SizeFile-&gt;Setting-&gt;Build-&gt;Compiler设置Compiler heap大小 JDKFile-&gt;Project Structure-&gt;Platform Settings-&gt;SDKs 包层级设置点击右上角齿轮，在弹出的菜单中去掉选项：Compact Empty Middle Packages GitFile-&gt;Setting-&gt;Version Control-&gt;Git确定系统已安装git并git路径正确。 教程IntelliJ IDEA 简体中文专题教程]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git]]></title>
    <url>%2F2017%2F10%2F17%2Fgit%2F</url>
    <content type="text"><![CDATA[git 通过使用基于 P2P 网络的源码库，使得多人维护数字化工作变得可能。git 支持分布式工作流，允许一部分工作被分发出去，或是合并回来。 git安装git 我yum安装时报错，然后就百度一番，也记录下吧。 123456# 错误Not using downloaded repomd.xml because it is older than what we have# 解决（清空缓存）yum clean allyum makecache 安装 1234567yum -y install git# 测试git --version# 查看帮助git --help 查看帮助所有的命令都可以通过帮助查到 查看全局帮助1git --help 注意最下面这句话123'git help -a' and 'git help -g' lists available subcommands and someconcept guides. See 'git help &lt;command&gt;' or 'git help &lt;concept&gt;'to read about a specific subcommand or concept. 意思是可以通过如下命令来查看命令具体配置1git help &lt;command&gt; 查看git配置帮助1git config 比如配置用户名邮箱12git config --global user.name shichaogenggit config --global user.email shichaogeng@gmail.com Git一些概念git init命令同时会创建 .git 子目录：1234567891011121314151617181920212223.git/|-- HEAD|-- config|-- description|-- hooks| |-- applypatch-msg.sample| |-- commit-msg.sample| |-- post-commit.sample| |-- post-receive.sample| |-- post-update.sample| |-- pre-applypatch.sample| |-- pre-commit.sample| |-- pre-rebase.sample| |-- prepare-commit-msg.sample| |-- update.sample|-- info| |-- exclude|-- objects| |-- info| |-- pack|-- refs |-- heads |-- tags .git 包含以下文件和目录： 配置：.git/config, .git/description, .git/info/exclude 用来配置本地代码库 钩子：.git/hooks 包含在代码库各个周期时会被执行的脚本 临时区域：.git/index 提供当前工作目录的临时区 对象数据库：.git/objects 是默认的git对象数据库，它包含本地内容或指向本地内容的指针。这些对象均为只读 引用：.git/refs 用来存储本地/远程的分支，标签，以及 head 的引用。引用是指向对象的指针，一般为 tag 或 commit .git 是实际的代码库。而保存当前文件的目录被称为 工作目录。 使用 git init --bare 创建不包含工作目录的代码库。 .git/index 是另一个重要的文件：它提供了一个当前工作目录和当前代码库之间的缓冲区，用来存储当前未提交的一个或多个文件。 git checkout [branch] 把 HEAD 引用移到指定分支，然后通过索引文件见当前工作目录中的文件恢复至该分支的状态。 git add [files] 会交叉引用索引文件中的校验和来检查当前未提交文件是否需要更新工作目录的版本，git 目录不受影响。 git工作区域图 从图中可以看出，所有操作都保存在缓存区中，commit之后才保存修改到版本库。其中head是游标，表示当前的分支是master（指向当前分支的最新提交点，所谓的提交点就是时间为主线，每次提交都是一次提交点）。 Git 创建仓库1git init Git 使用 git init 命令来初始化一个 Git 仓库，Git 的很多命令都需要在 Git 的仓库中运行，所以 git init 是使用 Git 的第一个命令。 在执行完成 git init 命令后，Git 仓库会生成一个 .git 目录，该目录包含了资源的所有元数据，其他的项目目录保持不变（不像 SVN 会在每个子目录生成 .svn 目录，Git 只在仓库的根目录生成 .git 目录）。 使用当前目录作为Git仓库，我们只需使它初始化。 常用命令把文件添加到缓存区12# filename为 . 表示把工作区中所有文件加入缓存区git add filename 查看版本状态信息，可以看现工作区中文件的状态1234567891011121314[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git status# On branch master## Initial commit## Changes to be committed:# (use "git rm --cached &lt;file&gt;..." to unstage)## new file: start.sh## Untracked files:# (use "git add &lt;file&gt;..." to include in what will be committed)## vip 加入参数-s获得精简的信息123[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git status -sA start.sh?? vip 版本提交，提交到版本库(某种程度上相当于git add和git commit -m的组合技，前提是被改动文件已经是tracked)1234git commit –m &lt;message&gt;# 加入缓存区并提交git commit –am &lt;message&gt; git diff命令 比较工作区和缓存区差异1git diff 比较缓存区和版本库（HEAD）之间的差异1git diff --cached 比较工作区和版本库（HEAD）的差别1git diff HEAD -- &lt;filename&gt; 比较两个版本号码的src 文件夹的差异1git diff 版本号码1 版本号码2 版本克隆123git clone &lt;repo&gt; &lt;directory&gt;git clone https://github.com/alibaba/dubbo.git dubbogit clone git@github.com:shichaogeng/gitskills.git 其中，git开头的表示使用的是git协议，https当然使用的是https协议。 命令用于取消已缓存的内容1git reset HEAD 分支管理几乎每一种版本控制系统都以某种形式支持分支。使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。 创建分支命令(创建分支会复制当前提交点)1git branch (branchname) 查看分支1234[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git branch jack* master# 上面的*代表当前所在分支 切换分支命令1git checkout (branchname) 删除分支1git branch -d (branchname) 合并分支命令12345678910# 如果a分支要合并b分支，首先切换到a分支git checkout master# 查看当前分支git branch jack* master# 合并jack分支git merge jack 合并的内容不需要提交，直接合并进来。 如果合并时遇到冲突，比如像下面这样1234[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git merge jackAuto-merging vipCONFLICT (content): Merge conflict in vipAutomatic merge failed; fix conflicts and then commit the result. 编辑冲突文件，解决冲突，然后提交到版本库1git commit -am 'conflict resolved' 关于另一种命令git rebase,网上找到博客 git rebase简介(基本篇) Git提交历史查看提交历史1git log 查看提交历史简单版本（一行展示）1git log –oneline 查看分支情况，–graph图形表示，可以看到当前哪里创建的节点，以及节点的提交合并情况123456789[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git log --oneline --graph* 3d6c89d conflict resolved|\ | * aeb2e8d jack-conflict* | 8bbe83f master-conflict|/ * 909958a jack commit 1* a0af866 brach jack* 40d8ffb first commit Git 标签如果你达到一个重要的阶段，并希望永远记住那个特别的提交快照，你可以使用 git tag 给它打上标签。某个时刻的提交点有特殊的意义，可以在分支打上标签。 首先决定在哪个提交点打标签1234567[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git log --oneline3d6c89d conflict resolvedaeb2e8d jack-conflict8bbe83f master-conflict909958a jack commit 1a0af866 brach jack40d8ffb first commit 我选择在倒数第二个提交点打标签1git tag -a v1.0 a0af866 查看tag1git log --decorate 在当前提交点打标签1git tag -a v0.9 Git回退命令12[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git reset --hard 40d8ffbHEAD is now at 40d8ffb first commit 回退的原理：HEAD的指针指向id所在的提交点。 也可以使用git reset --hard HARD|HARD^|HARD酱紫的命令，其中HARD代表当前提交点，HARD^代表上一个提交点，HARD^^代表上两个提交点，HARD~100代表100个以前的这种，额 这时候还是用commit id比较好。 查看历史123456[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git logcommit 40d8ffbc45c8b37c260b67a6c728cfb37a60da34Author: shichaogeng &lt;shichaogeng@gmail.com&gt;Date: Tue Oct 17 15:43:45 2017 +0800 first commit 发现回退点以后的log都消失了。表示回退提交点以后的记录都删除了。如果发现删除错误了，需要恢复，这个时候就要使用git reflog1234567891011121314151617181920git reflog40d8ffb HEAD@&#123;0&#125;: reset: moving to 40d8ffb3d6c89d HEAD@&#123;1&#125;: reset: moving to 3d6c89d40d8ffb HEAD@&#123;2&#125;: reset: moving to 40d8ffb3d6c89d HEAD@&#123;3&#125;: checkout: moving from jack to masteraeb2e8d HEAD@&#123;4&#125;: checkout: moving from master to jack3d6c89d HEAD@&#123;5&#125;: commit (merge): conflict resolved8bbe83f HEAD@&#123;6&#125;: checkout: moving from jack to masteraeb2e8d HEAD@&#123;7&#125;: commit: jack-conflict909958a HEAD@&#123;8&#125;: checkout: moving from master to jack8bbe83f HEAD@&#123;9&#125;: commit: master-conflict909958a HEAD@&#123;10&#125;: checkout: moving from master to master909958a HEAD@&#123;11&#125;: merge jack: Fast-forward40d8ffb HEAD@&#123;12&#125;: checkout: moving from jack to master909958a HEAD@&#123;13&#125;: commit: jack commit 1a0af866 HEAD@&#123;14&#125;: checkout: moving from master to jack40d8ffb HEAD@&#123;15&#125;: checkout: moving from jack to mastera0af866 HEAD@&#123;16&#125;: commit: brach jack40d8ffb HEAD@&#123;17&#125;: checkout: moving from master to jack40d8ffb HEAD@&#123;18&#125;: commit (initial): first commit reflog显示整个本地仓储的commit, 包括所有branch的commit, 甚至包括已经撤销的commit, 只要HEAD发生了变化, 就会在reflog里面看得到. git log只包括当前分支的commit. 然后可以再使用git reset回退到已被删除的提交点12[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git reset --hard 3d6c89dHEAD is now at 3d6c89d conflict resolved 查看log，发现已经恢复1234567[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git log --oneline3d6c89d conflict resolvedaeb2e8d jack-conflict8bbe83f master-conflict909958a jack commit 1a0af866 brach jack40d8ffb first commit github用户配置我要用github上的项目做测试，配置github用户名密码12git config --global user.name shichaogenggit config --global user.email shichaogeng@gmail.com 配置秘钥 git在部署github时使用SSH协议连接和验证远程服务器和服务。为避免暴露账户密码，最好使用证书认证。使用SSH密钥，可以连接到GitHub，而无需在每次访问时提供用户名或密码。 查看密匙执行cd ~/.ssh命令，如果存在该目录，表明之前生成果SSH Key，利用ll命令即可以查看。123[root@iZ2zehu64p5eabr7fp9t0iZ .ssh]# lltotal 0-rw------- 1 root root 0 Sep 15 13:20 authorized_keys 看一下有没有id_rsa和id_rsa.pub(或者是id_dsa和id_dsa.pub之类成对的文件)，有.pub 后缀的文件就是公钥，另一个文件则是密钥。 假如没有这些文件，甚至连.ssh 目录都没有，可以用 ssh-keygen 来创建。该程序在 Linux/Mac 系统上由 SSH 包提供，而在 Windows 上则包含在 MSysGit 包里。 生成私钥12345678910111213141516171819202122[root@iZ2zehu64p5eabr7fp9t0iZ .ssh]# ssh-keygen -t rsa -C "shichaogeng@gmail.com"Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:4f:e4:71:c2:89:92:03:80:41:1c:c2:11:cc:06:ff:ea shichaogeng@gmail.comThe key's randomart image is:+--[ RSA 2048]----+|@B=.. ||oB . . o . ||. . + . * . || . o o + || . S o || . o || . . || . || E |+-----------------+# 本地密匙生成成功！ 查看生成的公钥1ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7+EsE7t+TmI9AA16QQMNnwB3fbogZGznD18jttNvANvkYITlNnty2a/qiFdVuaSvPHbwW5djKT8fwVpieJStlefEsdAXg+r7DPgyttFf2vHYdHULdZNc48aNy/GN1hZFvPU1PwsV/xAL8phFER4aFhQYygcnkY1/KbfSZOHo+9uL+oc7bBQZYTEhfdl+twwesnAt3erSPIl1U0Cv5tkCdj2WRnLGiLXdnUfK7Zq5jtfQiXWeXCXjt3+wB0zWS1W6HysQ4pJ5f7OuuzG8sHj44KTYqSf5hSHuGVXX5P7x9OiKT4zDyZ/rBsGJAehyxDRd3ErAP2D4IY1zmpzgEBkgx shichaogeng@gmail.com github公钥登陆github帐户。点击头像，然后 Settings -&gt; 左栏点击 SSH and GPG keys -&gt; 点击 New SSH key，向下面酱紫的界面 然后你复制上面的公钥内容，粘贴进“Key”文本域内。 title域，自己随便起个名字。点击 Add key。 完成以后，验证下这个key是不是正常工作123456[root@iZ2zehu64p5eabr7fp9t0iZ .ssh]# ssh -T git@github.comThe authenticity of host 'github.com (192.30.255.112)' can't be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added 'github.com,192.30.255.112' (RSA) to the list of known hosts.Hi shichaogeng! You've successfully authenticated, but GitHub does not provide shell access. 搞定！ 远程操作在github上创建项目，之后 会看到如下帮助信息 …or create a new repository on the command line1234567echo "# gitvip" &gt;&gt; README.mdgit initgit add README.mdgit commit -m "first commit"# 添加远程库git remote add origin https://github.com/shichaogeng/gitvip.gitgit push -u origin master …or push an existing repository from the command line12git remote add origin https://github.com/shichaogeng/gitvip.gitgit push -u origin master 可以查看远程连接信息123[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git remote -vorigin https://github.com/shichaogeng/gitvip.git (fetch)`origin https://github.com/shichaogeng/gitvip.git (push)` 其中，fetch和push都是https://github.com/shichaogeng/gitvip.git Git中从远程的分支获取最新的版本到本地有这样2个命令git fetch,git pull git fetch：相当于是从远程获取最新版本到本地，不会自动merge123git fetch origin mastergit log -p master..origin/mastergit merge origin/master 以上命令的含义： 首先从远程的origin的master主分支下载最新的版本到origin/master分支上然后比较本地的master分支和origin/master分支的差别最后进行合并 上述过程其实可以用以下更清晰的方式来进行123git fetch origin master:tmpgit diff tmp git merge tmp 从远程获取最新的版本到本地的test分支上，之后再进行比较合并 git pull：相当于是从远程获取最新版本并merge到本地1git pull origin master 上述命令其实相当于git fetch 和 git merge在实际使用中，git fetch更安全一些因为在merge前，我们可以查看更新情况，然后再决定是否合并结束 看这里写完之后，发现一个超有用的教程，写的超好，感觉自己白写了，又把他的教程又刷了一遍 Git教程]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis需要注意的点]]></title>
    <url>%2F2017%2F10%2F11%2FRedis%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E7%82%B9%2F</url>
    <content type="text"><![CDATA[关于redis使用中需要注意的地方，记录下。 API命令查看键总数127.0.0.1:6379&gt; keys *1) “name” 12127.0.0.1:6379&gt; dbsize(integer) 1 dbsize命令在计算键总数时不会遍历所有键，而是直接获取Redis内置的键总数变量，所以dbsize命令的时间复杂度是O（1）。 而keys命令会遍历所有键，所以它的时间复杂度是O（n），当Redis保存了大量键时，线上环境禁止使用。 查询数据结构内部编码12127.0.0.1:6379&gt; object encoding name&quot;embstr 单线程模型因为Redis是单线程来处理命令的，所以一条命令从客户端达到服务端不会立刻被执行，所有命令都会进入一个队列中，然后逐个被执行。 为什么单线程还能这么快 纯内存访问，Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，这是Redis达到每秒万级别访问的重要基础。 非阻塞I/O，Redis使用epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间。 单线程避免了线程切换和竞态产生的消耗。单线程能带来几个好处：第一，单线程可以简化数据结构和算法的实现。如果对高级编程语言熟悉的读者应该了解并发数据结构实现不但困难而且开发测试比较麻烦。第二，单线程避免了线程切换和竞态产生的消耗，对于服务端开发来说，锁和线程切换通常是性能杀手。 字符串最大512M mget命令假如没有mget这样的命令，要执行n次get命令1n次get时间 = n次网络时间 + n次命令时间 使用mget命令后，要执行n次get命令1n次get时间 = 1次网络时间 + n次命令时间 1000次get命令，网络耗时1ms，执行命令0.1ms,1000次get和一次met对比 使用批量操作，有助于提高业务处理效率，但是要注意的是每次批量操作所发送的命令数不是无节制的，如果数量过多可能造成Redis阻塞或者网络拥塞。 SETNX1234127.0.0.1:6379&gt; set company go+OK127.0.0.1:6379&gt; setnx company go+(integer) 0 因为键hello已存在，所以setnx失败，返回结果为0 由于Redis的单线程命令处理机制，如果有多个客户端同时执行setnx key value，根据setnx的特性只有一个客户端能设置成功，setnx可以作为分布式锁的一种实现方案，Redis官方给出了使用setnx实现分布式锁的方法：http://redis.io/topics/distlock。 redis数据迁移]]></content>
      <categories>
        <category>no-</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven小总结]]></title>
    <url>%2F2017%2F09%2F29%2FMaven%E5%B0%8F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[maven是项目管理工具，用的也比较熟练了，但是还是有记不到的和常用的不了解的内容，在这里记录下。 单元测试构建项目打包上传时经常需要跳过测试，如果确定项目没有问题（你要确定哦），因为测试需要跑你的每个测试方法，非常耗时间，而且方法写错了，还要报错等等…… maven-surefire-plugin简介Maven本身并不是一个单元测试框架，它只是在构建执行到特定生命周期阶段的时候，通过插件来执行JUnit或者TestNG的测试用例。这个插件就是maven-surefire-plugin，也可以称为测试运行器(Test Runner)，它能兼容JUnit 3、JUnit 4以及TestNG。 在默认情况下，maven-surefire-plugin的test目标会自动执行测试源码路径（默认为src/test/java/）下所有符合一组命名模式的测试类。这组模式为： 123**/Test*.java：任何子目录下所有命名以Test开关的Java类。**/*Test.java：任何子目录下所有命名以Test结尾的Java类。**/*TestCase.java：任何子目录下所有命名以TestCase结尾的Java类。 跳过测试命令可以才命令行中mvn输入，也可以在eclipse的右键-run-maven build..-Goals中输入 命令行中1mvn package -DskipTests eclipse中（我用的是eclipse）1package -DskipTests 也可以酱紫，不过我都用上面的1mvn package -Dmaven.test.skip=true 也可以配置插件 pom配置插件跳过测试在pom文件中加入如下配置12345678&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.18.1&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;/configuration&gt;&lt;/plugin&gt; 动态指定要运行的测试用例maven-surefire-plugin提供了一个test参数让Maven用户能够在命令行指定要运行的测试用例。如：1mvn test -Dtest=RandomGeneratorTest 也可以使用通配符：1mvn test -Dtest=Random*Test 或者也可以使用“，”号指定多个测试类：1mvn test -Dtest=Random*Test,AccountCaptchaServiceTest 包含与排除测试用例在pom文件中配置要包含和排除的测试用例1234567891011121314&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.18.1&lt;/version&gt; &lt;configuration&gt; &lt;includes&gt; &lt;include&gt;**/*Tests.java&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;**/*ServiceTest.java&lt;/exclude&gt; &lt;exclude&gt;**/TempDaoTest.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt;&lt;/plugin&gt; 生成测试报告默认情况下，maven-surefire-plugin会在项目的target/surefire-reports目录下生成两种格式的错误报告。 简单文本格式——内容十分简单，可以看出哪个测试项出错。 与JUnit兼容的XML格式——XML格式已经成为了Java单元测试报告的事实标准，这个文件可以用其他的工具如IDE来查看。 maven-model-builder插件仓库配置大家都应该明白依赖的查找路径：本地仓库–&gt;远程仓库 但是，插件的依赖有所不同，插件依赖的查找路径：本地仓库–&gt;插件远程仓库 Maven的父POM中也是有内置一个插件仓库的，我现在用的电脑安装的是Maven 3.1.1版本，我们可以找到这个文件：${M2_HOME}/lib/maven-model-builder-3.1.1.jar，打开该文件，能找到超级父POM：\org\apache\maven\model\pom-4.0.0.xml，它是所有Maven POM的父POM，所有Maven项目都继承该配置。 我们来看看默认的远程插件仓库配置的是啥：1234567891011121314&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;http://repo.maven.apache.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; 默认插件仓库的地址就是中央仓库咯，它关闭了对snapshots的支持，防止引入snapshots版本的插件而导致不稳定的构件。一般来说，中央仓库所包含的插件完全能够满足我们的需要，只有在少数情况下才要配置，比如项目的插件无法在中央仓库找到，或者自己编写了插件才会配置自己的远程插件仓库。 这个文件中还有一些其他的配置，自己看吧 依赖的范围和传递性关于依赖范围和传递依赖果然还是不理解，用时候百度吧。 比如这样的： compile：编译依赖范围（默认），使用此依赖范围对于编译、测试、运行三种 classpath 都有效，即在编译、测试和运行的时候都要使用该依赖jar包； 啥叫三种classpath啊，不懂不懂不懂 还有依赖的传递，有时候传递有时候不传递，有个表格，就不贴了，自己查吧。 pom的一些标签relativePath&lt;relativePath&gt;: 表示父模块POM的相对路径，在构建的时候，Maven会先根据relativePath检查父POM，如果找不到，再从本地仓库查找 relativePath的默认值： ../pom.xml finalName打包的时候，打包的名称 查看maven-model-builder.jar的pom文件可以看到（这个是超级父工程）下面的标签1&lt;finalName&gt;$&#123;project.artifactId&#125;-$&#123;project.version&#125;&lt;/finalName&gt; 工程是这样的12345678&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;maven-test&lt;/artifactId&gt; &lt;parent&gt;&lt;groupId&gt;com.gengsc.practise&lt;/groupId&gt;&lt;artifactId&gt;maven-test-parent&lt;/artifactId&gt;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 打包之后的jar包就是这样的(默认jar包)1maven-test-0.0.1-SNAPSHOT.jar 现在添加finalName标签，也就是覆盖了父pom文件1&lt;finalName&gt;maven-test&lt;/finalName&gt; 再次打包，jar文件变成酱紫1maven-test.jar 依赖树查看pom文件呢的依赖树可以在eclipse的pom文件中打开Dependency Hierarchy。像酱紫 也可用命令查看1mvn dependency:tree 也可导出到文件中分析1mvn dependency:tree -Doutput=db.txt 常用骨架我平时都直接选Create a simple project(skip archetype selection)，没选骨架，记下最常用的两个吧 maven-archetype-quickstart 打jar包 maven-archetype-webapp 打war包 配置阿里云镜像12345678910111213&lt;!--配置阿里云国内镜像 --&gt;&lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt;&lt;mirror&gt; &lt;id&gt;central&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;url&gt;http://repo1.maven.org/maven2/&lt;/url&gt;&lt;/mirror&gt; 配置文件动态切换pom build节点下面添加resource配置：123456789101112131415161718&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;!-- 设置对auto-config.properties，jdbc.properties进行过虑，即这些文件中的$&#123;key&#125;会被替换掉为真正的值 --&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;jdbc.properties&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt;&lt;/resources&gt; resource的filtering属性用来表示资源文件中的占位符是否需要被替换，true为需要替换。上面的定义是jdbc.properties文件中的EL表达式占位符都会在打包时动态替换，所有的其他文件则不会替换占位符。 接下来我们配置三个profile,一个是测试环境，一个开发环境，一个是正式环境配置：12345678910111213141516171819202122232425262728293031323334353637383940&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;test&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;jdbc.driver&gt;test.mysql&lt;/jdbc.driver&gt; &lt;jdbc.url&gt;test.url&lt;/jdbc.url&gt; &lt;jdbc.username&gt;test.username&lt;/jdbc.username&gt; &lt;jdbc.password&gt;test.password&lt;/jdbc.password&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;jdbc.driver&gt;dev.mysql&lt;/jdbc.driver&gt; &lt;jdbc.url&gt;dev.url&lt;/jdbc.url&gt; &lt;jdbc.username&gt;dev.username&lt;/jdbc.username&gt; &lt;jdbc.password&gt;dev.password&lt;/jdbc.password&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;product&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;jdbc.driver&gt;product.mysql&lt;/jdbc.driver&gt; &lt;jdbc.url&gt;product.url&lt;/jdbc.url&gt; &lt;jdbc.username&gt;product.username&lt;/jdbc.username&gt; &lt;jdbc.password&gt;product.password&lt;/jdbc.password&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 我们再在src/main/resources目录下面创建一个jdbc.properties文件，内容如下：1234jdbc.driver = $&#123;jdbc.driver&#125;jdbc.url = $&#123;jdbc.url&#125;jdbc.username = $&#123;jdbc.username&#125;jdbc.password = $&#123;jdbc.password&#125; 然后我们执行maven打包命令：clean package -DskipTests -Pdev 查看对应的jar包里面的jdbc.properties文件，可以发现占位符已经被替换成了profile dev中配置的值了。 私服Nexus 是Maven仓库管理器，如果你使用Maven，你可以从Maven中央仓库 下载所需要的构件（artifact），但这通常不是一个好的做法，你应该在本地架设一个Maven仓库服务器，在代理远程仓库的同时维护本地仓库，以节省带宽和时间，Nexus就可以满足这样的需要。此外，他还提供了强大的仓库管理功能，构件搜索功能，它基于REST，友好的UI是一个extjs的REST客户端，它占用较少的内存，基于简单文件系统而非数据库。这些优点使其日趋成为最流行的Maven仓库管理器。 下载nexus参照这个博客吧，懒得自己写了：【Maven】Nexus（Maven仓库私服）下载与安装 Nexus使用及配置这个也参照上面同学的博客吧：【Maven】Nexus配置和使用 特别说明下：Public Repositories：该仓库组将上述所有策略为Release的仓库聚合并通过一致的地址提供服务。可以认为这个公共仓库是多个仓库的组合,里面包含了很多个仓库。确保能下载到jar包它按照下面的顺序寻找依赖 国内镜像地址：http://maven.oschina.net/content/groups/public/ Maven手动添加jar包假如遇到依赖下载不到的情况，我们可以手动把jar包添加到本地仓库中，命令如下：1mvn install:install-file -Dfile=IKAnalyzer3.2.8.jar -DgroupId=org.wltea.ik-analyzer -DartifactId=ik-analyzer -Dversion=3.2.8 -Dpackaging=jar 详细配置网上找了个写的比较全的，看到没用过的可以到这里查查 史上最全的Maven Pom文件标签详解]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker初探]]></title>
    <url>%2F2017%2F09%2F21%2Fdocker%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[弄完了springboot，接下来就可以通过springboot快速搭建springcloud组件了，配合docker完成传说中的微服务架构，但。。。docker是撒啊，决定搞一搞。整体下来操作感觉比较简单，但是理解那个镜像与容器的关系有点费劲。还有什么镜像分层的东东。。。 为啥用dockerDocker到底是什么看看官方的介绍 Docker provides a way to run applications securely isolated in a container, packaged with all its dependencies and libraries. 意思就是为应用提供一个安全隔绝的运行容器，打包它所有的依赖和类库。 Docker是Docker公司开源的一个基于轻量级虚拟化技术的容器引擎项目,整个项目基于Go语言开发，并遵从Apache 2.0协议。目前，Docker可以在容器内部快速自动化部署应用，并可以通过内核虚拟化技术（namespaces及cgroups等）来提供容器的资源隔离与安全保障等。由于Docker通过操作系统层的虚拟化实现隔离，所以Docker容器在运行时，不需要类似虚拟机（VM）额外的操作系统开销，提高资源利用率，并且提升诸如IO等方面的性能。 以前，如果想尝试新的编程语言/数据库/命令行工具，会先找找apt的源里有没有相应的包，没有的话再看看是否有PPA源可以用，再没有就只能尝试从源码编译，编译成功前可能还要经历一遍安装编译工具链，依赖库等过程，而这个过程中遇到下代码被墙，依赖库版本太老/太新等麻烦也不少见。 比如说要安装个nginx，模块依赖性Nginx需要依赖下面3个包1.gzip 模块需要 zlib 库 ( 下载: http://www.zlib.NET/ )2.rewrite 模块需要 pcre 库 ( 下载: http://www.pcre.org/ )3.ssl 功能需要 openssl 库 ( 下载: http://www.openssl.org/ )依赖包安装顺序依次为:openssl、zlib、pcre, 然后安装Nginx包 假如有一步出错，就呵呵，一天就没了，话说我自己装个rabbitmq，弄两天没弄好，编译各种失败。技术烂的，各种搞不定，搞定了也没用，对我有什么好处？docker镜像都搞好了，你只需要一行命令，成了。不过这种隔绝了编译过程，可能对软件的理解有一定影响。不过一般人不需要这些，而是快速搞定。如果想要了解，再去查资料好了，而不是我用的时候，先要学习他的原理。 知乎里面有比较形象的解释docker的概念如何通俗解释Docker是什么？ docker的名言: docker:Build Ship and Run Any App, Anywhere! 软件的生态圈Docker有自己的软件生态圈，应用是以镜像的方式存在于仓库上。然后用户可以根据需要去下载对应的镜像 比如说docker官方库https://hub.docker.com/ 再比如阿里云的管理控制台–&gt;产品服务–容器服务–&gt;镜像里提供的镜像下载。这里也可以进行搜索。我的阿里云链接 版本控制使用docker可以灵活的控制镜像的版本，前进或者回退 Docker的安装Docker对操作系统的要求是，必须是64位的、以及是linux 3.8以上版本的内核 我用的是阿里云服务器Centos7(内核是3.10，centos6的好像内核在3.8以下，安装docker会失败):12~]# uname -aLinux iZ2zehu64p5eabr7fp9t0iZ 3.10.0-514.6.2.el7.x86_64 #1 SMP Thu Feb 23 03:04:39 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux 配置yum软件库为保证安装的成功，首先使用yum update更新Yum包，耐心等候吧。然后在yum软件库中新增docker的配置：12# 更新yumyum update 安装启动有了yum软件库的配置之后，安装也变得异常的简单，只需要以下一句即可：12# 安装yum install docker 一切就绪之后，使用start命令来启动Docker守护进程12# 启动docker引擎systemctl start docker 验证输出hello-world，其实就是利用人家已经写好的hello-world镜像，下载到本地，然后把他运行起来1docker run hello-world 出现如下提示表示安装成功1234...Hello from Docker!This message shows that your installation appears to be working correctly.... docker的国内镜像配置一个阿里云、另一个是DaoCloud; 都是免费的 这里用是阿里的镜像，上面也有提到 阿里容器服务 进入容器服务之后，右上角有个镜像仓库管理控制台的按钮，戳它 点进去之后，点击Doker Hub镜像站点，可以看到加速服务地址和镜像配置 编辑配置文件，添加如下内容12345678# 编辑vi /etc/docker/damon.json#添加&#123; "live-restore":true, "registry-mirrors":["https://lh4kbgp2.mirror.aliyuncs.com"]&#125; 重启服务123systemctl daemon-reload systemctl restart docker 下面，我们以安装tomcat为例，来展开docker的使用。 Docker的操作指令repository、image and ContainerDocker中有三个重要的点：仓库（repository）、镜像（image）、容器（Container） 仓库是存储镜像的（类似appstore）而镜像是软件包（app）容器是基于镜像去创建的，基于一个镜像可以创建若干个不同名字但功能相同的容器 先看下docker的架构了解三个点的执行流程 关于容器和镜像的理解，我贫乏的语言就不进行赘述了，找到一个介绍的好理解的大白话Docker入门（二），尤其是里面AUFS的介绍。 安装tomcat假如我们要使用tomcat镜像，首先我们要到仓库中找到它，阿里云提供了 搜索到tomcat，点击详情，翻到下面就可以看到使用tomcat镜像的指令 按照上面的指令运行tomcat吧1Docker run -it -d -p 8084:8080 tomcat:8.0 日志是酱紫的1You can test it by visiting http://container-ip:8080 in a browser or, if you need access outside the host, on port 8888: 在浏览器上访问吧:http://ip:8084/ 那么这些指令参数究竟都是什么意思呢 docker的指令帮助先查看帮助吧1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768docker --helpUsage: docker [OPTIONS] COMMAND [arg...] docker [ --help | -v | --version ]A self-sufficient runtime for containers.Options: --config=~/.docker Location of client config files -D, --debug Enable debug mode -H, --host=[] Daemon socket(s) to connect to -h, --help Print usage -l, --log-level=info Set the logging level --tls Use TLS; implied by --tlsverify --tlscacert=~/.docker/ca.pem Trust certs signed only by this CA --tlscert=~/.docker/cert.pem Path to TLS certificate file --tlskey=~/.docker/key.pem Path to TLS key file --tlsverify Use TLS and verify the remote -v, --version Print version information and quitCommands: attach Attach to a running container build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container diff Inspect changes on a container's filesystem events Get real time events from the server exec Run a command in a running container export Export a container's filesystem as a tar archive history Show the history of an image images List images import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on a container, image or task kill Kill one or more running containers load Load an image from a tar archive or STDIN login Log in to a Docker registry. logout Log out from a Docker registry. logs Fetch the logs of a container network Manage Docker networks node Manage Docker Swarm nodes pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart a container rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images service Manage Docker services start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers swarm Manage Docker Swarm tag Tag an image into a repository top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information volume Manage Docker volumes wait Block until a container stops, then print its exit codeRun 'docker COMMAND --help' for more information on a command. 帮助已经写的非常明白了，这么使用指令1docker [OPTIONS] COMMAND [arg...] COMMAND有这些，后面都有详细的功能介绍1234567Commands: attach Attach to a running container build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container ... 每个指令的使用也可以查看帮助1Run 'docker COMMAND --help' for more information on a command. 比如说，我想查查刚才运行tomcat容器的-it、-d、-p都是啥意思啊,就酱紫1234567891011~]# docker run --helpUsage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]Run a command in a new containerOptions: -i, --interactive Keep STDIN open even if not attached -t, --tty Allocate a pseudo-TTY -d, --detach Run container in background and print container ID -p, --publish value Publish a container's port(s) to the host (default []) 再看下命令1Docker run -it -d -p 8084:8080 tomcat:8.0 诺，-it大概就是命令行的意思，-d表示后台运行呗，-p表示映射端口到服务器，在容器里的8080端口映射到外部服务器8084端口，然后咱就可以输入外部服务器的ip:8084访问啦。 指令分类docker的指令大概可以分为四个种类，分类之后有助于使用，不然到帮助里遍历可能会比较慢 针对守护进程的系统资源设置和全局信息的获取 12docker infodocker daemon 针对docker仓库的查询、下载 12docker searchdocker pull 针对docker镜像的查询、创建、删除 1234docker imagesdocker builddocker deletedocker rmi [image id] 针对docker容器的查询、开启、停止 123docker rundocker psdocker stop [image id /container id] 操作tomcat这里我们操作使用tomcat来熟练下使用 我们已经运行了tomcat容器，那么我们查看下tomcat的运行情况吧，查看帮助12~]# docker --help ps List containers ps命令会列出现有的容器123456789~]# docker ps --helpUsage: docker ps [OPTIONS]List containersOptions: -a, --all Show all containers (default shows just running) --no-trunc Don't truncate output 看到了吧，-a表示列出所有的容器，不写默认显示正在运行的容器123456~]# docker psCONTAINER ID IMAGE PORTS NAMES7b3e73e5c624 tomcat:8.0 0.0.0.0:8084-&gt;8080/tcp clever_shaw04120a965a49 wordpress 0.0.0.0:8082-&gt;80/tcp mywordPress2adb8da207e2 mariadb 3306/tcp mydbee42fdb74565 tomcat:8.0 0.0.0.0:8083-&gt;8080/tcp Atomcat 前面的是CONTAINER ID，用来标识不同的容器 停止tomcat12345~]# docker stop 7b3e73e5c6247b3e73e5c624~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 发现运行的容器找不到了，查看所有容器123~]# docker ps -aCONTAINER ID IMAGE STATUS NAMES7b3e73e5c624 tomcat:8.0 Exited (143) About a minute ago clever_shaw 删掉这个容器12~]# docker rm 7b3e73e5c6247b3e73e5c624 查看镜像1234567~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/redis latest aaf79d45ddb1 2 days ago 106.6 MBdocker.io/wordpress latest 2c69ebee76a8 6 days ago 408.3 MBdocker.io/tomcat 8.0 4b4d4b37d587 7 days ago 453.8 MBdocker.io/mariadb latest eb7b193b1631 7 days ago 397.1 MBdocker.io/hello-world latest 05a3bd381fc2 8 days ago 1.84 kB 删除镜像（以helloworld为例，tomcat在用）12~]# docker rmi 05a3bd381fc2Error response from daemon: conflict: unable to delete 05a3bd381fc2 (must be forced) - image is being used by stopped container 97531974bb1d 发现删不了，因为有容器在使用镜像，所以先要删除容器123456~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES97531974bb1d hello-world "/hello" 4 hours ago Exited (0) 4 hours ago thirsty_chandrasekhar~]# docker rm 97531974bb1d97531974bb1d 然后再删除镜像12345~]# docker rmi 05a3bd381fc2Untagged: docker.io/hello-world:latestUntagged: docker.io/hello-world@sha256:1f19634d26995c320618d94e6f29c09c6589d5df3c063287a00e6de8458f8242Deleted: sha256:05a3bd381fc2470695a35f230afefd7bf978b566253199c4ae5cc96fafa29b37Deleted: sha256:3a36971a9f14df69f90891bf24dc2b9ed9c2d20959b624eab41bbf126272a023 上述操作也可以通过names来完成（上面操作的是id）,给容器起个别名,默认也有名123456~]# docker run --name Atomcat -it -d -p 8083:8080 tomcat:8.0ee42fdb74565e80ff262b40cb172f23b610f4d156c907e04cab5d13e59f1073b~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESee42fdb74565 tomcat:8.0 "catalina.sh run" 6 seconds ago Up 4 seconds 0.0.0.0:8083-&gt;8080/tcp Atomcat 单个容器的详细信息1docker inspect f6071fc4ccc9 查看tomcat日志1docker logs -f Atomcat Docker容器管理容器标识符每个容器被创建以后，都会分配一个Container Id作为容器唯一的标识符，后续对容器的所有操作命令都是通过container id来执行 传说中有128位字符，现在它只显示在当前服务器能够区别开来的字符长度，想看全部的话，加–no-trunc参数123~]# docker ps --no-trunc | awk '&#123;print $1&#125;'CONTAINER7b3e73e5c6243d0d504af7f07f61d052fbc95c8450b6582d384681a0dbfbd577 变的好长。。。 容器内部命令有时候我们需要登录到容器内部执行一些命令或者配置，那么docker可以通过原生的方式去登录到容器 进入容器内部1234567891011121314151617# 查看帮助~]# docker exec --helpUsage: docker exec [OPTIONS] CONTAINER COMMAND [ARG...]Run a command in a running container -d, --detach Detached mode: run command in the background --detach-keys Override the key sequence for detaching a container --help Print usage -i, --interactive Keep STDIN open even if not attached --privileged Give extended privileges to the command -t, --tty Allocate a pseudo-TTY -u, --user Username or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;])# 进入容器内部~]# docker exec -it Atomcat /bin/bash 容器的结构12/]# lsbin boot dev docker-java-home etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 执行完以后，通过exit来退出 多容器管理假设一个场景，加入我现在想用wordpress搭建个人博客在我的服务器上，需要多长时间呢，你会搭建的很顺利吗？这些，通过docker只需要2到3min即可完成。 安装mariaDb12# mydb 表示的自定义的那么 、 --env配置数据的帐号密码Docker run --name mydb –env MYSQL_ROOT_PASSWORD=example -d mariadb 安装wordpress并关联mariaDb12# myWordPress 自定义名称，mydb表示的是第一步所运行的容器名称Docker run –name myWordPress –link mydb:mysql -p 8080:80 -d wordpress 查看下容器1234# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES04120a965a49 wordpress "docker-entrypoint.sh" 16 hours ago Up 16 hours 0.0.0.0:8082-&gt;80/tcp mywordPress2adb8da207e2 mariadb "docker-entrypoint.sh" 16 hours ago Up 16 hours 3306/tcp mydb 可以看到，数据库和wordpress已经跑起来了，找个浏览器访问下吧。 根据引导，你的个人博客就搭建起来了，肿么样，快不快。 Docker compose容器编排工具Docker提供了一个容器编排工具 docker compose,允许用户在一个YAML的文件中定义一组相关联的应用容器 下载地址在这里，都有帮助信息的 查看帮助 借鉴下别人的博客，编辑yaml模板 Run this command to download the latest version of Docker Compose1~]# curl -L https://github.com/docker/compose/releases/download/1.16.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose Apply executable permissions to the binary1local]# chmod +x /usr/local/bin/docker-compose 创建文件~/wordpress/docker-compose.yml这就是个配置文件123456789101112~]# vim docker-compose.yml compose-wordpress: image: wordpress links: - 'compose-db:mysql' ports: - '8086:80'compose-db: image: mariadb environment: MYSQL_ROOT_PASSWORD: example 文件意义：a. 定义了两个服务分别叫做compose_wordpress和compose_dbb. 使用image定义每个服务的镜像名c. MySQL容器的环境变量定义在environmentd. MySQL容器使用links和WildFly容器链接e. 使用ports实现端口转发 补充:这个yaml格式的文件，我写的时候疯狂报错，害我又耽误时间查yaml的语法，结果镜像仓库里有这个代码，早知道就抄过来了。不过springboot也可以用这个写配置文件，学了也不吃亏。 后台模式启动12345~]# docker-compose up -dCreating root_compose-db_1 ... Creating root_compose-db_1 ... doneCreating root_compose-wordpress_1 ... Creating root_compose-wordpress_1 ... done 查看1234~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES32d75b04dfeb wordpress &quot;docker-entrypoint.sh&quot; 11 seconds ago Up 7 seconds 0.0.0.0:8086-&gt;80/tcp root_compose-wordpress_11394b6ee28b0 mariadb &quot;docker-entrypoint.sh&quot; 11 seconds ago Up 11 seconds 3306/tcp root_compose-db_1 浏览器访问就可以了。 停止服务1docker-compose start/stop 删除服务1docker-compose ~/wordpress/docker-compose.yml down 检查日志1docker-compose logs 检查运行的实例1docker-compose ps 镜像分层设计docker特点docker image的体积非常的小 docker的系统启动的耗时为0 docker系统占用资源极少 为什么呢基于aufs实现镜像分层大量复用已有的镜像资源，嗯，差不多就酱紫，话说我也一直半解。 镜像的层的特性 已有的分层只能读不能修改 上层镜像的优先级高于底层镜像 可以通过在上层增加新的镜像，来覆盖底层镜像以达到修改的目的 资料网上有很多大牛的博客写的很好或者写的非常精巧便于理解，放在这里做个索引 官方文档使用的时候查这个最方便了 理解docker架构有助于了解docker的运行流程 docker架构 这篇文章通俗的讲解了aufs系统的原理，对于理解镜像分层概念很有帮助 Docker入门 阿里云仓库 ali-rep]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot]]></title>
    <url>%2F2017%2F09%2F19%2Fspring-boot%2F</url>
    <content type="text"><![CDATA[spring-boot新框架，大量默认配置简化开发， Spring Boot是为了简化Spring应用的创建、运行、调试、部署等而出现的，使用它可以做到专注于Spring应用的开发，而无需过多关注XML的配置。简单来说，它提供了一堆依赖打包，并已经按照使用习惯解决了依赖问题—习惯大于约定。 Spring Boot默认使用tomcat作为服务器，使用logback提供日志记录。 Spring Boot提供了一系列的依赖包，所以需要构建工具的支持：maven 或 gradle。 这里做个记录。demo项目放在github上，点我 官方文档去官网找，这里发现个翻译版的，好矛盾，是不是不应该看中文的。 常用配置Spring boot 四个核心：Starter，autoconfiguration，actuator，CLI 常用配置属性配置可以在application.properties或者application.yml中配置属性，比如说12server.port=8888server.context-path=/demo 导入xml配置@importResouce 如果在实际项目中，存在特殊场景必须使用xml配置，那么可以通过这个注解来加载xml配置 外部配置使用@ConfigurationProperties将properties属性和一个bean中的属性做关联，比如想把两个常量配置注入到controller中使用，先在properties中配置12demo.student.name=tomdemo.student.age=23 然后写个专门注入常量的类，用@ConfigurationProperties注解来注入properties中的常量，可以用prefix来配置前缀。123456789101112131415161718192021222324252627282930313233343536373839@ConfigurationProperties(prefix = "demo.student")@Componentpublic class StudentConstants &#123; private String name; private Integer age; /** * @return the name */ public String getName() &#123; return name; &#125; /** * @param name * the name to set */ public void setName(String name) &#123; this.name = name; &#125; /** * @return the age */ public Integer getAge() &#123; return age; &#125; /** * @param age * the age to set */ public void setAge(Integer age) &#123; this.age = age; &#125;&#125; 在controller中注入常量类对象来获取常量的值1234567891011121314@RestControllerpublic class StudentController &#123; @Autowired private StudentConstants studentConstants; @RequestMapping("/getStudent") public Student getStudent() &#123; Student student = new Student(); student.setName(studentConstants.getName()); student.setAge(studentConstants.getAge()); return student; &#125;&#125; 使用profile在多环境下切换实际开发中可能遇到不同环境需要不同配置的情况，这样的情况下可以定义不同的配置文件而在需要相应的开发环境时做切换。 首先在application.properties中定一个spring.profiles.active={profile}然后在application-{profile}.properties中写入不同环境的变量就可以了，比如我开发、生产环境的student默认name和age不同 先在application.properties中定义活跃的profile 12345spring.profiles.active=dev# 注意此时定义的属性值demo.student.name=tomdemo.student.age=23 然后在application-dev中添加常量属性 12demo.student.name=jerrydemo.student.age=24 运行下试试吧 12345//没有设spring.profiles.active=dev时值是这样的&#123;"id":null,"name":"tom","age":23,"sex":null&#125;//设置spring.profiles.active=dev时值是这样的&#123;"id":null,"name":"jerry","age":24,"sex":null&#125; 组件(SpringBoot启动器) spring-boot-starter:这是SpringBoot的核心启动器，包含了自动配置、日志和YAML。 spring-boot-starter-actuator:帮助监控和管理应用。 spring-boot-starter-amqp:通过spring-rabbit来支持AMQP协议（Advanced Message Queuing Protocol）。 spring-boot-starter-aop:支持面向方面的编程即AOP，包括spring-aop和AspectJ。 spring-boot-starter-artemis:通过Apache Artemis支持JMS的API（Java Message Service API）。 spring-boot-starter-batch:支持Spring Batch，包括HSQLDB数据库。 spring-boot-starter-cache:支持Spring的Cache抽象。 spring-boot-starter-cloud-connectors:支持Spring Cloud Connectors，简化了在像Cloud Foundry或Heroku这样的云平台上连接服务。 spring-boot-starter-data-elasticsearch:支持ElasticSearch搜索和分析引擎，包括spring-data-elasticsearch。 spring-boot-starter-data-gemfire:支持GemFire分布式数据存储，包括spring-data-gemfire。 spring-boot-starter-data-jpa:支持JPA（java Persistence API），包括spring-data-jpa、spring-orm、hibernate。 spring-boot-starter-data-MongoDB:支持mongodb数据，包括spring-data-mongodb。 spring-boot-starter-data-rest:通过spring-data-rest-webmvc，支持通过REST暴露Spring Data数据仓库。 spring-boot-starter-data-solr:支持Apache Solr搜索平台，包括spring-data-solr。 spring-boot-starter-freemarker:支持FreeMarker模板引擎。 spring-boot-starter-groovy-templates:支持Groovy模板引擎。 spring-boot-starter-hateoas:通过spring-hateoas支持基于HATEOAS的RESTful Web服务。 spring-boot-starter-hornetq:通过HornetQ支持JMS。 spring-boot-starter-integration:支持通用的spring-integration模块。 spring-boot-starter-jdbc:支持JDBC数据库。 spring-boot-starter-jersey:支持Jersey RESTful Web服务框架。 spring-boot-starter-jta-atomikos:通过Atomikos支持JTA分布式事务处理。 spring-boot-starter-jta-bitronix:通过Bitronix支持JTA分布式事务处理。 spring-boot-starter-mail:支持javax.mail模块。 spring-boot-starter-mobile:支持spring-mobile。 spring-boot-starter-mustache:支持Mustache模板引擎。 spring-boot-starter-Redis:支持redis键值存储数据库，包括spring-redis。 spring-boot-starter-security:支持spring-security。 spring-boot-starter-social-facebook:支持spring-social-facebook spring-boot-starter-social-linkedin:支持pring-social-linkedin spring-boot-starter-social-twitter:支持pring-social-twitter spring-boot-starter-test:支持常规的测试依赖，包括JUnit、Hamcrest、Mockito以及spring-test模块。 spring-boot-starter-thymeleaf:支持Thymeleaf模板引擎，包括与Spring的集成。 spring-boot-starter-velocity:支持Velocity模板引擎。 spring-boot-starter-web:S支持全栈式Web开发，包括Tomcat和spring-webmvc。 spring-boot-starter-websocket:支持WebSocket开发。 spring-boot-starter-ws:支持Spring Web Services。 自己实现starter来理解启动器原理创建个maven工程，导入依赖spring-boot12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot&lt;/artifactId&gt; &lt;version&gt;1.5.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; 创建service类1234567891011121314package com.gsc.springboot.starter.demo;/** * @author shichaogeng * * 2017年9月22日 */public class HelloService &#123; public String sayHello() &#123; System.out.println("Hello Starter"); return "hello starter"; &#125;&#125; 创建自动配置类1234567891011121314151617181920package com.gsc.springboot.starter.demo;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author shichaogeng * * 2017年9月22日 */@Configuration//@EnableAutoConfiguration会自动扫描管理@Configuration的类完成初始化配置public class HelloAtuoConfiure &#123; @Bean //@Bean表示这个方法创建的类，会交给spirng容器 public HelloService sayHello() &#123; return new HelloService(); &#125;&#125; 在resources目录下创建/META-INF/spring.factories文件，加入如下配置1org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.gsc.springboot.starter.demo.HelloAtuoConfiure 使用maven install打成jar包，在springboot项目中导入依赖，就可以当做一个starter来使用了。1234567891011121314151617181920212223242526package com.gsc.demo.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import com.gsc.demo.config.StudentConstants;import com.gsc.demo.domain.Student;import com.gsc.springboot.starter.demo.HelloService;/** * @author shichaogeng * * 2017年9月22日 */@RestControllerpublic class StudentController &#123; @Autowired private HelloService HelloService; @RequestMapping("/hellostarter") public String helloStarter() &#123; return HelloService.sayHello(); &#125;&#125; 启动工程，访问结果如下1hello starter actuator默认终端导入依赖12345&lt;!-- 监控 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 在application.properties中打开配置，就可以看到一些springboot项目的运行状况123endpoints.env.sensitive=falseendpoints.trace.sensitive=falseendpoints.beans.sensitive=false 访问localhost：8888/demo/env /info /metrics /health /beans /trace 等等 也可以自己扩展定义个类继承AbstractEndpoint就可以实现扩展1234567891011121314151617181920212223242526272829303132333435package com.gsc.demo.endpoint;import java.text.SimpleDateFormat;import java.util.Date;import org.springframework.boot.actuate.endpoint.AbstractEndpoint;import org.springframework.boot.context.properties.ConfigurationProperties;/** * @author shichaogeng * * 2017年9月22日 */@ConfigurationProperties(prefix="endpoints.servertimes")public class ServerTimeEndPoint extends AbstractEndpoint&lt;String&gt;&#123; /** * @param id */ public ServerTimeEndPoint() &#123; super("servertimes"); &#125; /** * @author shichaogeng * @date 2017年9月22日 * @return */ @Override public String invoke() &#123; return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()); &#125;&#125; invoke方法中定义自己要实现的检测内容，然后实例化你的类交给spring管理123456789101112131415161718192021package com.gsc.demo.config;import org.springframework.boot.actuate.endpoint.Endpoint;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import com.gsc.demo.endpoint.ServerTimeEndPoint;/** * @author shichaogeng * * 2017年9月22日 */@Configurationpublic class EndpointCofig &#123; @Bean public Endpoint&lt;String&gt; serverTimes() &#123; return new ServerTimeEndPoint(); &#125;&#125; 配置文件中打开配置，默认是true，在父类构造中1endpoints.servertimes.sensitive=false 访问 localhost:8888/demo/servertimes看到12017-09-22 16:11:56 一个检测时间的就写好了 spring CLI一个自动化管理的脚本，具体的去官网看吧 Installing the Spring Boot CLI pom配置 Springboot父工程依赖 123456&lt;parent&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&lt;version&gt;1.3.1.RELEASE&lt;/version&gt;&lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt; Springboot web启动器依赖 1234&lt;dependency&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 常用注解 @SpringBootApplication：包含了@ComponentScan、@Configuration和@EnableAutoConfiguration注解。其中@ComponentScan让spring Boot扫描到Configuration类并把它加入到程序上下文。 @Configuration 等同于spring的XML配置文件；使用Java代码可以检查类型安全。 @EnableAutoConfiguration 自动配置。 @ComponentScan 组件扫描，可自动发现和装配一些Bean。 @Component可配合CommandLineRunner使用，在程序启动后执行一些基础任务。 @RestController注解是@Controller和@ResponseBody的合集,表示这是个控制器bean,并且是将函数的返回值直接填入HTTP响应体中,是REST风格的控制器。 @Autowired自动导入。 @PathVariable获取参数。 @JsonBackReference解决嵌套外链问题。 @RepositoryRestResourcepublic配合spring-boot-starter-data-rest使用。 @EnableAutoConfiguration：SpringBoot自动配置（auto-configuration）：尝试根据你添加的jar依赖自动配置你的Spring应用。例如，如果你的classpath下存在HSQLDB，并且你没有手动配置任何数据库连接beans，那么我们将自动配置一个内存型（in-memory）数据库”。你可以将@EnableAutoConfiguration或者@SpringBootApplication注解添加到一个@Configuration类上来选择自动配置。如果发现应用了你不想要的特定自动配置类，你可以使用@EnableAutoConfiguration注解的排除属性来禁用它们。 这个注释告诉SpringBoot“猜”你将如何想配置Spring,基于你已经添加jar依赖项。如果spring-boot-starter-web已经添加Tomcat和Spring MVC,这个注释自动将假设您正在开发一个web应用程序并添加相应的spring设置。 自动配置被设计用来和“Starters”一起更好的工作,但这两个概念并不直接相关。您可以自由挑选starter依赖项以外的jar包，springboot仍将尽力自动配置您的应用程序。 @Bean:相当于XML中的bean,放在方法的上面，而不是类，意思是产生一个bean,并交给spring管理。 SpringBoot启动123456789import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class SpringBootSampleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootSampleApplication.class, args); &#125; &#125; 配置文件去官网看吧 SpringBoot支持JSP 配置application.properties 1234# 页面默认前缀目录spring.mvc.view.prefix=/WEB-INF/jsp/# 响应页面默认后缀spring.mvc.view.suffix=.jsp 加入依赖 123456789&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; SpringBoot支持freemarker 配置application.properties 12345678spring.freemarker.allow-request-override=falsespring.freemarker.cache=truespring.freemarker.check-template-location=truespring.freemarker.charset=UTF-8spring.freemarker.content-type=text/htmlspring.freemarker.expose-request-attributes=falsespring.freemarker.expose-session-attributes=falsespring.freemarker.expose-spring-macro-helpers=false 加入依赖 12345&lt;!-- 引入freeMarker的依赖包. --&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;&lt;/dependency&gt; SpringBoot-Servlet注册Springboot中有两种方式可以添加 Servlet、Filter、Listener 代码注册通过ServletRegistrationBean、 FilterRegistrationBean 和 ServletListenerRegistrationBean 获得控制 1234@Bean public ServletRegistrationBean servletRegistrationBean() &#123; return new ServletRegistrationBean(new MyServlet(), "/xs/*");&#125; 在 SpringBootApplication 上使用@ServletComponentScan 注解后，Servlet、Filter、Listener 可以直接通过 @WebServlet、@WebFilter、@WebListener 注解自动注册，无需其他代码。 1234567@SpringBootApplication@ServletComponentScanpublic class SpringBootSampleApplication &#123; public static void main(String[] args)&#123; SpringApplication.run(SpringBootSampleApplication.class, args); &#125; &#125; SpringBoot拦截器 创建我们自己的拦截器类并实现 HandlerInterceptor 接口。 创建一个Java类继承WebMvcConfigurerAdapter，并重写 addInterceptors 方法。 实例化我们自定义的拦截器，然后将对像手动添加到拦截器链中（在addInterceptors方法中添加）。 SpringBoot静态资源处理 Spring Boot 的默认资源映射 其中默认配置的 /** 映射到 /static （或/public、/resources、/META-INF/resources） 其中默认配置的 /webjars/**映射到classpath:/META-INF/resources/webjars/..上面的 static、public、resources 等目录都在 classpath: 下面（如 src/main/resources/static）。 自定义资源映射 继承 WebMvcConfigurerAdapter 并重写方法 addResourceHandlers 12registry.addResourceHandler("/image/**").addResourceLocations("file:H:/image/");registry.addResourceHandler("/image1/**").addResourceLocations("classpath:/img1/") 通过配置文件映射 使用 spring.mvc.static-path-pattern 可以重新定义pattern，如修改为 /image/** 使用 spring.resources.static-locations 可以重新定义 pattern 所指向的路径，支持 classpath: 和 file: 注意 spring.mvc.static-path-pattern 只可以定义一个，目前不支持多个逗号分割的方式。 默认值为 /映射: spring.mvc.static-path-pattern= /image/ 默认值为 classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/映射: spring.resources.static-locations=classpath:/image/ SpringBoot启动加载数据实际应用中，我们会有在项目服务启动的时候就去加载一些数据或做一些事情这样的需求。 为了解决这样的问题，spring Boot 为我们提供了一个方法，通过实现接口 CommandLineRunner 来实现。 SpringBoot日志spring boot内部使用Commons Logging来记录日志，但也保留外部接口可以让一些日志框架来进行实现，例如Java Util Logging,Log4J2还有Logback。如果你想用某一种日志框架来进行实现的话，就必须先配置，默认情况下，spring boot使用Logback作为日志实现的框架。 ${LOG_PATH}, Spring Boot配置文件中logging.path的值 配置logging.level.*来具体输出哪些包的日志级别logging.level.root=INFOlogging.level.org.springframework.web=DEBUGlogging.level.org.hibernate=ERROR 将日志输出到文件中logging.path=D:\demologging.file=demo.loglogging.level.root=info 关于logback使用请参照从零开始玩转logback SpringBoot-JDBC 属性配置文件（application.properties） 1234spring.datasource.url=jdbc:mysql://localhost:3306/test spring.datasource.username=root spring.datasource.password=123456 spring.datasource.driver-class-name=com.mysql.jdbc.Driver pom.xml 配置maven依赖 1&lt;!-- MYSQL --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot JDBC --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; Springboot-Mybatis pom.xml 配置maven依赖 1&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; 一定要在启动的地方加上@MapperScan(“com.dongnao.jack.dao”) 配置文件中加上配置 12mybatis.typeAliasesPackage=com.dongnao.jack.beanmybatis.mapperLocations=classpath:com/dongnao/jack/xml/*Mapper.xml SpringBoot动态数据源抄的这里 启动类注册动态数据源 123456@SpringBootApplication@Import(&#123;DynamicDataSourceRegister.class&#125;) // 注册动态多数据源public class SpringBootSampleApplication &#123; // 省略其他代码&#125; 配置文件中配置多个数据源(application.properties) 1234567891011121314151617# 主数据源，默认的spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.url=jdbc:mysql://localhost:3306/testspring.datasource.username=rootspring.datasource.password=123456# 更多数据源custom.datasource.names=ds1,ds2custom.datasource.ds1.driver-class-name=com.mysql.jdbc.Drivercustom.datasource.ds1.url=jdbc:mysql://localhost:3306/test1custom.datasource.ds1.username=rootcustom.datasource.ds1.password=123456custom.datasource.ds2.driver-class-name=com.mysql.jdbc.Drivercustom.datasource.ds2.url=jdbc:mysql://localhost:3306/test2custom.datasource.ds2.username=rootcustom.datasource.ds2.password=123456 在方法用注解指定数据源 123456789101112131415@Servicepublic class StudentService &#123; // MyBatis的Mapper方法定义接口 @Autowired private StudentMapper studentMapper; @TargetDataSource(name=&quot;ds2&quot;) public List&lt;Student&gt; likeName(String name)&#123; return studentMapper.likeName(name); &#125; public List&lt;Student&gt; likeNameByDefaultDataSource(String name)&#123; return studentMapper.likeName(name); &#125; 这个博客讲的好明白Spring(AbstractRoutingDataSource)实现动态数据源切换 这里记下运行流程代码地址点spring-boot动态数据源github代码 通知spring注册动态数据源(DemoApplication)123456789@SpringBootApplication@MapperScan(basePackages="com.gsc.demo.mapper")@Import(&#123;DynamicDataSourceRegister.class&#125;) // 注册动态多数据源public class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 动态数据源注册(DynamicDataSourceRegister)12public class DynamicDataSourceRegister implements ImportBeanDefinitionRegistrar, EnvironmentAware &#123;&#125; spring调用EnvironmentAware.setEnvironment()接口读取配置文件，加载数据源 12345678/** * 加载多数据源配置 */@Overridepublic void setEnvironment(Environment env) &#123; initDefaultDataSource(env); initCustomDataSources(env);&#125; 在spring中加载registerBeanDefinitions的bean 1public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123;&#125; aop切换数据源(DynamicDataSourceAspect) 在StudentServiceImpl中调用方法之前，看到注解@TargetDataSource 1234567891011/** * @author shichaogeng * @date 2017年9月20日 * @param name * @return */@Override@TargetDataSource(name="ds1")public List&lt;Student&gt; likeName(String name) &#123; return studentMapper.likeName(name);&#125; 动态代理，先执行切面(DynamicDataSourceAspect)增强方法@Before，设置数据源 12345678910111213141516171819202122232425/** * * 切换数据源Advice * @author shichaogeng * * 2017年9月20日 */@Aspect@Order(-1)// 保证该AOP在@Transactional之前执行@Componentpublic class DynamicDataSourceAspect &#123; private static final Logger logger = LoggerFactory.getLogger(DynamicDataSourceAspect.class); @Before("@annotation(ds)") public void changeDataSource(JoinPoint point, TargetDataSource ds) throws Throwable &#123; String dsId = ds.name(); if (!DynamicDataSourceContextHolder.containsDataSource(dsId)) &#123; logger.error("数据源[&#123;&#125;]不存在，使用默认数据源 &gt; &#123;&#125;", ds.name(), point.getSignature()); &#125; else &#123; logger.debug("Use DataSource : &#123;&#125; &gt; &#123;&#125;", ds.name(), point.getSignature()); DynamicDataSourceContextHolder.setDataSourceType(dsId); &#125; &#125;&#125; 获取数据源 执行studentMapper.likeName(name)，这里需要获取数据源 12345678910111213public List&lt;Student&gt; likeName(String name) &#123; return studentMapper.likeName(name);&#125;/** * @author shichaogeng * * 2017年9月20日 */public interface StudentMapper &#123; List&lt;Student&gt; likeName(String name);&#125; 执行AbstractRoutingDataSource数据源路由获取连接getConnection() 1234@Overridepublic Connection getConnection() throws SQLException &#123; return determineTargetDataSource().getConnection();&#125; 可以看到要调用determineTargetDataSource获取数据源 123456789101112protected DataSource determineTargetDataSource() &#123; Assert.notNull(this.resolvedDataSources, "DataSource router not initialized"); Object lookupKey = determineCurrentLookupKey(); DataSource dataSource = this.resolvedDataSources.get(lookupKey); if (dataSource == null &amp;&amp; (this.lenientFallback || lookupKey == null)) &#123; dataSource = this.resolvedDefaultDataSource; &#125; if (dataSource == null) &#123; throw new IllegalStateException("Cannot determine target DataSource for lookup key [" + lookupKey + "]"); &#125; return dataSource;&#125; 其中关键代码就是获取数据源的key 1Object lookupKey = determineCurrentLookupKey(); 这里就调用AbstractRoutingDataSource的实现类DynamicDataSource 123456789101112131415/** * * 动态数据源 * @author shichaogeng * * 2017年9月20日 */public class DynamicDataSource extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; return DynamicDataSourceContextHolder.getDataSourceType(); &#125;&#125; 就酱紫了，结束了，一切都结束了。]]></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>动态数据源切换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins牛刀小试]]></title>
    <url>%2F2017%2F09%2F15%2FJenkins%E7%89%9B%E5%88%80%E5%B0%8F%E8%AF%95%2F</url>
    <content type="text"><![CDATA[想用jenkins完成项目自动部署，结果搞了一下午各种失败，没办法，买了个阿里云服务器，以后在这上面玩吧。从头弄下，搭建个基本环境，然后记录下，故有此文。 环境12[root@test105 /usr/local/tomcat/webapps]# uname -aLinux test105.server 2.6.32-504.el6.x86_64 #1 SMP Wed Oct 15 04:27:16 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux Jdk tomcat运行需要jdk环境，网上下个jdk1.8。下载地址 有自带的jdk就卸了 12345java –versionrpm -qa | grep javarpm -e --nodeps java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.x86_64rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.x86_64 上传jdk到服务器，解压 1234567tar -zxvf jdk-8u144-linux-x64.tar.gzcp -r jdk1.8.0_144/ /lab/dev/[root@iZ2zehu64p5eabr7fp9t0iZ dev]# cd /lab/dev/ &amp;&amp; lltotal 4drwxr-xr-x 8 root root 4096 Sep 15 15:09 jdk1.8.0_144 第三步：配置环境变量 123456789101112vim /etc/profile# 在文件末尾追加JAVA_HOME=/usr/jdkexport CLASSPATH=.:$JAVA_HOME/libexport PATH=$JAVA_HOME/bin:$PATH# 保存退出:wq#重启source /etc/profile 检验，看成了没 1234567[root@iZ2zehu64p5eabr7fp9t0iZ dev]# echo $PATH/lab/dev/jdk1.8.0_144/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin[root@iZ2zehu64p5eabr7fp9t0iZ dev]# java -versionjava version "1.8.0_144"Java(TM) SE Runtime Environment (build 1.8.0_144-b01)Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode) Tomcat 下载 上传，解压 12345tar -zxvf apache-tomcat-8.0.46.tar.gz [root@iZ2zehu64p5eabr7fp9t0iZ source]# cp -rf apache-tomcat-8.0.46 /lab/dev/tomcat-jenkins[root@iZ2zehu64p5eabr7fp9t0iZ source]# cp -rf apache-tomcat-8.0.46 /lab/dev/tomcat-server01 配置下server01用tomcat端口号 配置下server01用tomcat用户权限（jenkins部署用）` 12345678910# 编辑vim tomcat-users.xml #添加&lt;role rolename="tomcat"/&gt;&lt;role rolename="role1"/&gt;&lt;role rolename="manager-gui"/&gt;&lt;role rolename="manager-script"/&gt;&lt;role rolename="manager-status"/&gt;&lt;user username="tomcat" password="tomcat" roles="manager-gui,manager-script,manager-status"/&gt; 启动下，找个浏览器看能不能访问 Maven 下载 上传服务器，解压 123tar -zxvf apache-maven-3.5.0-bin.tar.gz cp -r apache-maven-3.5.0 /lab/dev/ 配置maven 1234567891011121314151617# 编辑# 添加&lt;localRepository&gt;/lab/dev/apache-maven-3.5.0/repository&lt;/localRepository&gt;&lt;!--配置阿里云国内镜像 --&gt;&lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;&lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;central&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;url&gt;http://repo1.maven.org/maven2/&lt;/url&gt;&lt;/mirror&gt; 环境变量 12345678910# 编辑vim /etc/profile# 添加MAVEN_HOME=/lab/dev/apache-maven-3.5.0PATH=$PATH:$MAVEN_HOME/binexport PATH MAVEN_HOME# 加载source /etc/profile Git安装git 我yum安装时报错，然后就百度一番，也记录下吧。 123456# 错误Not using downloaded repomd.xml because it is older than what we have# 解决（清空缓存）yum clean allyum makecache 安装 1234567yum -y install git# 测试git --version# 查看帮助git --help 配置github用户配置我要用github上的项目做测试，配置github用户名密码12git config --global user.name shichaogenggit config --global user.email shichaogeng@gmail.com 配置秘钥 git在部署github时使用SSH协议连接和验证远程服务器和服务。为避免暴露账户密码，最好使用证书认证。使用SSH密钥，可以连接到GitHub，而无需在每次访问时提供用户名或密码。 查看密匙执行cd ~/.ssh命令，如果存在该目录，表明之前生成果SSH Key，利用ll命令即可以查看。123[root@iZ2zehu64p5eabr7fp9t0iZ .ssh]# lltotal 0-rw------- 1 root root 0 Sep 15 13:20 authorized_keys 看一下有没有id_rsa和id_rsa.pub(或者是id_dsa和id_dsa.pub之类成对的文件)，有.pub 后缀的文件就是公钥，另一个文件则是密钥。 假如没有这些文件，甚至连.ssh 目录都没有，可以用 ssh-keygen 来创建。该程序在 Linux/Mac 系统上由 SSH 包提供，而在 Windows 上则包含在 MSysGit 包里。 生成私钥12345678910111213141516171819202122[root@iZ2zehu64p5eabr7fp9t0iZ .ssh]# ssh-keygen -t rsa -C "shichaogeng@gmail.com"Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:4f:e4:71:c2:89:92:03:80:41:1c:c2:11:cc:06:ff:ea shichaogeng@gmail.comThe key's randomart image is:+--[ RSA 2048]----+|@B=.. ||oB . . o . ||. . + . * . || . o o + || . S o || . o || . . || . || E |+-----------------+# 本地密匙生成成功！ 查看生成的公钥1ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7+EsE7t+TmI9AA16QQMNnwB3fbogZGznD18jttNvANvkYITlNnty2a/qiFdVuaSvPHbwW5djKT8fwVpieJStlefEsdAXg+r7DPgyttFf2vHYdHULdZNc48aNy/GN1hZFvPU1PwsV/xAL8phFER4aFhQYygcnkY1/KbfSZOHo+9uL+oc7bBQZYTEhfdl+twwesnAt3erSPIl1U0Cv5tkCdj2WRnLGiLXdnUfK7Zq5jtfQiXWeXCXjt3+wB0zWS1W6HysQ4pJ5f7OuuzG8sHj44KTYqSf5hSHuGVXX5P7x9OiKT4zDyZ/rBsGJAehyxDRd3ErAP2D4IY1zmpzgEBkgx shichaogeng@gmail.com github公钥登陆github帐户。点击头像，然后 Settings -&gt; 左栏点击 SSH and GPG keys -&gt; 点击 New SSH key，向下面酱紫的界面 然后你复制上面的公钥内容，粘贴进“Key”文本域内。 title域，自己随便起个名字。点击 Add key。 完成以后，验证下这个key是不是正常工作123456[root@iZ2zehu64p5eabr7fp9t0iZ .ssh]# ssh -T git@github.comThe authenticity of host 'github.com (192.30.255.112)' can't be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added 'github.com,192.30.255.112' (RSA) to the list of known hosts.Hi shichaogeng! You've successfully authenticated, but GitHub does not provide shell access. 搞定！ Jenkins下载安装还是先下载 把下的war包，上传服务器，放到tomat下1cp jenkins.war /lab/dev/tomcat-jenkins/webapps/ 浏览器访问”http://47.94.170.46:8080/jenkins&quot;，出现如下界面 让你输入密匙，tomcat日志查到这个12345# 我的密匙1d4989effd224179a60709f5e5fbda3d# 密匙路径This may also be found at: /root/.jenkins/secrets/initialAdminPassword 输入密匙，就开始初始化，然后让你选择插件，我就选推荐安装，等吧（有点久）。。。 装插件继续装插件 单独添加两个插件 Maven Integration pluginPublish Over SSH 装完得重启（等。。。） Global Tool Configurationconfiguration jdk配置 git配置 maven配置 系统设置系统设置 Publish over SSH 设置 构建项目（只挑重要的截图啦）源码管理 构建 构建后操作 服务器上执行的bash脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/bin/bash #定义变量export JAVA_HOME=/lab/dev/jdk1.8.0_144TOMCAT_PORT=8081TOMCAT_HOME="/lab/dev/tomcat-server01"PROJECT="$1"SERVER="/lab/publish"#参数验证if [ $# -lt 1 ]; then echo "you must use like this : ./publish.sh &lt;projectname&gt; [tomcat port] [tomcat home dir]" exitfiif [ "$2" != "" ]; then TOMCAT_PORT=$2fiif [ "$3" != "" ]; then TOMCAT_HOME="$3"fiif [ ! -e "$SERVER"/"$PROJECT".war ]; then echo "$PROJECT".war "文件不存在，结束当前执行" exit;fi#关闭 tomcat "$TOMCAT_HOME"/bin/shutdown.sh#杀进程kill -9 $(lsof -i:'$TOMCAT_PORT' |awk '&#123;print $2&#125;'| tail -1)echo "tomcat shutdown" #替换war包 rm -rf "$TOMCAT_HOME"/webapps/"$PROJECT"*mv /lab/publish/$PROJECT.war "$TOMCAT_HOME"/webapps/$PROJECT.warecho "替换webapps下的war包"#备份项目 BAK_DIR=/lab/publish/bak/$PROJECT/`date +%Y%m%d`mkdir -p "$BAK_DIR"cp "$TOMCAT_HOME"/webapps/$PROJECT.war "$BAK_DIR"/"$PROJECT"_`date +%H%M%S`.war#启动 tomcat"$TOMCAT_HOME"/bin/startup.shecho "tomcat is starting,please try to access $PROJECT conslone url" 再记录下平时重启服务的命令1ps -ef | grep flm | grep -v grep | awk '&#123;print $2&#125;' | xargs kill -9 &amp;&amp; rm -r logs/* &amp;&amp; rm -rf work/* &amp;&amp; ./bin/startup.sh &amp;&amp; tail -f logs/catalina.out 差不多就酱紫，反正我是自动部署成功了，还有一些其他的功能，这里只完成基本的。有精力再弄吧!]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>Jenkins</tag>
        <tag>github</tag>
        <tag>jdk</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化（一）--- MySQL参数优化]]></title>
    <url>%2F2017%2F09%2F12%2FMySQL%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[一些没营养的东西，懒得弄了，有时间再补充下吧，先记录下。 操作系统的优化优化网络连接使用netstat查看连接1234567891011[root@localhost ~]# netstat -anActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 192.168.25.143:22 192.168.25.1:58527 ESTABLISHEDtcp 0 0 192.168.25.143:22 192.168.25.1:57553 ESTABLISHEDtcp 0 52 192.168.25.143:22 192.168.25.1:58078 ESTABLISHEDtcp 0 0 192.168.25.143:22 192.168.25.1:63590 ESTABLISHEDtcp6 0 0 :::3306 :::* LISTEN tcp6 0 0 :::22 :::* LISTEN tcp6 0 0 192.168.25.143:3306 192.168.25.139:48938 ESTABLISHED state参数：ESTABLISHED：正在通讯 TIME_WAIT: 主动关闭 CLOSE_WAIT:被动关闭time_wait会导致服务器error：Too Many Open files 优化思路：让服务器能够自动快速回收和重复利用Time_Wait资源 编辑vi /etc/sysctl.conf，加入的内容：12345678# 开启重用：允许将TIME_WAIT socket资源重新用于新的TCP连接，默认是0，关闭 net.ipv4.tcp_rw_reuse=1# 开启回收:net.ipv4.tcp_tw_recycle=1# 使配置生效：sysctl –p Open files查看用户默认打开的最大文件数，默认1024：12[root@localhost ~]# ulimit -n1024 修改打开文件数，vi /etc/profile，加入如下内容 1234ulimit –n 65535# 使配置生效source /etc/profile vi /etc/security/limits.conf，在末尾加入如下内容： 1234* soft nofile 65535* hard nofile 65535* soft nproc 65535* hard nproc 65535 MySQL对多核CPU利用特点MySQL5.1之后，支持多核心5.6,5.7都支持64核CPU 架构设计scale up ： 向上扩展，也叫纵向扩展scale out： 向外扩展，也叫水平扩展 内存使用建议：MySQL内存配置位物理内存的70%左右 MySQL配置优化大部分情况下使用innodb作为表存储引擎,以下参数配置在my.cnf中 innodb的缓冲池配置1innodb_buffer_pool_size 这对Innodb表来说非常重要。Innodb相比MyISAM表对缓冲更为敏感。MyISAM可以在默认的key_buffer_size设置下运行的可以，然而Innodb在默认的 innodb_buffer_pool_size设置下却跟蜗牛似的。由于Innodb把数据和索引都缓存起来，无需留给操作系统太多的内存，因此如果只需要用Innodb的话则可以设置它高达 70-80% 的可用内存。一些应用于 key_buffer 的规则有 — 如果你的数据量不大，并且不会暴增，那么无需把 innodb_buffer_pool_size 设置的太大了。 innodb log 缓存配置1innodb_log_buffer_size 此参数确定些日志文件所用的内存大小，以M为单位。缓冲区更大能提高性能，但意外的故障将会丢失数据.MySQL开发人员建议设置为1－8M之间 配置缓冲池个数1innodb_buffer_pool_instances 默认情况下只有一个 在提交事务的时候，是否刷新日志缓冲（重要，对性能影响较大）1innodb_flush_log_at_trx_commit 有3个值：0：不会主动触发日志缓冲写入磁盘1（默认）：每次提交事务的时候，同时会把日志缓冲刷新到磁盘2：每次提交事务的时候，会把日志缓冲刷新到磁盘，但是他不是同时进行的，而是每秒钟刷新一次 怎么配置考虑两个点： 考虑安全性：如果对数据安全性较高，配置成1 考虑性能：建议配置成2 理由：再高并发事务下，如果执行事务的同时就把缓存中刷新到磁盘，就会大量的对磁盘进行写操作，导致大量的IO innodb读写IO的线程数12innodb_read_io_threadsinnodb_write_io_threads 默认都是4个 独立表空间配置1innodb_file_per_table 默认是打开的 查询缓存1query_cache_size 参考可以找别人博客中的介绍，或者自己到官网去看具体配置 常用的sql写法和优化数据准备 为保证大数据操作执行速度，添加mysql参数配置 1234innodb_flush_log_at_trx_commit=2innodb_buffer_pool_instances=4innodb_buffer_pool_size=2048Minnodb_log_buffer_size=16M 重启服务 12[root@localhost mysql]# service mysqld restart;Redirecting to /bin/systemctl restart mysqld.service 插入数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051create database db5;use db5;/* 用户表 */drop table if exists users;create table users( id int primary key auto_increment, name varchar(20));insert into users(name) values ('A');insert into users(name) values ('B');insert into users(name) values ('C');insert into users(name) values ('D');insert into users(name) values ('E');insert into users(name) values ('F');insert into users(name) values ('G');insert into users(name) values ('H');insert into users(name) values ('I');insert into users(name) values ('J');/* 订单表 */drop table if exists orders;create table orders( id int primary key auto_increment,/*订单id*/ order_no varchar(20) not null,/*订单编号*/ title varchar(20) not null,/*订单标题*/ goods_num int not null,/*商品数量*/ money decimal(7,4) not null,/*订单金额*/ user_id int not null /*订单所属用户id*/)engine=innodb default charset=utf8 ;delimiter $$drop procedure if exists batch_orders $$create procedure batch_orders(in max int)begindeclare start int default 0;declare i int default 0;set autocommit = 0; while i &lt; max do set i = i + 1; insert into orders(order_no,title,goods_num,money,user_id) values (concat('NCS-',floor(1 + rand()*1000000000004 )),concat('订单title-',i),i%50,(100.0000+(i%50)),i%10); end while;commit;end $$delimiter ;/* 3百万数据*/call batch_orders(3000000); Max()在money上面加索引解决性能问题 12345678910111213141516171819mysql&gt; create index idx_money on orders(money);Query OK, 0 rows affected (16.46 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; explain select max(money) from orders\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: NULL partitions: NULL type: NULLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: NULL filtered: NULL Extra: Select tables optimized away1 row in set, 1 warning (0.00 sec) “Select tables optimized away”，介是啥意思呢，官方解释： For explains on simple count queries (i.e. explain select count(*) from people) the extra section will read “Select tables optimized away.” This is due to the fact that MySQL can read the result directly from the table internals and therefore does not need to perform the select. 意思就是记录已经保存了，不需要查询物理表或者索引，直接返回结果。 count()需求：分别查询出A用户和B用户各自的订单总数A B3 20 12345678910111213141516171819mysql&gt; create index idx_user_id on orders(user_id);Query OK, 0 rows affected (19.25 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; explain select count(case when user_id=1 then id end),count(case when user_id=2 then id end ) from orders\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: orders partitions: NULL type: indexpossible_keys: NULL key: idx_user_id key_len: 4 ref: NULL rows: 2987346 filtered: 100.00 Extra: Using index1 row in set, 1 warning (0.00 sec) limitlimit limit ?,? limit 555,5 limit 55555555,5 从rows可以看出来，limit的开始位置越大，必须检索的行就越多，就会对性能产生影响而且如果太大了，会产生using filesort 可以设置下面的参数来解决：12分配的排序的空间大小max_length_for_sort_data 默认为1024字节如果排序的字段的空间大于这个设置的值，就不会使用索引排序，而会使用using filesort可以设置大点，这样就不会产生文件内排序 行列转换行转列：name total_goods_numA 100B 20把上面的结果转换成下面的结果：A B100 20 SQL如下：1234567891011select sum(case when u.id=1 then goods_num end) as 'A',sum(case when u.id=2 then goods_num end) as 'B',sum(case when u.id=3 then goods_num end) as 'C',sum(case when u.id=4 then goods_num end) as 'D',sum(case when u.id=5 then goods_num end) as 'E',sum(case when u.id=6 then goods_num end) as 'F',sum(case when u.id=7 then goods_num end) as 'G',sum(case when u.id=8 then goods_num end) as 'H',sum(case when u.id=9 then goods_num end) as 'I',sum(case when u.id=10 then goods_num end) as 'J'from users u inner join orders o on u.id=o.user_id;]]></content>
      <categories>
        <category>MySQL优化</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FirewalldAndTelnet]]></title>
    <url>%2F2017%2F09%2F07%2FFirewalldAndTelnet%2F</url>
    <content type="text"><![CDATA[操作MySQL主从复制时候需要设定防火墙规则，决定还是总结记录一下。操作系统CentOs7 firewalld防火墙firewalld是centos7的一大特性，最大的好处有两个：支持动态更新，不用重启服务；第二个就是加入了防火墙的“zone”概念 firewalld的字符界面管理工具是 firewall-cmd firewalld默认配置文件有两个：/usr/lib/firewalld/ （系统配置）和 /etc/firewalld/ （用户配置） zone概念硬件防火墙默认一般有三个区，firewalld引入这一概念系统默认存在以下区域： drop：任何流入网络的包都被丢弃，不作出任何响应。只允许流出的网络连接。block：任何进入的网络连接都被拒绝，并返回 IPv4 的 icmp-host-prohibited 报文或者 IPv6 的 icmp6-adm-prohibited 报文。只允许由该系统初始化的网络连接。public：用以可以公开的部分。你认为网络中其他的计算机不可信并且可能伤害你的计算机。只允许选中的连接接入。external：用在路由器等启用伪装的外部网络。你认为网络中其他的计算机不可信并且可能伤害你的计算机。只允许选中的连接接入。dmz：用以允许隔离区（dmz）中的电脑有限地被外界网络访问。只接受被选中的连接。work：用在工作网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。home：用在家庭网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。internal：用在内部网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。 安装、运行、停止、禁用、重启firewalld 安装 1yum -y install firewalld firewall-config 启动 1systemctl start firewalld 查看状态 1systemctl status firewalld 或者 firewall-cmd --state 停止 1systemctl disable firewalld 禁用 1systemctl stop firewalld 更新防火墙规则(不会重启服务) 1firewall-cmd --reload 更新防火墙规则（会重启服务） 1firewall-cmd --complete-reload 配置firewalld 查看版本 1firewall-cmd --version 查看帮助 1firewall-cmd --help 查看区域信息 1firewall-cmd --get-active-zones 查询默认区域 1firewall-cmd --get-default-zone 设置默认区域 1firewall-cmd --set-default-zone=public 查看所有打开的端口 1firewall-cmd --zone=dmz --list-ports 查询端口是否启用 1firewall-cmd [--zone=&lt;zone&gt;] --query-port=&lt;port&gt;[-&lt;port&gt;]/&lt;protocol&gt; 添加指定端口 12firewall-cmd --zone=&lt;zone&gt; --add-port=&lt;port&gt;[-&lt;port&gt;]/&lt;protocol&gt; [--timeout=&lt;seconds&gt;]# 要使定义的协议永久生效，需要加一句--permanent，--zone不写则使用默认区域 移除允许的端口： 1firewall-cmd [--zone=&lt;zone&gt;] --remove-port=&lt;port&gt;[-&lt;port&gt;]/&lt;protocol&gt; 参考资料 官方文档 wiki 安装telnet 先检查CentOS7.0是否已经安装以下两个安装包:telnet-server、xinetd。 12[root@localhost sysconfig]# rpm -qa telnet-server[root@localhost sysconfig]# rpm -qa xinetd 如果没有安装，则先安装。安装命令 1234567891011121314151617[root@localhost ~]# yum list | grep telnettelnet.x86_64 1:0.17-60.el7 base telnet-server.x86_64 1:0.17-60.el7 base [root@localhost ~]# yum -y install telnet-server.x86_64[root@localhost ~]# yum -y install telnet.x86_64[root@localhost ~]# yum list |grep xinetdxinetd.x86_64 2:2.3.15-13.el7 base [root@localhost ~]# yum -y install xinetd.x86_64``` 1. 安装完成后，将xinetd服务加入开机自启动```bash[root@localhost ~]# systemctl enable xinetd.service 最后，启动以上两个服务即可： 12[root@localhost ~]# systemctl start telnet.socket[root@localhost ~]# systemctl start xinetd 将telnet服务加入开机自启动 12[root@localhost ~]# systemctl enable telnet.socketCreated symlink from /etc/systemd/system/sockets.target.wants/telnet.socket to /usr/lib/systemd/system/telnet.socket. 使用的时候，用telnet测试下端口是否可以访问 1234567891011121314151617181920[root@localhost ~]# ping 192.168.25.143PING 192.168.25.143 (192.168.25.143) 56(84) bytes of data.64 bytes from 192.168.25.143: icmp_seq=1 ttl=64 time=0.529 ms64 bytes from 192.168.25.143: icmp_seq=2 ttl=64 time=0.473 ms64 bytes from 192.168.25.143: icmp_seq=3 ttl=64 time=0.473 ms64 bytes from 192.168.25.143: icmp_seq=4 ttl=64 time=0.496 ms^C--- 192.168.25.143 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3001msrtt min/avg/max/mdev = 0.473/0.492/0.529/0.035 ms# 网络连接成功，下面测试端口[root@localhost ~]# telnet 192.168.25.143 3306Trying 192.168.25.143...Connected to 192.168.25.143.Escape character is '^]'.N5.7.14-log gBI8)"ÿ󿾂uc49BQ,emysql_native_password123456!#08S01Got packets out of orderConnection closed by foreign host.]]></content>
      <categories>
        <category>Linux设置</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化（一）--- MySQL主从复制]]></title>
    <url>%2F2017%2F08%2F30%2FMySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[MySQL Replication是MySQL官方提供的主从同步方案，用于将一个MySQL实例的数据，同步到另一个实例中。Replication为保证数据安全做了重要保证，也是现在运用最广的MySQL容灾方案。Replication用两个或以上的实例搭建MySQL主从复制集群，提供单点写入，多点读取的服务，实现了读的scale out。 主从复制的原理MySQL内建的复制功能是构建大型，高性能应用程序的基础。将MySQL的数据分布到多个系统上去，这种分布的机制，是通过将MySQL的某一台主机的数据复制到其它主机（slaves）上，并重新执行一遍来实现的。复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。主服务器将更新写入二进制日志文件，并维护文件的一个索引以跟踪日志循环。这些日志可以记录发送到从服务器的更新。当一个从服务器连接主服务器时，它通知主服务器从服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，然后封锁并等待主服务器通知新的更新。 MySQL主从复制相关有3个线程 slave上的I/O线程：向master请求数据 master上的Binlog Dump线程：读取binlog事件并把数据发送给slave上的I/O线程 slave上的SQL线程：读取中继日志并执行，更新数据库 下图描述了复制的过程： 从上图分析的主从复制的3个步骤： master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）。 在每个事务更新数据完成之前，master在二日志记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。 slave将master的binary log events拷贝到它的中继日志(relay log)。 首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，然后开始binlog dump process。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。 slave重做中继日志中的事件，将改变反映它自己的数据。该过程的第一部分就是master记录二进制日志。 SQL slave thread（SQL从线程）处理该过程的最后一步。SQL线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致。只要该线程与I/O线程保持一致，中继日志通常会位于OS的缓存中，所以中继日志的开销很小。 复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。 主从复制的配置 准备环境有两台MySQL数据库服务器master和slave，master为主服务器，slave为从服务器，初始状态时，通过MySQL备份机制令master和slave中的数据信息相同，当Master中的数据发生变化时，slave也跟着发生相应的变化，使得master和slave的数据信息同步，达到备份的目的。要点：负责在主、从服务器传输各种修改动作的媒介是主服务器的二进制变更日志，这个日志记载着需要传输给从服务器的各种修改动作。因此，主服务器必须激活二进制日志功能。从服务器必须具备足以让它连接主服务器并请求主服务器把二进制变更日志传输给它的权限。 环境：master和slave的MySQL数据库版本同为5.7.14操作系统：CentOs 3.10.0-514.el7.x86_64IP地址：master=’192.168.25.143’,slave=’192.168.25.138’ 首先保证两台机器网络上互通然后对端口进行防火墙设置。（防火墙设置及Telnet安装） 123456789101112131415161718192021# 开启端口[root@localhost ~]# firewall-cmd --zone=public --add-port=3306/tcp --permanentsuccess# 不需重启服务重新加载防火墙规则[root@localhost ~]# firewall-cmd --reloadsuccess# 查询端口是否启用：[root@localhost ~]# firewall-cmd --zone=public --query-port=3306/tcpyes# 使用telnet测试端口链接[root@localhost ~]# telnet 192.168.25.143 3306Trying 192.168.25.143...Connected to 192.168.25.143.Escape character is '^]'.N5.7.14-log gBI8)"ÿ󿾂uc49BQ,emysql_native_password123456!#08S01Got packets out of orderConnection closed by foreign host. 真实场景肯定是已经有很多历史数据在老数据库中，而且服务器正在运行并对外提供服务，我们模拟下这个环境。在master机数据库上创建库表。 123456789101112mysql&gt; create database db1;Query OK, 1 row affected (0.00 sec)mysql&gt; use db1;Database changedmysql&gt; create table t1(id int);Query OK, 0 rows affected (0.01 sec)mysql&gt; insert into t1 values(1),(2),(3);Query OK, 3 rows affected (0.00 sec)Records: 3 Duplicates: 0 Warnings: 0 配置master先要复制master上已有的数据到slave上，而且master服务不能停，这就需要基于二进制日志来操作。在master上开启二进制日志。包括打开二进制日志，指定唯一的servr-id。 修改my.cnf,添加如下配置（设置服务id，开启二进制日志） 12server-id=1log-bin=/var/lib/mysql/mysql-bin 重启服务 12[root@localhost ~]# service mysqld restart;Redirecting to /bin/systemctl restart mysqld.service 查看master二进制日志状态 12345678mysql&gt; show master status;+------------------+----------+--------------+--------------- ---+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+--------------- ---+-------------------+| mysql-bin.000001 | 154 | | | |+------------------+----------+--------------+--------------- ---+-------------------+1 row in set (0.00 sec)# 注意，position位置就是二进制日志复制的起点。 在/var/lib/mysql文件夹下生成如下二进制日志文件 1-rw-r-----. 1 mysql mysql 154 8月 30 22:07 mysql-bin.000001 查看二进制文件的内容 1[root@localhost mysql]# mysqlbinlog --no-defaults mysql-bin.000001 如果想要清空master二进制日志 1reset master; 拷贝数据关停master服务器，将master中的数据拷贝到slave服务器中，使得master和slave中的数据同步。 备份 1[root@localhost charsets]# mysqldump -uroot -p --single-transaction --master-data=2 --triggers --routines --all-databases &gt; ~/abc.sql 生成备份文件如下 1-rw-r--r--. 1 root root 767934 8月 30 23:01 abc.sql 查看此文件，注意看MASTER_LOG_POS 12-- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=154;# 它标记了从154位置之前的数据已经备份到abc.sql中，以后的数据要从154开始，我们会在slave里用到。 在slave上操作，把abc.sql从master远程拷贝到salve 123456789[root@localhost ~]# scp root@192.168.25.143:/root/abc.sql ~The authenticity of host '192.168.25.143 (192.168.25.143)' can't be established.ECDSA key fingerprint is 1f:eb:16:4e:2e:34:e1:7f:79:a4:b2:e7:51:b7:83:9d.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '192.168.25.143' (ECDSA) to the list of known hosts.root@192.168.25.143's password: Permission denied, please try again.root@192.168.25.143's password: abc.sql 100% 750KB 749.9KB/s 00:00 在slave上执行abc.sql（重定向） 12[root@localhost ~]# mysql -uroot -p &lt; ~/abc.sqlEnter password: 查看slave数据库，发现导入成功 1234567891011mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || db1 || mysql || performance_schema || sys |+--------------------+5 rows in set (0.00 sec) 这时备份时点的数据已经拷贝到从服务器上了 创建复制帐号在master的数据库中建立一个备份帐户：每个slave使用标准的MySQL用户名和密码连接master。进行复制操作的用户会授予REPLICATION SLAVE权限。用户名的密码都会存储在文本文件master.info中。 创建授权用户 123456789? grant# 上面是查看授权语法mysql&gt; grant replication slave on *.* to 'slave'@'192.168.25.138' identified by 'Gengsc_123';Query OK, 0 rows affected, 1 warning (0.00 sec)# 注意上面的密码因为密码策略的原因要大小写字母特殊符号数字同时具备（我记得是这样）mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 查看是否成功 12345mysql&gt; select * from mysql.user where host = '192.168.25.138'\G;*************************** 1. row *************************** Host: 192.168.25.138 User: slave Repl_slave_priv: Y 执行完授权后，我们来查看下master状态 12345678mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000005 Position: 154 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec) 配置slave配置在下面，其中，server_id：是必须的，而且唯一。slave：没有必要开启二进制日志，但是在一些情况下，必须设置，例如，如果slave为其他slave的master，必须设置log-bin。在这里，我们开启二进制日志。relay_log：配置中继日志。log_slave_updates：表示slave将复制事件写进自己的二进制日志。有些人开启了slave的二进制日志，却没有设置log_slave_updates，这是一种错误的配置。原因：从库开启log-bin参数，如果直接往从库写数据，是可以记录log-bin日志的，但是从库通过I0线程读取主库二进制日志文件，然后通过SQL线程写入的数据，是不会记录binlog日志的。也就是说从库从主库上复制的数据，是不写入从库的binlog日志的。所以从库做为其他从库的主库时需要在配置文件中添加log-slave-updates参数。 编辑my.cnf 1234server-id=2log-bin=/var/lib/mysql/mysql-binrelay_log=/var/lib/mysql/mysql-relay-binlog_slave_updates=1 重启MySQL服务 12[root@localhost ~]# service mysqld restart;Redirecting to /bin/systemctl restart mysqld.service 启动slave接下来就是让slave连接master，并开始重做master二进制日志中的事件。使用CHANGE MASTER TO语句不需要停止服务器。如下： 如果之前这台slave已经做过从机，先停止主从复制 1stop slave; 如果之前这台slave已经做过从机，先清空之前的relay-log 1reset slave; 为slave指定master 123456789mysql&gt; change master to master_host='192.168.25.143',-&gt; master_user='slave',-&gt; master_password='Gengsc_123',-&gt; master_log_file='mysql-bin.000004',-&gt; master_log_pos=154;Query OK, 0 rows affected, 2 warnings (0.03 sec)# 具体命令参数可以通过下面的命令查看(里面有例子)? change master to 启动Slave开始复制 12mysql&gt; start slave;Query OK, 0 rows affected (0.01 sec) 检查主从同步状态，主要查看io线程和sql线程状态(Slave_IO_Running和Slave_SQL_Running) 123456789101112131415mysql&gt; show slave status\G*************************** 1. row ***************************Slave_IO_State: Waiting for master to send eventMaster_Host: 192.168.25.143Master_User: slaveMaster_Port: 3306Connect_Retry: 60Master_Log_File: mysql-bin.000004Read_Master_Log_Pos: 2167Relay_Log_File: localhost-relay-bin.000002Relay_Log_Pos: 2333Relay_Master_Log_File: mysql-bin.000004Slave_IO_Running: YesSlave_SQL_Running: YesReplicate_Do_DB: 常见错误：Slave_IO_Running=NO：检查change master语句中ip log_file log_pos等所有参数Slave_SQL_Running=NO：因为主从同步需要创建用户，查看当前登录用户是否有此权限。可以查看show slave status查看错误日志，一般都是表不存在就操作DML啥的。 查看线程你可已查看master和slave上的线程状态 在master上，你可以看见slave的io线程创建的链接（dump线程） 12345678910mysql&gt; show processlist\G;*************************** 1. row *************************** Id: 4 User: slave Host: 192.168.25.138:53396 db: NULLCommand: Binlog Dump Time: 172 State: Master has sent all binlog to slave; waiting for more updates Info: NULL 在slave上，你可以看到io线程状态和sql线程状态 12345678910111213141516171819mysql&gt; show processlist\G;*************************** 1. row *************************** Id: 4 User: system user Host: db: NULLCommand: Connect Time: 599068 State: Waiting for master to send event Info: NULL*************************** 2. row *************************** Id: 5 User: system user Host: db: NULLCommand: Connect Time: 598967 State: Slave has read all relay log; waiting for more updates Info: NULL 验证主从同步 在master中操作 123456789101112mysql&gt; create database db2;Query OK, 1 row affected (0.01 sec)mysql&gt; use db2;Database changedmysql&gt; create table user(id int,name varchar(20));Query OK, 0 rows affected (0.03 sec)mysql&gt; insert into user values (1,'张三'),(2,'李四');Query OK, 2 rows affected (0.09 sec)Records: 2 Duplicates: 0 Warnings: 0 在slave中查看 1234567891011121314151617181920212223242526mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || db1 || db2 || mysql || performance_schema || sys |+--------------------+6 rows in set (0.00 sec)mysql&gt; use db2;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select * from user;+------+--------+| id | name |+------+--------+| 1 | 张三 || 2 | 李四 |+------+--------+2 rows in set (0.00 sec) 查看二进制日志变化 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 开始状态，此时位置是2509mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000005 Position: 2509 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec)# 执行dml sqlmysql&gt; update user set name = '王舞' where id = 3;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0# 再次查看master状态，position变了mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000005 Position: 2785 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec)# 查看bin-log日志增量[root@localhost mysql]# mysqlbinlog --no-defaults --start-position=2509 --stop-position=2789 --base64-output=decode-rows -v mysql-bin.000005BEGIN/*!*/;# at 2645#170908 11:50:13 server id 1 end_log_pos 2694 CRC32 0xfacee981 Table_map: `db2`.`user` mapped to number 114# at 2694#170908 11:50:13 server id 1 end_log_pos 2754 CRC32 0x9d44a8e3 Update_rows: table id 114 flags: STMT_END_F### UPDATE `db2`.`user`### WHERE### @1=3### @2='王五'### SET### @1=3### @2='王舞'# at 2754#170908 11:50:13 server id 1 end_log_pos 2785 CRC32 0xd7a8cc0a Xid = 707COMMIT/*!*/; 大功告成。 一致性问题数据同步其实可以使用冷备份的方案，但冷备存在以下问题： 1. 冷备时要停止mysql服务 2. 冷备都是基于某一确定的时间点，如果备份之后的一段时间，数据遭到破坏，那么这段时间的数据将无法恢复。 但是主从复制就能保证数据一致性吗，使用复制技术实现读写分离，主库插入以后，马上去从库中读数据，主从同步延时的原因可能得到不一致的结果。 产生延迟的几个因素： 1. 网络状态 2. 大并发写操作特别多。 3. 读服务器压力过大 为解决一致性问题，看这里吧戳我，人家写的挺好，懒的写了。 binlog内容解析开这章的意义本来在于向看懂binlog中的内容，但是但是感觉知识好多啊 复制的类型首先，还是先看下mysql支持哪几种复制方式吧 Statement-Based Replication在主服务器上执行的SQL语句，在从服务器上执行同样的语句。MySQL默认采用Statement-Based复制，效率比较高。一旦发现没法精确复制时， 会自动选着Row-Based复制。 MySQL 5.0及之前的版本仅支持基于语句的复制，这在数据库并不常见。master记录下改变数据的查询，然后，slave从中继日志中读取事件，并执行它，这些SQL语句与master执行的语句一样。 这种方式的优点就是实现简单。此外，基于语句的复制的二进制日志可以很好的进行压缩，而且日志的数据量也较小，占用带宽少——例如，一个更新GB的数据的查询仅需要几十个字节的二进制日志。而mysqlbinlog对于基于语句的日志处理十分方便。 但是，基于语句的复制并不是像它看起来那么简单，因为一些查询语句依赖于master的特定条件，例如，master与slave可能有不同的时间。所以，MySQL的二进制日志的格式不仅仅是查询语句，还包括一些元数据信息，例如，当前的时间戳。即使如此，还是有一些语句，比如，CURRENT USER函数，不能正确的进行复制。此外，存储过程和触发器也是一个问题。 另外一个问题就是基于语句的复制必须是串行化的。这要求大量特殊的代码，配置，例如InnoDB的next-key锁等。并不是所有的存储引擎都支持基于语句的复制。 Row-Based Replication把改变的内容复制过去，而不是把命令在从服务器上执行一遍，从mysql5.0开始支持 MySQL增加基于记录的复制，在二进制日志中记录下实际数据的改变，这与其它一些DBMS的实现方式类似。这种方式有优点，也有缺点。优点就是可以对任何语句都能正确工作，一些语句的效率更高。主要的缺点就是二进制日志可能会很大，而且不直观，所以，你不能使用mysqlbinlog来查看二进制日志。 对于一些语句，基于记录的复制能够更有效的工作，如：1234mysql&gt; INSERT INTO summary_table(col1, col2, sum_col3) -&gt; SELECT col1, col2, sum(col3) -&gt; FROM enormous_table -&gt; GROUP BY col1, col2; 假设，只有三种唯一的col1和col2的组合，但是，该查询会扫描原表的许多行，却仅返回三条记录。此时，基于记录的复制效率更高。 另一方面，下面的语句，基于语句的复制更有效：1mysql&gt; UPDATE enormous_table SET col1 = 0; 此时使用基于记录的复制代价会非常高。 Mixed-Based Replication默认采用Statement-Based复制，一旦发现基于语句的无法精确的复制时，就会采用Row-Based复制。 由于两种方式不能对所有情况都能很好的处理，所以，MySQL 5.1支持在基于语句的复制和基于记录的复制之前动态交换。你可以通过设置session变量binlog_format来进行控制。 Binary Logging Formats这一节，我们尝试查看bin-log的内容，解读bin-log中的重要信息 binlog_format=statement环境准备1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465mysql&gt; set binlog_format = 'statement';Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like 'binlog_format'\G;*************************** 1. row ***************************Variable_name: binlog_format Value: STATEMENT1 row in set (0.01 sec)# 关闭当前的二进制日志文件并创建一个新文件，新的二进制日志文件的名字在当前的二进制文件的编号上加1mysql&gt; flush logs;Query OK, 0 rows affected (0.02 sec)mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000007 Position: 154 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec)# 此时记录下log_file=mysql-bin.000007,log_pos=154mysql&gt; create table t1 ( -&gt; id int auto_increment primary key, -&gt; name varchar(20) not null, -&gt; uuids varchar(45) not null -&gt; ) engine = InnoDB;Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into t1(name,uuids) values('tom',uuid());Query OK, 1 row affected, 1 warning (0.01 sec)# 发现有一个警告# 查看警告mysql&gt; show warnings\G;*************************** 1. row *************************** Level: Note Code: 1592Message: Unsafe statement written to the binary log using statement format since BINLOG_FORMAT = STATEMENT. Statement is unsafe because it uses a system function that may return a different value on the slave.1 row in set (0.00 sec)# 提示statement方式使用uuid()可能会导致从库数据与主库数据不一样mysql&gt; update t1 set name = 'jerry' where id = 1;Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; insert into t1(name,uuids) values('jack',uuid());Query OK, 1 row affected, 1 warning (0.01 sec)mysql&gt; delete from t1 where id = 2;Query OK, 1 row affected (0.01 sec)mysql&gt; drop table t1;Query OK, 0 rows affected (0.02 sec)mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000007 Position: 1539 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec)# 此时记录下log_file=mysql-bin.000007,log_pos=1539 分析日志内容DDL跟DML操作执行后，得到当前的binlog文件是mysql-bin.000007，开始的position是154 ，结束的position是1539，所以直接读取整个文件从position=154到1539之间的操作记录，使用mysqlbinlog读取。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118[root@localhost mysql]# mysqlbinlog --no-defaults --start-position=154 --stop-position=1539 mysql-bin.000007# at 154#170908 15:30:24 server id 1 end_log_pos 219 CRC32 0x3a8142fc Anonymous_GTID last_committed=0 sequence_number=1SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 219#170908 15:30:24 server id 1 end_log_pos 296 CRC32 0x501abf9e Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855824/*!*/;SET @@session.pseudo_thread_id=24/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1436549152/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\C utf8 *//*!*/;SET @@session.character_set_client=192,@@session.collation_connection=192,@@session.collation_server=192/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 296--------------------------------------------------------------# at 328#170908 15:30:24 server id 1 end_log_pos 328 CRC32 0xcc1e8509 IntvarSET INSERT_ID=1/*!*/;#170908 15:30:24 server id 1 end_log_pos 447 CRC32 0x58f1bfa0 Query thread_id=24 exec_time=0 error_code=0use `db2`/*!*/;SET TIMESTAMP=1504855824/*!*/;insert into t1(name,uuids) values('tom',uuid())/*!*/;# at 447#170908 15:30:24 server id 1 end_log_pos 478 CRC32 0x37e68e4b Xid = 731COMMIT/*!*/;--------------------------------------------------------------# at 478#170908 15:31:32 server id 1 end_log_pos 543 CRC32 0x0e416741 Anonymous_GTID last_committed=1 sequence_number=2SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 543#170908 15:31:32 server id 1 end_log_pos 620 CRC32 0x58bc6f80 Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855892/*!*/;BEGIN/*!*/;# at 620#170908 15:31:32 server id 1 end_log_pos 733 CRC32 0x2dd8d9a4 Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855892/*!*/;update t1 set name = 'jerry' where id = 1/*!*/;# at 733#170908 15:31:32 server id 1 end_log_pos 764 CRC32 0xa3ab9727 Xid = 733COMMIT/*!*/;--------------------------------------------------------------# at 764#170908 15:32:46 server id 1 end_log_pos 829 CRC32 0xa0d31904 Anonymous_GTID last_committed=2 sequence_number=3SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 829#170908 15:32:46 server id 1 end_log_pos 906 CRC32 0xfa941cd4 Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855966/*!*/;BEGIN/*!*/;# at 906# at 938#170908 15:32:46 server id 1 end_log_pos 938 CRC32 0xd52d2aa8 IntvarSET INSERT_ID=2/*!*/;#170908 15:32:46 server id 1 end_log_pos 1058 CRC32 0x64a1e64e Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855966/*!*/;insert into t1(name,uuids) values('jack',uuid())/*!*/;# at 1058#170908 15:32:46 server id 1 end_log_pos 1089 CRC32 0xa1d6ce2d Xid = 736COMMIT/*!*/;--------------------------------------------------------------# at 1089#170908 15:33:03 server id 1 end_log_pos 1154 CRC32 0x5d070075 Anonymous_GTID last_committed=3 sequence_number=4SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 1154#170908 15:33:03 server id 1 end_log_pos 1231 CRC32 0x7778ba6a Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855983/*!*/;BEGIN/*!*/;# at 1231#170908 15:33:03 server id 1 end_log_pos 1330 CRC32 0xd2a967f2 Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855983/*!*/;delete from t1 where id = 2/*!*/;# at 1330#170908 15:33:03 server id 1 end_log_pos 1361 CRC32 0x5a49cde4 Xid = 737COMMIT/*!*/;-----------------------------------------------------------# at 1361#170908 15:33:21 server id 1 end_log_pos 1426 CRC32 0xf7074dba Anonymous_GTID last_committed=4 sequence_number=5SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 1426#170908 15:33:21 server id 1 end_log_pos 1539 CRC32 0xbe802308 Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504856001/*!*/;DROP TABLE `t1` /* generated by server *//*!*/;SET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 是不是好多，看的眼晕。但是我相信耐心的你一定可以看明白的，我已经把每个事物中间用间隔线分开处理。比如第一个事物insert（你可能奇怪，第一个为什么不是create呢，哈哈，我是创建表之后执行的flush logs，所以并未把create语句记录到当前的bin-log，应该在上一个编码的bin-log中）是用明文记录在bin-log中的。 结论当binlog_format=statement的时候，DDL及DML都是明文按照SQL记录存储对复制的影响。 某系统参数由于在不同时间不同服务器，执行结果不一致，这会给复制的主从带来数据不一致的严重影响。如LOAD_FILE()，UUID()，USER()，FOUND_ROWS()，defaults，now()及用户自定义函数等。 同步到从库的binlog都是SQL语句，在slave端再跑一遍，假设一个update语句性能很差，但是最终只修改了一行数据，那么在从库也会同样执行这个性能差的SQL，而对于 insert tb select * from tbname 这类型的SQL，则只需要同步一行SQL语句即可。 binlog_format=row环境准备123456789101112131415161718192021222324252627282930313233343536373839mysql&gt; set binlog_format = 'row';Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like '%binlog_format%'\G;*************************** 1. row ***************************Variable_name: binlog_format Value: ROW1 row in set (0.01 sec)mysql&gt; flush logs;Query OK, 0 rows affected (0.02 sec)mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000008 Position: 154 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec)mysql&gt; create table t2 ( -&gt; id int auto_increment primary key, -&gt; name varchar(20) not null, -&gt; uuids varchar(45) not null -&gt; ) engine = InnoDB;Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into t2(name,uuids) values ('jack',uuid());Query OK, 1 row affected (0.01 sec)mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000008 Position: 714 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec) 分析日志1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071[root@localhost mysql]# mysqlbinlog --no-defaults --start-position=154 --stop-position=714 mysql-bin.000008/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#170908 16:20:01 server id 1 end_log_pos 123 CRC32 0x6f2a48ed Start: binlog v 4, server v 5.7.14-log created 170908 16:20:01# Warning: this binlog is either in use or was not closed properly.BINLOG 'sVKyWQ8BAAAAdwAAAHsAAAABAAQANS43LjE0LWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQAAe1IKm8='/*!*/;# at 154#170908 16:20:52 server id 1 end_log_pos 219 CRC32 0x73d82462 Anonymous_GTID last_committed=0 sequence_number=1SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;------------------------------------------------------------# at 219#170908 16:20:52 server id 1 end_log_pos 415 CRC32 0xdb01c4e3 Query thread_id=24 exec_time=0 error_code=0use `db2`/*!*/;SET TIMESTAMP=1504858852/*!*/;SET @@session.pseudo_thread_id=24/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1436549152/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\C utf8 *//*!*/;SET @@session.character_set_client=192,@@session.collation_connection=192,@@session.collation_server=192/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;create table t2 (id int auto_increment primary key,name varchar(20) not null,uuids varchar(45) not null) engine = InnoDB/*!*/;------------------------------------------------------------# at 415#170908 16:21:34 server id 1 end_log_pos 480 CRC32 0x0dff2820 Anonymous_GTID last_committed=1 sequence_number=2SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 480#170908 16:21:34 server id 1 end_log_pos 551 CRC32 0x37c52cbb Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504858894/*!*/;BEGIN/*!*/;# at 551#170908 16:21:34 server id 1 end_log_pos 601 CRC32 0xecbd95aa Table_map: `db2`.`t2` mapped to number 148# at 601#170908 16:21:34 server id 1 end_log_pos 683 CRC32 0x69b6b96b Write_rows: table id 148 flags: STMT_END_FBINLOG 'DlOyWRMBAAAAMgAAAFkCAAAAAJQAAAAAAAEAA2RiMgACdDIAAwMPDwQ8AIcAAKqVvew=DlOyWR4BAAAAUgAAAKsCAAAAAJQAAAAAAAEAAgAD//gBAAAABGphY2skYmEwYzlmYjctOTQ2ZS0xMWU3LTk5NTQtMDAwYzI5YzM2ODBla7m2aQ=='/*!*/;# at 683#170908 16:21:34 server id 1 end_log_pos 714 CRC32 0xd096ef31 Xid = 747COMMIT/*!*/;--------------------------------------------------------------SET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 解密发现在binlog_format=row的情况下，DDL语句为明文存储，而DML语句都是密文存储，我们利用mysqlbinlog的参数反解来看看 原来是酱紫的 1234BINLOG 'DlOyWRMBAAAAMgAAAFkCAAAAAJQAAAAAAAEAA2RiMgACdDIAAwMPDwQ8AIcAAKqVvew=DlOyWR4BAAAAUgAAAKsCAAAAAJQAAAAAAAEAAgAD//gBAAAABGphY2skYmEwYzlmYjctOTQ2ZS0xMWU3LTk5NTQtMDAwYzI5YzM2ODBla7m2aQ== 反解 1[root@localhost mysql]# mysqlbinlog --no-defaults --start-position=154 --stop-position=714 --base64-output=decode-rows -v mysql-bin.000008 反解之后是酱紫的 12345### INSERT INTO `db2`.`t2`### SET### @1=1### @2='jack'### @3='ba0c9fb7-946e-11e7-9954-000c29c3680e' 结论当binlog_format=row的时候，其他参数默认，DDL明文存储SQL脚本，DML都是加密存储且存储的是每一行的行记录修改情况对复制的影响，它是最安全的同步设置。 同步到从库的binlog都是按行记录修改的SQL，所以假设一个update语句性能很差，但是最终只修改了一行数据，那么在从库不需要执行这个性能差的SQL，只需要直接执行行记录的修改结果即可（注意，使用基于row格式复制的实例，请给所有表格添加主键或者唯一索引，不然每一行记录的修改都需要全表扫，会导致从库性能非常差而且可能延时较长）而对于 update t2 set name = ‘rose’这类型的SQL，statment格式的只需要同步一条sql，但是row的话，则需要同步所有行记录。 binlog_format=mixed理解完statement跟row模式后，mixed混合模式就好理解了。 mixed模式下，大多数情况下，是以statement格式记录binlog日志，当隔离级别为RC模式的时候，则修改为row模式记录。或者语句中使用uuid()或者auto_increment这样的函数的时候，使用row模式记录。 Replication Filters复制过滤可以让你只复制服务器中的一部分数据。有两种复制过滤：在master上过滤二进制日志中的事件；在slave上过滤中继日志中的事件。 my.cnf中配置过滤条件 在master中 12345# 忽略复制的库，也就是不需要复制test库binlog-ignore-db=test# 需要复制的库binlog-do-db=test 在slave中配置 1234replicate-ignore-db=testreplicate-do-db=testreplicate-do-table=t1replicate-ignore-table=t1 注意：一般配置这种过滤规则，在slave中比较合适，因为在master上设置replicate_do_db或replicate_ignore_db时，任何不涉及到数据库相关的写操作都不会被记录到二进制日志当中，那么会造成主服务器上的二进制日志不完整，一旦将来数据库崩溃，不能做及时点还原，所以建议在从服务器上设置，尽管会浪费大量网络IO和磁盘IO。 若只想复制某个库，只需在slave的my.cnf配置文件中[mysqld]段中加一行replicate_do_db = db_name即可。若只想复制某张表，只需在slave的my.cnf配置文件中[mysqld]段中加一行replicate_do_db = tb_name即可。若想使用通配符，则使用replicate_wild_dotable = db[%]，%表示任意长度任意字符，_表示任意单个字符。 在线调整复制的过滤规则在slave中添加过滤规则 停止slave中的SQL_Thread 1stop slave sql_thread; 配置过滤规则 12345678# 过滤多个表，用逗号隔开CHANGE REPLICATION FILTER REPLICATE_DO_DB=(db1,db2);CHANGE REPLICATION FILTER REPLICATE_IGNORE_DB=(db1,db2);CHANGE REPLICATION FILTER REPLICATE_DO_TABLE=(db1.t1);CHANGE REPLICATION FILTER REPLICATE_IGNORE_TABLE=(db2.t2);CHANGE REPLICATION FILTER REPLICATE_WILD_DO_TABLE=('db.t%');CHANGE REPLICATION FILTER REPLICATE_WILD_IGNORE_TABLE=('db%.a%');CHANGE REPLICATION FILTER REPLICATE_REWRITE_DB=((from_db, to_db)); 重启slave中的SQL_Thread 1start slave sql_thread; 清除配置规则 停止slave中的SQL_Thread 1stop slave sql_thread; 配置过滤规则 12change replication filter replicate_ignore_db=();change replication filter replicate_ignore_table=(); 重启slave中的SQL_Thread 1start slave sql_thread; Multi-source ReplicationMySQL 5.7已经开始支持了多源复制，MySQL5.7之前只能实现一主一从、一主多从或者多主多从的复制，如果想实现多主一从的复制，只好使用MariaDB，但是MariaDB又与官方的MySQL版本不兼容的，在MySQL 5.7版本已经可以实现多主一从的复制了。 多源复制应用多源复制说白了就是一个从服务器从多个主服务器中拷贝数据，那它到底啥用呢： 在从服务器进行数据汇总，如果我们的主服务器进行了分库分表的操作，为了实现后期的一些数据统计功能，往往需要把数据汇总在一起再统计。 如果我们想在从服务器时时对主服务器的数据进行备份，在MySQL 5.7之前每一个主服务器都需要一个从服务器，这样很容易造成资源浪费，同时也加大了DBA的维护成本，但MySQL5.7引入多源复制，可以把多个主服务器的数据同步到一个从服务器进行备份。 多源复制搭建环境master和slave的MySQL数据库版本同为5.7.14操作系统：CentOs 3.10.0-514.el7.x86_64IP地址：master-1=’192.168.25.143’master-2=’192.168.25.138’slave=’192.168.25.139’ 具体操作参考前面的吧：环境准备配置master 创建复制账号 在master_1上 12345mysql&gt; grant replication slave on *.* to 'rep_139'@'192.168.25.139' identified by 'Gengsc_123';Query OK, 0 rows affected, 1 warning (0.05 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.02 sec) 在master_2上 12345mysql&gt; grant replication slave on *.* to 'rep_139'@'192.168.25.139' identified by 'Gengsc_123';Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.01 sec) 配置slave 配置二进制日志详细戳我 文件存储改为表存储，修改my.cnf，详细参数 123456master_info_repository=TABLErelay_log_info_repository=TABLE# 别忘了重启加载配置[root@localhost ~]# service mysqld restart;Redirecting to /bin/systemctl restart mysqld.service 可以导入历史数据了，数据备份 启动slave（FOR CHANNEL ‘CHANNEL_NAME’） 在slave中指定master 1234567# master_1，注意后面的"for channel 'master_1'"mysql&gt; change master to master_host='192.168.25.143',master_user='rep_139',master_password='Gengsc_123',master_log_file='mysql-bin.000001',master_log_pos=154 for channel 'master_1';Query OK, 0 rows affected, 2 warnings (0.09 sec)# master_2mysql&gt; change master to master_host='192.168.25.138',master_user='rep_139',master_password='Gengsc_123',master_log_file='mysql-bin.000001',master_log_pos=154 for channel 'master_2';Query OK, 0 rows affected, 2 warnings (0.04 sec) 启动slave 123456# 可以直接start slave开启所有，也可以像下面一样单独启动mysql&gt; start slave for channel 'master_1';Query OK, 0 rows affected (0.38 sec)mysql&gt; start slave for channel 'master_2';Query OK, 0 rows affected (0.02 sec) 查看同步状态 1234567891011121314151617181920212223242526272829# 可以查看所有，也可用for channel 'channel_name'单独查看mysql&gt; show slave status\G;*************************** 2. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.25.143 Master_User: rep_139 Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 154 Relay_Log_File: mysql-relay-bin-master_1.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes*************************** 3. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.25.138 Master_User: rep_139 Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 154 Relay_Log_File: mysql-relay-bin-master_2.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes3 rows in set (0.00 sec) 测试下吧 在master-1上创建db_master_1 12mysql&gt; create database db_master_1;Query OK, 1 row affected (0.01 sec) 在master-2上创建db_master_2 12mysql&gt; create database db_master_2;Query OK, 1 row affected (0.01 sec) 在slave中查看 1234567891011121314151617mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || db1 || db2 || db3 || db_master_1 || db_master_2 || mysql || performance_schema || sys || test || test2 |+--------------------+11 rows in set (0.00 sec) 成了！ 参考官方文档 高性能Mysql主从架构的复制原理及配置详解（博客） 关于binary log那些事——认真码了好长一篇，binary那些事（博客） MySQL主从复制原理及配置实现（博客） MySQL5.7的多源复制（博客）]]></content>
      <categories>
        <category>MySQL优化</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化（一）--- MySQL锁机制]]></title>
    <url>%2F2017%2F08%2F29%2FMySQL%E9%94%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[为了保证数据的一致完整性，任何一个数据库都存在锁定机制。锁定机制的优劣直接响应到一个数据库系统的并发处理能力和性能，所以锁定机制的实现也就成为了各种数据库的核心技术之一。本章将对MySQL中两种使用最为频繁的存储引擎MyISAM和Innodb各自的锁定机制进行较为详细的分析。 理论基础总的来说，划分锁类型要依赖两种标准。按照对数据操作的类型分：读锁，写锁。按照数据操作的粒度：表锁，行锁，页锁（本文不作介绍）。 读锁也称为共享锁。 共享锁的代号是S，是Share的缩写。针对同一资源，多个并发读操作可以并行执行，并且互不影响,不能写。 写锁也称排它锁。排它锁的代号是X，是eXclusive的缩写。当前线程写数据的时候，会阻塞其它线程来读取或者写数据。 表锁就是锁住整个表，主要在myisam表存储引擎中出现，myisam默认表锁。表级别的锁定是MySQL各存储引擎中最大颗粒度的锁定机制。该锁定机制最大的特点是实现逻辑简单，带来的系统负面影响最小。所以获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所以可以很好的避免死锁问题。当然，锁定颗粒度大所带来最大的负面影响就是出现锁定资源争用的概率也会最高，致使并发度较低。 行锁锁定单独的某个表中的某一行记录，主要用于innodb存储引擎，innodb默认行锁。行级锁是目前各大数据库管理软件所实现的锁定颗粒度最小的,所以发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能。 但是由于锁定资源的颗粒度很小，所以每次获取锁和释放锁消耗的资源也更多，带来的消耗自然也就更大了。此外，行级锁定也最容易发生死锁。 实践测试表结构及数据12345678910111213141516171819/* 表锁案例*/create table lock_one( id int primary key auto_increment, col int)engine=myisam;insert into lock_one(col) values (1);insert into lock_one(col) values (2);insert into lock_one(col) values (3);/* 行锁案例*/create table lock_two( id int, col int)engine=innodb;insert into lock_two(id,col) values (1,1);insert into lock_two(id,col) values (2,2);insert into lock_two(id,col) values (3,3); 测试表锁语法： 123456789101112# 手动增加表锁：lock table 表名 [read|write]，表名 [read|write]…# 查看锁状态show open tables; # 解开所有锁unlock tables;# 表锁的一些状态查询：show status like 'table_lock%';说明:Table_locks_immediate：表示可以立即获取锁的查询次数，每获取一次锁就增加Table_locks_waited：锁等待的次数 测试全表读锁 开两个会话session1和session2 在session1中锁定lock_one表 MySQL&gt; lock table lock_one read; Query OK, 0 rows affected (0.00 sec) 在session1中对lock_one执行查询，成功 MySQL&gt; select * from lock_one\G;*************************** 1. row ***************************id: 1col: 1*************************** 2. row ***************************id: 2col: 2*************************** 3. row ***************************id: 3col: 33 rows in set (0.00 sec) 在session1中对lock_one执行修改，报错 MySQL&gt; update lock_one set col = 11 where id = 1;ERROR 1099 (HY000): Table ‘lock_one’ was locked with a READ lock and can’t be updated 在session1中对lock_two执行查询，报错 MySQL&gt; update lock_two set col = 11 where id = 1;ERROR 1100 (HY000): Table ‘lock_two’ was not locked with LOCK TABLES 在session1中对lock_two执行修改，报错 MySQL&gt; update lock_two set col = 11 where id = 1;ERROR 1100 (HY000): Table ‘lock_two’ was not locked with LOCK TABLES 在session2中对lock_one执行查询，成功 MySQL&gt; select * from lock_one\G;*************************** 1. row ***************************id: 1col: 1*************************** 2. row ***************************id: 2col: 2*************************** 3. row ***************************id: 3col: 33 rows in set (0.00 sec) 在session2中对lock_one执行修改，阻塞。 MySQL&gt; update lock_one set col = 22 where id = 2; 在session1中解锁 MySQL&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) session2中阻塞更新操作执行 MySQL&gt; update lock_one set col = 22 where id = 2;Query OK, 1 row affected (17.71 sec)Rows matched: 1 Changed: 1 Warnings: 0 在session2中对lock_two执行查询，成功 MySQL&gt; select * from lock_two\G;*************************** 1. row ***************************id: 1col: 1*************************** 2. row ***************************id: 2col: 2*************************** 3. row ***************************id: 3col: 33 rows in set (0.01 sec) 在session2中对lock_two执行修改，成功 MySQL&gt; update lock_two set col = 2;Query OK, 2 rows affected (0.01 sec)Rows matched: 3 Changed: 2 Warnings: 0 据以上测试，结果如下： session1 session2 发送锁表语句lock table t1 read; 连接 可以查询当前锁定的表t1 可以查询t1 更新t1表，报错 更新t1表，阻塞 查询其他表，报错 可以查询其他表 更新其他表，报错 可以查询其他表 执行unlock tables 执行等待的更新操作 分析：读锁是共享锁。在全表上添加读锁时，本线程被锁定，只能进行被锁定表的读操作。其他线程可以对共享表进行读操作，但是要等待锁释放才能进行写操作。 测试全表写锁 开两个会话session1和session2 在session1中锁定lock_one表 MySQL&gt; lock table lock_one write;Query OK, 0 rows affected (0.00 sec) 在session1中对lock_one执行查询，成功 MySQL&gt; select * from lock_one\G*************************** 1. row ***************************id: 1col: 2*************************** 2. row ***************************id: 2col: 22*************************** 3. row ***************************id: 3col: 23 rows in set (0.00 sec) 在session1中对lock_one执行修改，成功 MySQL&gt; update lock_one set col = 3;Query OK, 3 rows affected (0.00 sec)Rows matched: 3 Changed: 3 Warnings: 0 在session1中对lock_two执行查询，报错 MySQL&gt; select * from lock_two;ERROR 1100 (HY000): Table ‘lock_two’ was not locked with LOCK TABLES 在session1中对lock_two执行修改，报错 MySQL&gt; update lock_two set col = 2;ERROR 1100 (HY000): Table ‘lock_two’ was not locked with LOCK TABLES 在session2中对lock_one执行查询，阻塞 MySQL&gt; select * from lock_one\G; 在session1中执行 MySQL&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) session2中查询执行 MySQL&gt; select * from lock_one\G;*************************** 1. row ***************************id: 1col: 2*************************** 2. row ***************************id: 2col: 2*************************** 3. row ***************************id: 3col: 23 rows in set (0.00 sec) 在session2中对lock_one执行修改，阻塞。 MySQL&gt; update lock_one set col = 22 where id = 2; 在session1中解锁 MySQL&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) session2中阻塞更新操作执行 MySQL&gt; update lock_one set col = 22 where id = 2;Query OK, 1 row affected (17.71 sec)Rows matched: 1 Changed: 1 Warnings: 0 在session2中对lock_two执行查询，成功 MySQL&gt; select * from lock_two\G;*************************** 1. row ***************************id: 1col: 1*************************** 2. row ***************************id: 2col: 2*************************** 3. row ***************************id: 3col: 33 rows in set (0.01 sec) 在session2中对lock_two执行修改，成功 MySQL&gt; update lock_two set col = 2;Query OK, 2 rows affected (0.01 sec)Rows matched: 3 Changed: 2 Warnings: 0 据以上测试，结果如下： session1 session2 发送锁表语句lock table t1 write; 连接 可以查询当前锁定的表t1 查询t1,阻塞 可以更新t1表 更新t1表，阻塞 查询其他表，报错 可以查询其他表 更新其他表，报错 可以查询其他表 执行unlock tables 执行等待的操作 分析：写锁是排他锁。在全表上添加写锁时，本线程被锁定，只能进行被锁定表的读写操作。其他线程等待本线程释放排他锁，才能进行读写操作。 MYISAM存储引擎中锁的特点执行select语句的时候，会自动给涉及的表加上读锁，在执行更新操作时，会自动给表加上写锁。 myisam存储引擎比较适合作为以查询为主的表存储引擎，不适合写为主的表存储引擎，因为加写锁后，是锁住整个表，其他用户线程不能做任何操作，这样会导致大量用户线程堵塞的情况。 测试行锁语法12345678910111213141516171819202122232425262728293031323334# 隔离级别show variables like '%iso%';# 查看自动提交参数show variables like '%autocommit%';# 关闭自动提交set autocommit = 0;# 手动锁一行记录begin; select \* from lock_two where id=2 for update；# 查看行锁的信息show status like '%innodb_row_lock%'\G;输出结果：*************************** 1. row ***************************Variable_name: Innodb_row_lock_current_waits Value: 0*************************** 2. row ***************************Variable_name: Innodb_row_lock_time Value: 147166*************************** 3. row ***************************Variable_name: Innodb_row_lock_time_avg Value: 21023*************************** 4. row ***************************Variable_name: Innodb_row_lock_time_max Value: 51044*************************** 5. row ***************************Variable_name: Innodb_row_lock_waits Value: 75 rows in set (0.00 sec)说明：Innodb_row_lock_current_waits ：当前正在等待的数量Innodb_row_lock_time: 从启动到现在锁定的总时长，单位是msInnodb_row_lock_time_avg :锁等待的平均时长Innodb_row_lock_time_max：等待锁时间最长的一个时间Innodb_row_lock_waits：总共的等待次数 开始测试 开启两个会话session1、session2 在两个会话中设置自动提交为手动提交 MySQL&gt; set autocommit=0;Query OK, 0 rows affected (0.00 sec) 在session1中执行update，没有提交事物 MySQL&gt; update lock_two set col = 2 where id = 2;Query OK, 0 rows affected (0.00 sec)Rows matched: 1 Changed: 0 Warnings: 0 在session2中update同一行记录，发生阻塞 MySQL&gt; update lock_two set col = 2 where id = 2; 提交session1和session2中的事物 MySQL&gt; commit; Query OK, 0 rows affected (0.00 sec) 分析：InnoDB自动加行级锁，修改时改行记录已被锁定，其他会话不能修改。 在session1中执行update,没有提交事物 MySQL&gt; MySQL&gt; update lock_two set col = 3 where id = 3;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0 在session2中执行update，操作非同行记录，发生阻塞 MySQL&gt; update lock_two set col = 22 where id = 2; 提交session1和session2中的事物 MySQL&gt; commit;Query OK, 0 rows affected (0.00 sec) 为嘛啊，为嘛啊，说好的行锁呢。分析：实际上，因为MySQL不确定哪行记录被修改，会在全表的范围上加上读锁，然后其他会话就不能更新该表记录。 在lock_two上建立索引 MySQL&gt; create index idx_id on lock_two(id);Query OK, 0 rows affected (0.03 sec)Records: 0 Duplicates: 0 Warnings: 0 执行第4步的操作： 在session1中执行update,没有提交事物 MySQL&gt;update lock_two set col = 3 where id = 3;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0 在session2中执行update，操作非同行记录，操作成功 MySQL&gt; MySQL&gt; update lock_two set col = 22 where id = 2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0 提交session1和session2中的事物 MySQL&gt; commit;Query OK, 0 rows affected (0.00 sec) 为嘛啊，为嘛啊，又和说好的不一样。分析：大概，也许，因为MySQL能通过索引快速的锁定被修改的行，所以只会在被操作范围的记录上加上行锁，然后其他会话就能更新非此范围记录。 间隙锁 在session1中修改范围记录，不提交 MySQL&gt; update lock_two set col = 1 where id &gt; 2 and id &lt; 8;Query OK, 2 rows affected (0.00 sec)Rows matched: 2 Changed: 2 Warnings: 0 在session2中插入id在session1修改where范围的记录，发生阻塞 MySQL&gt; insert into lock_two values(4,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction 分析：在范围查找的情况下，innodb会给范围条件中的数据加上锁，无论数据是否是否真实存在。建议：在innodb中，因为有间隙锁的存在，最好在where中少使用这种范围查找 测试结果结论：如果没有用上索引，行锁变成表锁原因：在不使用索引的情况下，更新表要全表扫描查询定位更新记录的位置，所以会在表上加全表读锁。在有索引的情况下，会走索引查询记录，只使用行锁即可。 InnoDB存储引擎中锁的特点InnoDB存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。支持事务，开销大，加锁慢；会出现死锁；锁的粒度小，并发情况下，产生锁等待的概率比较低，所以支持的并发数比较高]]></content>
      <categories>
        <category>MySQL优化</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化（二）--- MySQL库表设计]]></title>
    <url>%2F2017%2F08%2F28%2FMySQL%E5%BA%93%E8%A1%A8%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[MySQL 数据库是被广泛应用的关系型数据库，其体积小、支持多处理器、开源并免费的特性使其在Internet中小型网站中的使用率尤其高。在使用 MySQL 的过程中不规范的SQL编写、非最优的策略选择都可能导致系统性能甚至功能上的缺陷。本文主要对数据库库表设计上的一些规范做出总结，希望能有助于各位同行解决工作中的相关问题。 作为软件工程师对数据库的定位以下对软件工程师在数据库方面的主要工作做出总结： 业务驱动表的设计 如何写出sql，既满足业务，又高效 从数据库角度会分析抓取慢sql，并优化 掌握复杂业务或者大数据表的设计思路 MySQL逻辑架构了解MySQL的第一步，就要先了解MySQL的功能组件和执行流程。如下就是MySQL逻辑架构图： 从架构图分析，MySQL的执行流程： 库表设计MySQL存储引擎的选择在 MySQL 5.1 中，引入了新的插件式存储引擎体系结构，允许将存储引擎加载到正在运新的MySQL服务器中。使用MySQL插件式存储引擎体系结构，允许数据库专业人员或者设计库表的软件开发人员为特定的应用需求选择专门的存储引擎，完全不需要管理任何特殊的应用编码要求，也无需考虑所有的底层实施细节。因此，尽管不同的存储引擎具有不同的能力，应用程序是与之分离的。此外，使用者可以在服务器、数据库和表格三个层级中存储引擎，提供了极大的灵活性。 MySQL 常用的存储引擎包括MYISAM、Innodb和Memory。还有其他种类，这里不做赘述。那么从哪些方面来评判选择搜索引擎呢？ 是否支持事务 :ACID 检索和添加速度 锁机制 缓存 是否支持全文索引 是否支持外键 空间占用 其中各自的特点对比如下： 评判标准 MYISAM Innodb Memory 事物 不支持 支持 锁 全表锁 行级锁 全表锁 缓存 缓存索引，不缓存数据 缓存索引和数据 检索、添加速度 有较高 MYISAM 速度快 全文索引 支持 不支持 外键 不支持 支持 占用空间 较小 MYISAM 的 2.5 和数据量成正比的内存空间，且重启丢失 关注 性能 事物 性能 注：MYISAM : 并发性能差，MySQL 5.5 及以下仅 MYISAM 支持全文索引，不支持事务。在表有读取查询的同时，支持往表中插入新纪录Innodb：，并发能力相对强不支持全文索引（5.6开始支持），支持事务。在innodb存储引擎中应用比较多，支持事务，开销大，加锁慢；会出现死锁；锁的粒度小，并发情况下，产生锁等待的概率比较低，所以支持的并发数比较高 总体来讲，MyISAM适合SELECT密集型的表，而InnoDB适合INSERT和UPDATE密集型的表 基于以上特性，建议绝大部份都设置为innodb引擎，特殊的业务再考虑选用 MYISAM 或 Memory ，如全文索引支持或极高的执行效率等。 范式化设计1NF：原子性，列不可分。每一列都是不可分割的基本数据项2NF：1NF的基础上面，非主属性完全依赖于主关键字3NF：属性不依赖于其它非主属性 , 消除传递依赖 。一个非关键属性不应该依赖一个关键属性 使用范式会有哪些优缺点？ 优点： 避免数据冗余 减少数据的空间 减轻维护数据完整性的麻烦 范式设计的表通常比较小，可以更好的利用内存的优势，提高我们的检索速度 缺点： 经过范式设计出来的表，会很多，越严格来遵循，表就越多 多表关联会慢，可能会导致索引失效 范式越高，对操作性能可能就越低 简单来说就是单表快，多表慢，这里就可以运用到反范式化设计 反范式化设计不符合3NF的设计就是反范式，适当的增加冗余减少表的关联优化查询效率，以空间换时间，在NOSQL中大量运用 运用场景：检索性能要求高对冗余字段很少做更新操作]]></content>
      <categories>
        <category>MySQL优化</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化（一）--- MySQL环境准备]]></title>
    <url>%2F2017%2F08%2F28%2FMySQL%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87%2F</url>
    <content type="text"><![CDATA[最近系统看了下MySQL，决定写系列文章做个总结，为自己做个梳理，也为以后有新的idea或者收获都有个修正和添加记录的地方。先说一点，实际上网上的资料和本文在MySQL官网上都有，英语好的推荐直接阅读官方文档，英语不好先学好英语去阅读官方文档。 开始搭建Linux环境首先，需要linux环境，本文环境 Linux CentOs 3.10.0-514.el7.x86_64 MySQL下载然后，下载MySQL,本文环境 Mysql 5.7.14-1.el7.x86_64 进入官网下载页面，进入如下页面，选择操作系统并点击下载 MySQL安装 root用户登录 在root目录下面新建env目录，上传安装包到env目录，并创建mysql-install.sh脚本 [root@localhost env]# pwd &amp;&amp; ll /root/env 总用量 556004 -rw-r–r–. 1 root root 569344000 8月 25 19:49 mysql-5.7.14-1.el7.x86_64.rpm-bundle.tar -rw-r–r–. 1 root root 465 8月 25 19:48 mysql-install.sh 其中mysql-install.sh 中的命令为（注意替换为自己数据库版本）： 123456789101112#!/bin/bashmkdir mysqltar -xvf mysql-5.7.14-1.el7.x86_64.rpm-bundle.tar -C ./mysqlcd mysql &amp;&amp; yum remove mysql-libs -yrpm -ivh mysql-community-common-5.7.14-1.el7.x86_64.rpmrpm -ivh mysql-community-libs-5.7.14-1.el7.x86_64.rpm rpm -ivh mysql-community-client-5.7.14-1.el7.x86_64.rpm rpm -ivh mysql-community-server-5.7.14-1.el7.x86_64.rpmrpm -ivh mysql-community-devel-5.7.14-1.el7.x86_64.rpmcd ../#cp binary_log_types.h /usr/include/mysql/rm -rf mysql 运行完毕之后目录结构为： [root@localhost env]# pwd &amp;&amp; ll /root/env 总用量 556004 -rw-r–r–. 1 root root 569344000 8月 25 19:49 mysql-5.7.14-1.el7.x86_64.rpm-bundle.tar -rw-r–r–. 1 root root 465 8月 25 19:48 mysql-install.sh 安装好之后，按如下配置： 编辑MySQL配置文件my.cnf vi /etc/my.cnf #编辑文件，找到[mysqld]，在下面添加一行skip-grant-tables 123456789# 可通过以下命令查询my.cnf的位置whereis my.cnf# 或mysqld --verbose --help | grep -C 1 'Default opt'# 编辑配置文件[mysqld]skip-grant-tables :wq! #保存退出,重启MySQL服务 1service mysqld restart 进入MySQL控制台 1mysql -uroot -p #直接按回车，这时不需要输入root密码。 修改root密码 12345flush privileges; # 刷新系统授权表 grant all on *.* to 'root'@'localhost' identified by 'newpassword' with grant option;flush privileges; 取消/etc/my.cnf中的skip-grant-tables,编辑文件，找到[mysqld]，删除skip-grant-tables这一行 1service mysqld restart 忘记密码处理 12345678910111213# 设置密码也可用set password for 'root'@'localhost' = password(''); # 如果哪一天忘记密码，执行以下命令更新密码mysql&gt; UPDATE mysql.user SET authentication_string= password('root') WHERE User = 'root' ; Query OK, 1 row affected, 1 warning (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 1mysql&gt; flush privileges;Query OK, 0 rows affected (0.01 sec)# 并重启服务[root@localhost ~]# systemctl restart mysqld.service 配置文件和数据配置文件默认位置: Linux: /etc/my.cnfWindows: my.ini 在mysql安装的home目录 数据文件位置 命令：show variables like &#39;%datadir%&#39; ; 数据文件格式 InnoDB frm : 存储表结构 ibd：存储数据和索引 MyISAM frm： 存储表结构 MYD：存储数据 MYI：存储索引 字符集设置查看当前字符集 1mysql&gt; show variables like 'character%'; 输出结果如下： 123456789101112 +--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+ 名词解释： character_set_client：客户端请求数据的字符集 character_set_connection：客户机/服务器连接的字符集 character_set_database：默认数据库的字符集，无论默认数据库如何改变，都是这个字符集；如果没有默认数据库，那就使用 character_set_server指定的字符集，这个变量建议由系统自己管理，不要人为定义。 character_set_filesystem：把os上文件名转化成此字符集，即把 character_set_client转换character_set_filesystem， 默认binary是不做任何转换的 character_set_results：结果集，返回给客户端的字符集 character_set_server：数据库服务器的默认字符集 character_set_system：系统字符集，这个值总是utf8，不需要设置。这个字符集用于数据库对象（如表和列）的名字，也用于存储在目录表中的函数的名字。 编辑/etc/my.cnf文件，添加如下字符集设置 1234567891011121314[client]#影响参数：character_set_client，character_set_connection和character_set_results。default-character-set=utf8[mysql]default-character-set=utf8[mysqld]#影响参数：character_set_server 和 character_set_databaseinit_connect='SET collation_connection = utf8_unicode_ci'init_connect='SET NAMES utf8'character-set-server=utf8collation-server=utf8_unicode_ciskip-character-set-client-handshake 修改之后重启数据库生效 1service mysqld restart #重启MySQL服务]]></content>
      <categories>
        <category>MySQL优化</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
</search>
