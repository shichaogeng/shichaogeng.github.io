<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Concurrent（五）--- 线程池实现原理]]></title>
    <url>%2F2017%2F12%2F14%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[线程池源码我以前都看过了，感觉不想仔细写了。 什么是线程池？1、 降低资源的消耗2、 提高响应速度，任务：T1创建线程时间，T2任务执行时间，T3线程销毁时间，线程池没有或者减少T1和T33、 提高线程的可管理性。线程池要做些什么？1、 线程的容器和管理器2、 工作线程3、 任务接口4、 任务的容器 线程池的主要处理流程1）线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。2）线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。3）线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。 ThreadPoolExecutor执行execute()方法的示意1）如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。2）如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。3）如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。4）如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。 线程池的创建各个参数含义public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,BlockingQueue workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler)corePoolSize线程池中的核心线程数，当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；如果当前线程数为corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；如果执行了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有核心线程。maximumPoolSize线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于maximumPoolSizekeepAliveTime线程空闲时的存活时间，即当线程没有任务执行时，继续存活的时间。默认情况下，该参数只在线程数大于corePoolSize时才有用TimeUnitkeepAliveTime的时间单位workQueueworkQueue必须是BlockingQueue阻塞队列。当线程池中的线程数超过它的corePoolSize的时候，线程会进入阻塞队列进行阻塞等待。通过workQueue，线程池实现了阻塞功能threadFactory创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名Executors静态工厂里默认的threadFactory，线程的命名规则是“pool-数字-thread-数字”RejectedExecutionHandler（饱和策略）线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略：（1）AbortPolicy：直接抛出异常，默认策略；（2）CallerRunsPolicy：用调用者所在的线程来执行任务；（3）DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；（4）DiscardPolicy：直接丢弃任务；当然也可以根据应用场景实现RejectedExecutionHandler接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务。关闭线程池ShutDown():interrupt方法来终止线程shutDownNow() 尝试停止所有正在执行的线程合理地配置线程池线程数配置：任务：计算密集型，IO密集型，混合型计算密集型=计算机的cpu数或计算机的cpu数+1（应付页缺失）IO密集型=计算机的cpu数*2混合型，拆分成计算密集型，IO密集型Runtime.getRuntime().availableProcessors();当前机器中的cpu核心个数尽量有界队列，不要使用无界队列 Executor框架调度模型 三大组成部分：任务，任务的执行，异步计算的结果 成员结构图 Executor框架基本使用流程 FixedThreadPool详解 SingleThreadExecutor详解 CachedThreadPool详解 WorkStealingPool ScheduledThreadPoolExecutor详解 对这4个步骤的说明。 有关提交定时任务的四个方法：public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit)//向定时任务线程池提交一个延时Runnable任务（仅执行一次）public ScheduledFuture schedule(Callable callable, long delay, TimeUnit unit);//向定时任务线程池提交一个延时的Callable任务（仅执行一次）public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)//向定时任务线程池提交一个固定时间间隔执行的任务public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit);//向定时任务线程池提交一个固定延时间隔执行的任务 ScheduleThreadPoolExecutor与Timer相比的优势。 scheduleAtFixedRate定时任务超时问题 Callable、Future和FutureTask详解 CompletionService详解]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Concurrent（四）--- 并发工具&并发容器]]></title>
    <url>%2F2017%2F12%2F08%2F%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[本篇对并发中常用的并发容器如ConcurrentHashMap何阻塞队列原理进行解读，并探讨下并发工具类的使用方式。 ConcurrentHashMap为什么要使用ConcurrentHashMap在多线程环境下，使用HashMap进行put操作会引起死循环，导致CPU利用率接近100%，HashMap在并发执行put操作时会引起死循环，是因为多线程会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。 HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法，其他线程也访问HashTable的同步方法时，会进入阻塞或轮询状态。如线程1使用put进行元素添加，线程2不但不能使用put方法添加元素，也不能使用get方法来获取元素，所以竞争越激烈效率越低。 公众号上找到一篇很好理解的文章：高并发下的HashMap 一些有用的API很多时候我们希望在元素不存在时插入元素，我们一般会像下面那样写代码1234567synchronized(map)&#123; if (map.get(key) == null)&#123; return map.put(key, value); &#125; else&#123; return map.get(key); &#125;&#125; putIfAbsent(key,value)方法原子性的实现了同样的功能12//如果key对应的value不存在，则put进去，返回null。否则不put，返回已存在的value。V putIfAbsent(K key, V value) 12// 如果key对应的值是value，则移除K-V，返回true。否则不移除，返回false。 boolean remove(Object key, Object value) 12//如果key对应的当前值是oldValue，则替换为newValue，返回true。否则不替换，返回false。boolean replace(K key, V oldValue, V newValue) Hash的解释散列，任意长度的输入，通过一种算法，变换成固定长度的输出。属于压缩的映射。Md5，Sha，取余都是散列算法，ConcurrentHashMap中是wang/jenkins算法 ConcurrentHashMap在1.7下的实现分段锁的设计思想。 ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment实际是一种可重入锁（ReentrantLock），HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组。Segment的结构和HashMap类似，是一种数组和链表结构。一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得与它对应的Segment锁。 ConcurrentHashMap初始化方法是通过initialCapacity、loadFactor和concurrencyLevel(参数concurrencyLevel是用户估计的并发级别，就是说你觉得最多有多少线程共同修改这个map，根据这个来确定Segment数组的大小concurrencyLevel默认是DEFAULT_CONCURRENCY_LEVEL = 16;)。 ConcurrentHashMap完全允许多个读操作并发进行，读操作并不需要加锁。ConcurrentHashMap实现技术是保证HashEntry几乎是不可变的。HashEntry代表每个hash链中的一个节点，可以看到其中的对象属性要么是final的，要么是volatile的。 小灰的漫画形象的展现了jdk1.7中concurrenthashmap的实现，尤其是其中size()方法的讲解。 ConcurrentHashMap在1.8下的实现改进一：取消segments字段,直接采用transient volatile HashEntry[] table保存数据，采用table数组元素作为锁，从而实现了对每一行数据进行加锁，进一步减少并发冲突的概率。 改进二：将原先table数组＋单向链表的数据结构，变更为table数组＋单向链表＋红黑树的结构。对于个数超过8(默认值)的列表，jdk1.8中采用了红黑树的结构，那么查询的时间复杂度可以降低到O(logN)，可以改进性能。 1.8的get性能提升明显，在hash碰撞激烈的情况下，尤其明显，因为链表会越来越长。 红黑树小灰的漫画 简单总结下，红黑树基于二叉树并由下列特点：a. 节点有红色和黑色b. 根节点和叶子节点(叶子节点都为NIL)都是黑色c.红色节点不能连续d.从某一子节点到叶子节点的黑色节点数量相同 红黑树有自平衡的特性，用变色和旋转来保持自平衡：变色：为了符合自平衡原则会红黑变色。左旋：逆时针旋转，右子节点变为父节点，父节点变为现父节点的左子节点右旋：顺时针旋转，左子节点变为父节点，父节点变为现父节点的右子节点 其他并发容器ConcurrentSkipListMap 和ConcurrentSkipListSetConcurrentSkipListMap:TreeMap的并发实现ConcurrentSkipListSet:TreeSet的并发实现 了解什么是SkipList？二分查找二分查找要求元素可以随机访问，所以决定了需要把元素存储在连续内存。这样查找确实很快，但是插入和删除元素的时候，为了保证元素的有序性，就需要大量的移动元素了。如果需要的是一个能够进行二分查找，又能快速添加和删除元素的数据结构，首先就是二叉查找树，二叉查找树在最坏情况下可能变成一个链表。 AVL树查找于是，就出现了平衡二叉树，根据平衡算法的不同有AVL树，B-Tree，B+Tree，红黑树等，但是AVL树实现起来比较复杂，平衡操作较难理解，这时候就可以用SkipList跳跃表结构。 跳跃表传统意义的单链表是一个线性结构，向有序的链表中插入一个节点需要O(n)的时间，查找操作需要O(n)的时间。 如果我们使用上图所示的跳跃表，就可以减少查找所需时间为O(n/2)，因为我们可以先通过每个节点的最上面的指针先进行查找，这样子就能跳过一半的节点。 比如我们想查找19，首先和6比较，大于6之后，在和9进行比较，然后在和12进行比较……最后比较到21的时候，发现21大于19，说明查找的点在17和21之间，从这个过程中，我们可以看出，查找的时候跳过了3、7、12等点，因此查找的复杂度为O(n/2)。跳跃表其实也是一种通过“空间来换取时间”的一个算法，通过在每个节点中增加了向前的指针，从而提升查找的效率。跳跃表又被称为概率，或者说是随机化的数据结构，目前开源软件 Redis(SortedSet) 和 lucence都有用到它。 小灰漫画之跳跃表 ConcurrentLinkedQueue 无界非阻塞队列ConcurrentLinkedQueue:LinkedList并发版本123Add,offer：添加元素Peek：get头元素并不把元素拿走poll()：get头元素把元素拿走 CopyOnWriteArrayList和CopyOnWriteArraySet写的时候进行复制，可以进行并发的读。 适用读多写少的场景：比如白名单，黑名单，商品类目的访问和更新场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单每天晚上更新一次。当用户搜索时，会检查当前关键字在不在黑名单当中，如果在，则提示不能搜索。弱点：内存占用高，数据一致性弱 阻塞队列取数据和读数据不满足要求时，会对线程进行阻塞 API1234方法 抛出异常 返回值 一直阻塞 超时退出插入 Add offer put offer移除 remove poll take poll检查 element peek 没有 没有 常用阻塞队列: ArrayBlockingQueue： 数组结构组成有界阻塞队列。先进先出原则，初始化必须传大小，不扩容，take和put时候用的同一把锁 LinkedBlockingQueue：链表结构组成的有界阻塞队列先进先出原则，初始化可以不传大小，最大Integer.MAX_VALUE，put，take锁分离 PriorityBlockingQueue：支持优先级排序的无界阻塞队列，排序，自然顺序升序排列，更改顺序：类自己实现compareTo()方法，初始化PriorityBlockingQueue指定一个比较器Comparator DelayQueue： 使用了优先级队列的无界阻塞队列支持延时获取，队列里的元素要实现Delay接口。DelayQueue非常有用，可以将DelayQueue运用在以下应用场景。缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。还有订单到期，限时支付等等。 SynchronousQueue：不存储元素的阻塞队列每个put操作必须要等take操作 LinkedTransferQueue：链表结构组成的无界阻塞队列Transfer,tryTransfer，生产者put时，当前有消费者take，生产者直接把元素传给消费者 LinkedBlockingDeque：链表结构组成的双向阻塞队列可以在队列的两端插入和移除，xxxFirst头部操作,xxxLast尾部操作。工作窃取模式。 了解阻塞队列的实现原理使用了Condition实现。 生产者消费者模式在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序整体处理数据的速度。 在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这种生产消费能力不均衡的问题，便有了生产者和消费者模式。 生产者和消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通信，而是通过阻塞队列来进行通信，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。 什么是Fork/Join框架并行执行任务的框架，把大任务拆分成很多的小任务，汇总每个小任务的结果得到大任务的结果。 工作窃取算法：工作窃取（work-stealing）算法是指某个线程从其他队列里窃取任务来执行。那么，为什么需要使用工作窃取算法呢？假如我们需要做一个比较大的任务，可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应。比如A线程负责处理A队列里的任务。但是，有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。 Fork/Join框架的使用```Fork/Join使用两个类来完成以上两件事情。①ForkJoinTask：我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork()和join()操作的机制。通常情况下，我们不需要直接继承ForkJoinTask类，只需要继承它的子类，Fork/Join框架提供了以下两个子类。·RecursiveAction：用于没有返回结果的任务。·RecursiveTask：用于有返回结果的任务。②ForkJoinPool：ForkJoinTask需要通过ForkJoinPool来执行。Fork/Join有同步和异步两种方式。 CountDownLatch CyclicBarrier CyclicBarrier和CountDownLatch的区别 Semaphore Exchanger]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Concurrent（三）--- Lock&Condition&AQS]]></title>
    <url>%2F2017%2F12%2F06%2FLock-Condition-AQs%2F</url>
    <content type="text"><![CDATA[本篇旨在解读高级并发同步队列器的原理及其在高级主题中的应用。 Lock有了synchronized为什么还要Lock？1.尝试非阻塞地获取锁 获取锁的过程可以被中断，Lock#lockInterruptibly()能够在获取锁的同时保持对中断的响应(synchronized无法中断一个等待获取锁的线程)。定时的tryLock同样能响应中断，当需要同时满足定时和中断时，可以使用带时间的tryLock 超时获取锁tryLock(long time, TimeUnit unit); 什么时候使用ReentrantLck而不是synchronized？1一些高级功能，比如说可轮询的，计时的，可中断的锁的获取。公平队列，非区块的锁。 如何防止死锁内置锁：避免出现不一致的锁顺序 可定时锁和轮询锁：避免死锁发生 trylock(时间限制的tryLock，当没有想要的结果，就会使程序提前结束，内置锁不能办到这点)。 Lock的标准用法参考代码1234567Lock lock = new ReentrantLock();lock.lock();try&#123; // do my work.....&#125;finally&#123; lock.unlock();&#125; Lock的常用API123456789public interface Lock &#123; void lock();//获取锁 void lockInterruptibly() throws InterruptedException;//可中断 boolean tryLock();//尝试非阻塞地获取锁 boolean tryLock(long time, TimeUnit unit) throws InterruptedException;//定时锁 void unlock();//释放锁 Condition newCondition();&#125; 锁的可重入一个线程尝试获取一个自己持有的锁，这个请求就会成功，即可重入。 实现原理：为每个锁关联一个计数器和所有者线程，同一线程获取锁之后计数器加1，退出后计数器减1，计数器为0时，释放锁。 递归的时候发生锁的重入，没有锁的可重入，就会死锁。继承的时候也需要使用可重入锁。 我们可以看看ReentrantLock是怎么实现的可重入123456789101112131415161718192021222324252627282930313233final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123;//为0表示没有线程占用资源 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //资源已经被占用，查看当前与占用资源的是同一线程。记录当前线程记录的次数 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125;//锁的释放protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123;//为0代表可重入锁释放完毕 free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 公平和非公平锁公平锁，先对锁发出获取请求的一定先被满足。公平锁的效率比非公平锁(默认)效率要低。 为什么公平锁更消费资源，因为在恢复被挂起的线程和它真正运行之间存在严重的延迟。如线程a持有一个锁，而此时线程b请求这个锁，由于锁被线程a持有，所以b被挂起。当a释放锁时，b被唤醒并尝试获取锁，如果此时线程c获取，持有，并 那么b获取锁并没有任何推迟，将极大提高吞吐量。 当持有锁的时间很长，或者请求锁的间隔时间很长，那么应该使用公平锁，因为此时不会出现上述情况。 以上理论例子均来自&lt;&lt;并发编程实战&gt;&gt; 源码123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125; 那么费公平锁是如何实现的呢，我们来对比下公平和非公平锁获取资源12345678910111213141516171819202122232425262728//公平的实现protected final boolean tryAcquire(int acquires) &#123; if (c == 0) &#123; //如果等待队列有在等待的节点，tryAcquire返回false,获取失败 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125;&#125;public final boolean hasQueuedPredecessors() &#123; Node t = tail; Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125;//非公平的实现final boolean nonfairTryAcquire(int acquires) &#123; if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125;&#125; 读写锁ReentrantReadWriteLock允许多个读线程同时进行，但是只允许一个写线程(不允许其他读线程和写线程)，支持读多写少场景，性能会有提升。 源码：1234public interface ReadWriteLock &#123; Lock readLock(); Lock writeLock();&#125; 使用读写锁:1234567891011121314151617181920212223242526public class RwLockTemplete &#123; static final Map&lt;String,String&gt; map = new HashMap&lt;&gt;(); static ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(); static Lock r = reentrantReadWriteLock.readLock(); static Lock w = reentrantReadWriteLock.writeLock(); public void put()&#123; w.lock(); try&#123; // do my work..... &#125;finally&#123; w.unlock(); &#125; &#125; public void get()&#123; r.lock(); try&#123; // do my work..... &#125;finally&#123; r.unlock(); &#125; &#125;&#125; 读写锁把int 32个字节分为两部分来使用，高16位作为读锁，低16位作为写锁。并使用ThreadLocal来保存重入的次数。 ConditionObject wait,notify/allCondition接口和Lock配合来实现等待通知机制 Condition常用方法和使用范式源码1234567public interface Condition &#123; void await() throws InterruptedException;boolean await(long time, TimeUnit unit) throws InterruptedException; void awaitUninterruptibly();//不可被中断 void signal(); void signalAll();&#125; 使用范式，参见代码123456789101112131415161718192021222324public class ConditionTemplete &#123; Lock lock = new ReentrantLock(); Condition condition = lock.newCondition(); public void waitc() throws InterruptedException &#123; lock.lock(); try&#123; condition.await(); &#125;finally&#123; lock.unlock(); &#125; &#125; public void waitnotify() throws InterruptedException &#123; lock.lock(); try&#123; condition.signal(); //condition.signalAll();尽量少使用,因为lock可以定义多个condition &#125;finally&#123; lock.unlock(); &#125; &#125;&#125; 结合ReentrantLock和Condition实现线程安全的有界队列参见代码1234567891011121314151617181920212223242526272829303132333435363738public class BlockingQueueLC&lt;T&gt; &#123; private List queue = new LinkedList&lt;&gt;(); private final int limit; Lock lock = new ReentrantLock(); private Condition needNotEmpty = lock.newCondition(); private Condition needNotFull = lock.newCondition(); public BlockingQueueLC(int limit) &#123; this.limit = limit; &#125; public void enqueue(T item) throws InterruptedException &#123; lock.lock(); try&#123; while(this.queue.size()==this.limit)&#123; needNotFull.await(); &#125; this.queue.add(item); needNotEmpty.signal(); &#125;finally&#123; lock.unlock(); &#125; &#125; public T dequeue() throws InterruptedException &#123; lock.lock(); try&#123; while(this.queue.size()==0)&#123; needNotEmpty.await(); &#125; needNotFull.signal(); return (T) this.queue.remove(0); &#125;finally&#123; lock.unlock(); &#125; &#125;&#125; AQS什么是AbstractQueuedSynchronizer？为什么我们要分析它？AQS是抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch…。它是大量并发同步类的底层实现，理解了AQS，就能实现同步类的实现原理。 AQS的基本使用方法同步器的主要使用方式是继承，子类通过继承同步器并实现它的抽象方法来管理同步状态。123456public class ReentrantLock implements Lock, java.io.Serializable &#123; private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer &#123; //implement method &#125; 我们可以通过源码查看可重写的方法有哪些123456789101112131415161718192021public abstract class AbstractQueuedSynchronizer &#123; /** * The synchronization state.同步状态，共享资源 */ private volatile int state; protected final int getState()&#123;//...&#125; protected final void setState(int newState)&#123;//...&#125; //负责原子设置同步状态 protected final boolean compareAndSetState(int expect, int update)&#123;//...&#125; /** * 可以重写的方法 */ tryAcquire()&#123;&#125; //独占锁获取 tryRelease()&#123;&#125; //独占锁释放 tryAcquireShared()&#123;&#125; //共享锁获取 tryReleaseShared()&#123;&#125; //共享锁释放 isHeldExclusively()&#123;&#125; //快速判断被线程独占&#125; 同步器的设计是基于模板方法模式, 使用者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。 LockSupportLockSupport主要提供线程的许可发放服务12345678910//阻塞一个线程public static void park() &#123; UNSAFE.park(false, 0L);&#125;//唤醒一个线程public static void unpark(Thread thread) &#123; if (thread != null) UNSAFE.unpark(thread);&#125; 调用的都是Unsafe中的方法，这里就不探究了12public native void unpark(Object var1);public native void park(boolean var1, long var2); 同步队列独占式同步状态获取与释放获取操作首先，先自定义一个独占锁(只贴出关键代码)123456789101112131415161718192021222324252627282930313233343536373839public class SingleLock implements Lock&#123; //内部类对象（队列同步器） private final sync sync = new sync(); //加锁 @Override public void lock() &#123; sync.acquire(1); &#125; //释放锁 @Override public void unlock() &#123; sync.tryRelease(0); &#125; //内部类继承aqs，获取和释放资源都是调用的此方法 static class sync extends AbstractQueuedSynchronizer &#123; //独占方法获取资源api @Override public boolean tryAcquire(int arg) &#123; if (compareAndSetState(0, arg)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; //独占方法释放资源api @Override public boolean tryRelease(int arg) &#123; setExclusiveOwnerThread(null); setState(arg); return true; &#125; &#125;&#125; 我们先来看加锁操作,调用AQS#acquire()方法123456public final void acquire(int arg) &#123; //tryAcquire自己实现的方法，获取共享状态state if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 我们看下流程图来仔细分析这波操作 我们跟着流程图来分析源码,首先是我们实现的tryAcquire123456789 @Overridepublic boolean tryAcquire(int arg) &#123; //简单的如果为0，设置为1，如果为1，返回false if (compareAndSetState(0, arg)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false;&#125; 我们先简单介绍下Node1234567891011121314static final class Node &#123; static final Node SHARED = new Node();//共享方式 static final Node EXCLUSIVE = null;//独占方式 olatile Node prev;//上个节点 volatile Node next;//下个节点 volatile Thread thread;//线程 Node nextWaiter; //构造 Node(Thread thread, Node mode) &#123;// Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125;&#125; 很明显这是一个双向链表，AQS内部维护这首尾节点123private transient volatile Node head;private transient volatile Node tail; 就是这个样子 现在继续，如果获取独占锁失败，就要调用addWaiter()，把线程放入节点加到同步队列尾部123456789101112131415161718192021222324252627282930313233private Node addWaiter(Node mode) &#123; //创建Node对象存放为获取锁的线程 Node node = new Node(Thread.currentThread(), mode); //先尝试快速入队，失败之后再正式无限循环入队（速度快呀） Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //入队 enq(node); return node;&#125;//无限循环入队列(把此节点当做尾节点)，还是利用的cas旋操作private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 就是这么个流程 再看下acquireQueued，看看如何把当前节点阻塞123456789101112131415161718192021222324252627final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; //下面这些操作都是为了再次尝试获取独占资源（万一别人释放了就能快速拿到了，大概） //获取上一个节点 final Node p = node.predecessor(); //如果上一个节点是头节点（头结点是正在占用资源的节点），并且获取资源成功，就把当前节点设为头节点。 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; //获取到资源，不用中断自己 return interrupted; &#125; //然后把线程阻塞起来 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;//上一个节点waitStatus设置为唤醒状态 //park线程，等待unpark或中断 parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 释放操作首先，自己的代码实现释放资源1234 @Overridepublic void unlock() &#123; sync.release(0);&#125; 调用的是AQS实现的release方法123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; 首先调用我们自己实现的tryRelease释放共享资源123456 @Overridepublic boolean tryRelease(int arg) &#123; setExclusiveOwnerThread(null); setState(arg); return true;&#125; 然后进入关键代码unparkSuccessor123456789101112131415161718private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); //找到头节点的下一个节点 Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; //这里倒序遍历从tail到node直到找到有效状态的阻塞节点 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) //唤醒线程 LockSupport.unpark(s.thread);&#125; 我们在回忆下阻塞的代码12345678910111213141516171819202122232425262728293031323334final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; //唤醒之后又循环到这里,其中node就是上文中的s，被唤醒的线程节点 final Node p = node.predecessor();//取得上一个节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; /** * 如果是头结点并获取到资源，干掉头结点，如下面的图 * 如果不是头节点，则进入shouldParkAfterFailedAcquire(), * 它会杀掉已取消的节点，然后*s就是head的下一个节点了，即此时p==head * 这时再次循环到这里，进行设置头节点的操作 */ setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;private final boolean parkAndCheckInterrupt() &#123; //阻塞在这里 LockSupport.park(this); return Thread.interrupted();&#125; 设置头节点如下图 走到这一步acquire操作就可以返回了，即lock操作结束了。 这个过程可以用下图来表示 独占的获取锁操作已经研究结束，下面来看下共享模式的资源获取操作。 共享式同步状态获取与释放前面分析过独占锁了，下面简单分析下共享锁，主要分析实现共享的思路1234567891011121314151617181920212223242526272829303132333435363738394041424344public class DoubleLock implements Lock&#123; private static Sync sync = new Sync(2); @Override public void lock() &#123; sync.acquireShared(1); &#125; @Override public void unlock() &#123; sync.releaseShared(1); &#125; static class Sync extends AbstractQueuedSynchronizer &#123; public Sync(int count) &#123; setState(count); &#125; //共享锁获取，返回值表示剩余资源的数量 @Override protected int tryAcquireShared(int arg) &#123; for (;;) &#123; int currCount = getState(); int newCount = currCount - arg; if ((newCount &lt; 0) || compareAndSetState(currCount, newCount)) &#123; return newCount; &#125; &#125; &#125; //共享锁的释放 @Override protected boolean tryReleaseShared(int arg) &#123; for (;;) &#123; int currCount = getState(); int newCount = currCount + arg; if (compareAndSetState(currCount, newCount)) &#123; return true; &#125; &#125; &#125; &#125;&#125; 通过自己的实现tryAcquireShared()代码可以看到,所谓的共享只不过是共享状态state有多种状态，而获取的时候通过cas自旋直到获取到共享资源。如果资源耗尽(tryAcquireShared(arg) &lt; 0)，就加入到队列中等待。 Condition的实现首先从我们自己实现的互斥锁来看1234567@Overridepublic Condition newCondition() &#123; return sync.newCondition();&#125;final ConditionObject newCondition() &#123; return new ConditionObject();&#125; 实际上是创建的ConditionObject对象，它实现了Condition接口，我们来看ConditionObject的具体实现123public class ConditionObject implements Condition &#123; private transient Node firstWaiter; private transient Node lastWaiter; 可以看出，他就是个单向链表，我们看下await方法12345678910111213141516171819public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); //加入到队列中 Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; 看下addConditionWaiter的实现12345678910111213141516171819private Node addConditionWaiter() &#123; //最后一个节点 Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; //不是Node.Condition状态的，清空，估计是更新了lastWaiter，懒得看了 unlinkCancelledWaiters(); //重新赋下值 t = lastWaiter; &#125; //线程保证成节点，状体设为Condition Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null)//链表是空的 firstWaiter = node; else t.nextWaiter = node; lastWaiter = node;//两步操作把新节点加到链表尾部 return node;&#125; NiceArticles懒得写了，想了解的就自己网上查吧，随便找个博客:Java多线程Condition接口原理详解 哎，具体的看这里吧：Java并发之AQS详解]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Concurrent（二）--- 什么是CAS]]></title>
    <url>%2F2017%2F12%2F05%2F%E4%BB%80%E4%B9%88%E6%98%AFCAS%2F</url>
    <content type="text"><![CDATA[原子（atomic (ə’tɑmɪk/)）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意为“不可被中断的一个或一系列操作”。CAS（ Compare And Swap ） 为什么要有CAS？JDK大量使用CAS自旋来实现原子性。这里我们来解开CAS神秘的面纱。github地址： 使用cas的原因我们经常需要轻量级的原子操作， 而锁要争夺资源并且容易阻塞。 CAS原理CAS有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，将内存值修改为B并返回true，否则什么都不做并返回false。 循环CAS：在一个（死）循环【for(;;)】里不断进行CAS操作，直到成功为止（自旋操作) Compare And Swap就是比较并且交换的一个原子操作，由Cpu在指令级别上进行保证。通过硬件层面的阻塞实现原子操作的安全。 cas方法是一个native,源码用c++编写，禁止指令重排和刷新到主内存 原子类源码解析（AtomicInteger）首先查看AtomicInteger#getAndIncrement()代码1234567891011121314151617181920//首先，要获取value内存偏移量private static final long valueOffset;static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;//并用volatile修饰保证value的可见性。private volatile int value;/** * Atomically increments by one the current value. * * @return the previous value */public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1);&#125; 它调用了Unsafe#getAndAddInt()12345678910111213141516/** * var1 对象（this） * var2 内存地址（原值） * var4 设定值 * var5 修改后的值 */public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; //从内存中获取最新值var5 var5 = this.getIntVolatile(var1, var2); //通过内存原值(通过var和var2获取)和最新值做对比，如果相同更新var5，否则继续循环获取最新值。因为每次都从内存中获取最新值，不会进入死循环，但并发激烈的情况下可能循环多次。 &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; CAS实现原子操作的三大问题 ABA问题：其他的线程把值改成了C，很快改成了A。然而cas检查认为A并没有修改过。要解决ABA问题，引入版本号：1A-》2C-》3A，可以使用带有标记的原子引用类AtomicStampedReference，他可以控制变量的版本来保证CAS。 循环时间很长的话，cpu的负荷比较大 对一个变量进行操作可以，同时操作多个共享变量有点麻烦，可以放在AtomicReference原子类里进行操作 原子类原子更新基本类型类AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference。AtomicInteger的常用方法如下12345·int addAndGet（int delta）： ·boolean compareAndSet（int expect，int update）： ·int getAndIncrement()： 原子递增，但是返回的是自增以前的值incrementAndGet：原子递增，但是返回的是自增以后的值·int getAndSet（int newValue）： 原子更新数组类AtomicIntegerArray，AtomicLongArray，AtomicReferenceArrayAtomicIntegerArray类主要是提供原子的方式更新数组里的整型，其常用方法如下。12·int addAndGet（int i，int delta）： ·boolean compareAndSet（int i，int expect，int update）： 数组通过构造方法传入，类会将数组复制一份，原数组不会发生变化。 原子更新引用类型AtomicReference： 可以解决更新多个变量的问题AtomicStampedReference：解决ABA问题 改过几次AtomicMarkableReference：解决ABA问题 又没改过 原子更新字段类Atomic包提供了以下3个类进行原子字段更新。123·AtomicReferenceFieldUpdater： ·AtomicIntegerFieldUpdater： ·AtomicLongFieldUpdater： 好的文章具体cas情况，可以点这里的链接：java中的Unsafejava中的CAS]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型]]></title>
    <url>%2F2017%2F11%2F28%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[线程安全]]></title>
    <url>%2F2017%2F11%2F28%2F%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Concurrent（一）--- 线程基础、中断、常用方法辨析]]></title>
    <url>%2F2017%2F11%2F28%2F%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E4%B8%AD%E6%96%AD%E3%80%81%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%E8%BE%A8%E6%9E%90%2F</url>
    <content type="text"><![CDATA[并发通常是指，通过设计保证系统能够同时并行处理很多请求。关注指标有响应时间（Response Time），吞吐量（Throughput），每秒查询率（Query Per Second），并发用户数。多线程是实现高并发的的手段。本系列文章就Java并发概念和遇到的问题汇总。本文代码github地址：https://github.com/shichaogeng/01study_ThreadBase 概念运行程序会创建一个进程。但OS调度的最小单元是线程（轻量级进程）。 通过java api可以查看的当前运行的线程状况1234567891011121314151617181920212223242526package com.gengsc;import java.lang.management.ManagementFactory;import java.lang.management.ThreadInfo;import java.lang.management.ThreadMXBean;/** * shichaogeng * 创建日期：2017/11/26 * 创建时间: 20:08 * 一个java程序包含的线程 */public class ShowMainThread &#123; public static void main(String[] args) &#123; //java虚拟机的线程管理接口 ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean(); //获取线程信息的方法 ThreadInfo[] threadInfos = threadMXBean.dumpAllThreads(false,false); for(ThreadInfo threadInfo:threadInfos)&#123; System.out.println(threadInfo.getThreadId()+":"+threadInfo.getThreadName()); &#125; &#125;&#125; 运行程序，查看打印结果（普通的java程序包含的线程）：1234566:Monitor Ctrl-Break //监听中断信号ctrl+c5:Attach Listener //获取内存dump,线程dump4:Signal Dispatcher //将信号分给jvm的线程3:Finalizer //调用对象的finalizer 方法 2:Reference Handler //清除Reference1:main //程序的主入口 为什么要用线程？ 充分利用多处理核心；提高cpu利用率，尽量不让cpu空闲（比如，阻塞的情况cpu就一直等待，这时可以让cpu处理其他的线程） 更快的响应时间(用户订单的场景，发送邮件等部分可由其他线程执行) 线程的学习思路Java多线程知识点多，相关的类和接口比较多，学习原理，看源码牵涉的知识点多，包括有设计模式，数据结构，操作系统，cpu相关的概念和定义。线程知识点本身的难度也高。 建议学习路线：1牢牢记住相关的概念和定义-&gt;多写代码，多用-&gt;了解原理-&gt;看看源码 启动线程和退出线程创建线程的方法12extends Threadimplements Runnable 查看Thread的源码1234567891011121314/* What will be run. */private Runnable target;public Thread(Runnable target) &#123; //省略了好大一片 this.target = target;&#125;@Overridepublic void run() &#123; if (target != null) &#123; target.run(); &#125;&#125; 当使用Runnable接口的时候需要通过构造传给target然后Thread#run()执行target.run() 继承Thread类就直接重写了run()方法。 启动线程threadl类的start() 线程完成 run()方法执行完成 抛出一个未处理的异常导致线程的提前结束 取消和中断不安全的取消单独使用一个取消标志位，如123456789101112131415161718192021222324252627282930313233343536package com.gengsc.interrupt;/** * shichaogeng * 创建日期：2017/11/26 * 创建时间: 20:32 * 使用自定义的取消标志位中断线程（不安全） */public class FlagCancel &#123; private static class TestRunable implements Runnable&#123; private volatile boolean on = true; private long i =0; @Override public void run() &#123; while(on)&#123; i++; //阻塞方法，on不起作用 //wait,sleep,blockingqueue(put,take) try &#123; Thread.sleep(20000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println("TestRunable is runing :"+i); &#125; public void cancel()&#123; on = false; &#125; &#125;&#125; Stop(),suspend(),resume()是过期的API，很大的副作用，容易导致死锁或者数据不一致12suspend的使线程进入睡眠状态，占用锁而不释放，容易造成死锁stop直接停止线程，数据处理到一半，容易导致共享数据结构不一致。 如何安全的终止线程使用线程的中断 : interrupt() 中断线程，本质是将线程的中断标志位设为true，其他线程向需要中断的线程打个招呼。是否真正进行中断由线程自己决定。 isInterrupted() 线程检查自己的中断标志位 静态方法Thread.interrupted() 重新设置中断状态，并返回之前的值。 看下源码说到底Thread#isInterrupted()方法12345public static boolean interrupted() &#123; return currentThread().isInterrupted(true);//注意这里的true，表示清空中断状态 //native方法 private native boolean isInterrupted(boolean ClearInterrupted);&#125; 由上面的中断机制可知Java里是没有抢占式任务，只有协作式任务（中不中断由线程自己决定，其他线程不能强行中断）。 为何要用中断，线程处于阻塞（如调用了java的sleep(),wait()等等方法时）的时候，是不会理会我们自己设置的取消标志位的，但是这些阻塞方法都会检查线程的中断标志位。 又找到一个特别赞的文章：处理 InterruptedException 里面对中断做了详尽的介绍，我简短总结下： 机制：123像windows任务管理一样的可以强行取消别的进程的这种叫抢占式机制而java中断是一种协作机制，它允许一个线程请求另一个线程停止它正在做的事情。这时，被中断的线程不一定要立即停止正在做的事情。相反，中断是礼貌地请求另一个线程在它愿意并且方便的时候停止它正在做的事情 好处：12中断允许被中断线程清理正在进行的工作，而不是强行结束从而造成共享的数据结构的不一致现象 中断流程1如果被中断的线程在执行一个低级可中断阻塞方法，例如 Thread.sleep()、 Thread.join() 或 Object.wait()，那么它将取消阻塞,清除中断状态，并抛出 InterruptedException。可以理解为这些方法会隐含调用Thread.interrputed()方法。否则， interrupt() 只是设置线程的中断状态。 在被中断线程中运行的代码以后可以轮询中断状态 InterruptedException异常1当一个方法抛出 InterruptedException 时，它是在告诉您，如果执行该方法的线程被中断，它将尝试停止它正在做的事情而提前返回，并通过抛出 InterruptedException 表明它提前返回。 阻塞函数1阻塞方法的入口例如blockqueue.put()方法入口会轮询中断状态 阻塞函数为什么要抛出InterruptedException异常1因为它们不会再自己的线程中执行，它们需要抛出异常告诉调用者中断情况，从而使栈中的上层代码可以采取响应的操纵。 InterruptedException异常的处理方法123456789101. （传递异常）抛出给调用者2. （恢复中断）Runnable代码不能抛出中断，这时需要捕捉中断异常并恢复中断状态，这样调用者才能看到一个中断，并对此中断做出响应。比如shutdown啥的。try &#123; //...&#125; catch (InterruptedException e) &#123; // Restore the interrupted status Thread.currentThread().interrupt();&#125;3. 不能捕捉中断而神马都不做，导致调用栈的代码无法对中断做出响应4. Thread类自己可以捕捉中断异常而不处理（不懂） 代码，看明白了这个就明白了1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package com.gengsc.interrupt;/** * shichaogeng * 创建日期：2017/11/26 * 创建时间: 21:02 * 调用阻塞方法时，如何中断线程 */public class BlockInterrupt &#123; private static Object o = new Object(); /*while循环中包含try/catch块*/ private static class WhileTryWhenBlock extends Thread &#123; private volatile boolean on = true; private long i =0; @Override public void run() &#123; System.out.println("当前执行线程id："+Thread.currentThread().getId()); while (on &amp;&amp; !Thread.currentThread().isInterrupted()) &#123; System.out.println("i="+i++); try &#123; //抛出中断异常的阻塞方法，抛出异常后，中断标志位会改成false //可以理解为这些方法会隐含调用Thread.interrputed()方法 synchronized (o)&#123; o.wait(); &#125; &#125; catch (InterruptedException e) &#123; System.out.println("当前执行线程的中断标志位：" +Thread.currentThread().getId() +":"+Thread.currentThread().isInterrupted()); Thread.currentThread().interrupt();//重新设置一下，不然while循环不会结束 System.out.println("被中断的线程_"+getId() +":"+isInterrupted()); //do my work &#125; //清理工作，准备结束线程 &#125; &#125; public void cancel() &#123; //on = false; interrupt(); System.out.println("本方法所在线程实例："+getId()); System.out.println("执行本方法的线程："+Thread.currentThread().getId()); //Thread.currentThread().interrupt(); &#125; &#125; /*try/catch块中包含while循环*/ private static class TryWhileWhenBlock extends Thread &#123; private volatile boolean on = true; private long i =0; @Override public void run() &#123; try &#123; while (on) &#123; System.out.println(i++); //抛出中断异常的阻塞方法，抛出异常后，中断标志位改成false synchronized (o)&#123; o.wait(); &#125; &#125; &#125; catch (InterruptedException e) &#123; System.out.println("当前执行线程的中断标志位：" +Thread.currentThread().getId() +":"+Thread.currentThread().isInterrupted()); &#125;finally &#123; //清理工作结束线程 &#125; &#125; public void cancel() &#123; on = false; interrupt(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; WhileTryWhenBlock whileTryWhenBlock = new WhileTryWhenBlock(); whileTryWhenBlock.start(); Thread.sleep(100); whileTryWhenBlock.cancel(); /*TryWhileWhenBlock tryWhileWhenBlock = new TryWhileWhenBlock(); tryWhileWhenBlock.start(); Thread.sleep(100); tryWhileWhenBlock.cancel();*/ &#125;&#125; 处理不可中断的阻塞IO通信 inputstream read/write等阻塞方法，不会理会中断，而关闭底层的套接字socket.close()会抛出socketException NIO： selector.select()会阻塞，调用selector的wakeup和close方法会抛出ClosedSelectorException 死锁状态不响应中断的请求，这个必须重启程序，修改错误。 如何让我们的代码既可以响应普通的中断，又可以关闭底层的套接字呢？覆盖线程的interrupt方法，在处理套接字异常时，再用super.interrupt()自行中断线程123456789101112131415161718192021222324252627282930313233343536373839package com.gengsc.interrupt;import java.io.IOException;import java.io.InputStream;import java.net.Socket;/** * shichaogeng * 创建日期：2017/11/26 * 创建时间: 21:00 * 如何覆盖线程的interrupt() 方法 */public class OverrideInterrupt extends Thread &#123; private final Socket socket; private final InputStream in; public OverrideInterrupt(Socket socket, InputStream in) &#123; this.socket = socket; this.in = in; &#125; private void t()&#123; &#125; @Override public void interrupt() &#123; try &#123; //关闭底层的套接字 socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); //..... &#125;finally &#123; //同时中断线程 super.interrupt(); &#125; &#125;&#125; 线程的状态新创建 线程被创建，但是没有调用start方法可运行（RUNNABLE） 运行状态，由cpu决定是不是正在运行被阻塞（BLOCKING） 阻塞，线程被阻塞于锁等待/计时等待（WAITING） 等待某些条件成熟被终止 线程执行完毕 运行中断的几种状态12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package com.gengsc.threadstate;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * shichaogeng * 创建日期：2017/11/15 * 创建时间: 17:12 * 查看线程的状态 */public class ThreadState &#123; private static Lock lock = new ReentrantLock(); public static void main(String[] args) &#123; new Thread(new SleepAlways(), &quot;SleepAlwaysThread&quot;).start(); new Thread(new Waiting(), &quot;WaitingThread&quot;).start(); // 使用两个Blocked线程，一个获取锁成功，另一个被阻塞 new Thread(new Blocked(), &quot;BlockedThread-1&quot;).start(); new Thread(new Blocked(), &quot;BlockedThread-2&quot;).start(); new Thread(new Sync(), &quot;SyncThread-1&quot;).start(); new Thread(new Sync(), &quot;SyncThread-2&quot;).start(); &#125; /** * 该线程不断的进行睡眠 */ static class SleepAlways implements Runnable &#123; @Override public void run() &#123; while (true) &#123; SleepUtils.second(100); &#125; &#125; &#125; /** * 该线程在Waiting.class实例上等待 */ static class Waiting implements Runnable &#123; @Override public void run() &#123; while (true) &#123; synchronized (Waiting.class) &#123; try &#123; Waiting.class.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; /** * 该线程在Blocked.class实例上加锁后，不会释放该锁 */ static class Blocked implements Runnable &#123; public void run() &#123; synchronized (Blocked.class) &#123; while (true) &#123; SleepUtils.second(100); &#125; &#125; &#125; &#125; /** * 该线程获得锁休眠后，又释放锁 */ static class Sync implements Runnable &#123; @Override public void run() &#123; lock.lock(); try &#123; SleepUtils.second(3000); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;&#125; 查看堆栈信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139D:\Develop\Java\jdk1.8.0_101\bin\java &quot;-javaagent:D:\JetBrains\IntelliJ IDEA 2017.2.5\lib\idea_rt.jar=57911:D:\JetBrains\IntelliJ IDEA 2017.2.5\bin&quot; -Dfile.encoding=UTF-8 -classpath D:\Develop\Java\jdk1.8.0_101\jre\lib\charsets.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\deploy.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\ext\access-bridge-64.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\ext\cldrdata.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\ext\dnsns.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\ext\jaccess.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\ext\jfxrt.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\ext\localedata.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\ext\nashorn.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\ext\sunec.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\ext\sunjce_provider.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\ext\sunmscapi.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\ext\sunpkcs11.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\ext\zipfs.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\javaws.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\jce.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\jfr.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\jfxswt.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\jsse.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\management-agent.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\plugin.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\resources.jar;D:\Develop\Java\jdk1.8.0_101\jre\lib\rt.jar;F:\BaiduYunDownload\多线程\019-多线程（基础）-20171126-Mark\01study_ThreadBase\01study_ThreadBase\out\production\01ThreadBase com.gengsc.threadstate.ThreadState2017-11-30 16:41:16Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.101-b13 mixed mode):&quot;DestroyJavaVM&quot; #17 prio=5 os_prio=0 tid=0x0000000002b7e800 nid=0x4c8 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE&quot;SyncThread-2&quot; #16 prio=5 os_prio=0 tid=0x000000001b3e0000 nid=0x1778 waiting on condition [0x000000001c49f000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at java.lang.Thread.sleep(Thread.java:340) at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386) at com.gengsc.threadstate.SleepUtils.second(SleepUtils.java:11) at com.gengsc.threadstate.ThreadState$Sync.run(ThreadState.java:77) at java.lang.Thread.run(Thread.java:745)&quot;SyncThread-1&quot; #15 prio=5 os_prio=0 tid=0x000000001b3df000 nid=0x5dc waiting on condition [0x000000001c39f000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x0000000780868570&gt; (a java.util.concurrent.locks.ReentrantLock$NonfairSync) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(AbstractQueuedSynchronizer.java:870) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:1199) at java.util.concurrent.locks.ReentrantLock$NonfairSync.lock(ReentrantLock.java:209) at java.util.concurrent.locks.ReentrantLock.lock(ReentrantLock.java:285) at com.gengsc.threadstate.ThreadState$Sync.run(ThreadState.java:75) at java.lang.Thread.run(Thread.java:745)&quot;BlockedThread-2&quot; #14 prio=5 os_prio=0 tid=0x000000001b3d6800 nid=0x2348 waiting for monitor entry [0x000000001c29f000] java.lang.Thread.State: BLOCKED (on object monitor) at com.gengsc.threadstate.ThreadState$Blocked.run(ThreadState.java:62) - waiting to lock &lt;0x0000000780873378&gt; (a java.lang.Class for com.gengsc.threadstate.ThreadState$Blocked) at java.lang.Thread.run(Thread.java:745)&quot;BlockedThread-1&quot; #13 prio=5 os_prio=0 tid=0x000000001b3d5800 nid=0x7b4 waiting on condition [0x000000001c19f000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at java.lang.Thread.sleep(Thread.java:340) at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386) at com.gengsc.threadstate.SleepUtils.second(SleepUtils.java:11) at com.gengsc.threadstate.ThreadState$Blocked.run(ThreadState.java:62) - locked &lt;0x0000000780873378&gt; (a java.lang.Class for com.gengsc.threadstate.ThreadState$Blocked) at java.lang.Thread.run(Thread.java:745)&quot;WaitingThread&quot; #12 prio=5 os_prio=0 tid=0x000000001b3d4000 nid=0x1458 in Object.wait() [0x000000001c09f000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x000000078086f898&gt; (a java.lang.Class for com.gengsc.threadstate.ThreadState$Waiting) at java.lang.Object.wait(Object.java:502) at com.gengsc.threadstate.ThreadState$Waiting.run(ThreadState.java:46) - locked &lt;0x000000078086f898&gt; (a java.lang.Class for com.gengsc.threadstate.ThreadState$Waiting) at java.lang.Thread.run(Thread.java:745)&quot;SleepAlwaysThread&quot; #11 prio=5 os_prio=0 tid=0x000000001b3cf000 nid=0x22e0 waiting on condition [0x000000001bf9f000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at java.lang.Thread.sleep(Thread.java:340) at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386) at com.gengsc.threadstate.SleepUtils.second(SleepUtils.java:11) at com.gengsc.threadstate.ThreadState$SleepAlways.run(ThreadState.java:32) at java.lang.Thread.run(Thread.java:745)&quot;Service Thread&quot; #10 daemon prio=9 os_prio=0 tid=0x000000001b371000 nid=0x430 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE&quot;C1 CompilerThread2&quot; #9 daemon prio=9 os_prio=2 tid=0x000000001b350000 nid=0x1570 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE&quot;C2 CompilerThread1&quot; #8 daemon prio=9 os_prio=2 tid=0x000000001b2f3800 nid=0x93c waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE&quot;C2 CompilerThread0&quot; #7 daemon prio=9 os_prio=2 tid=0x000000001b2f1800 nid=0xe0 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE&quot;Monitor Ctrl-Break&quot; #6 daemon prio=5 os_prio=0 tid=0x000000001b2f0000 nid=0xa90 runnable [0x000000001b99f000] java.lang.Thread.State: RUNNABLE at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) at java.net.SocketInputStream.read(SocketInputStream.java:170) at java.net.SocketInputStream.read(SocketInputStream.java:141) at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284) at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326) at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178) - locked &lt;0x000000078092b6f0&gt; (a java.io.InputStreamReader) at java.io.InputStreamReader.read(InputStreamReader.java:184) at java.io.BufferedReader.fill(BufferedReader.java:161) at java.io.BufferedReader.readLine(BufferedReader.java:324) - locked &lt;0x000000078092b6f0&gt; (a java.io.InputStreamReader) at java.io.BufferedReader.readLine(BufferedReader.java:389) at com.intellij.rt.execution.application.AppMainV2$1.run(AppMainV2.java:64)&quot;Attach Listener&quot; #5 daemon prio=5 os_prio=2 tid=0x0000000019f9e000 nid=0x28d8 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE&quot;Signal Dispatcher&quot; #4 daemon prio=9 os_prio=2 tid=0x0000000019f54000 nid=0x118 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE&quot;Finalizer&quot; #3 daemon prio=8 os_prio=1 tid=0x0000000019f2a800 nid=0x11d0 in Object.wait() [0x000000001b29e000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000780708ee0&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143) - locked &lt;0x0000000780708ee0&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164) at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)&quot;Reference Handler&quot; #2 daemon prio=10 os_prio=2 tid=0x0000000019f09000 nid=0x29c8 in Object.wait() [0x000000001b19e000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x0000000780706b50&gt; (a java.lang.ref.Reference$Lock) at java.lang.Object.wait(Object.java:502) at java.lang.ref.Reference.tryHandlePending(Reference.java:191) - locked &lt;0x0000000780706b50&gt; (a java.lang.ref.Reference$Lock) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)&quot;VM Thread&quot; os_prio=2 tid=0x0000000019f08000 nid=0x2ba8 runnable &quot;GC task thread#0 (ParallelGC)&quot; os_prio=0 tid=0x0000000002d97800 nid=0x28ac runnable &quot;GC task thread#1 (ParallelGC)&quot; os_prio=0 tid=0x0000000002d99000 nid=0x28a4 runnable &quot;GC task thread#2 (ParallelGC)&quot; os_prio=0 tid=0x0000000002d9a800 nid=0x151c runnable &quot;GC task thread#3 (ParallelGC)&quot; os_prio=0 tid=0x0000000002d9c000 nid=0x1774 runnable &quot;VM Periodic Task Thread&quot; os_prio=2 tid=0x000000001b38e000 nid=0x1ccc waiting on condition JNI global references: 33Heap PSYoungGen total 57344K, used 6881K [0x0000000780700000, 0x0000000784700000, 0x00000007c0000000) eden space 49152K, 14% used [0x0000000780700000,0x0000000780db8720,0x0000000783700000) from space 8192K, 0% used [0x0000000783f00000,0x0000000783f00000,0x0000000784700000) to space 8192K, 0% used [0x0000000783700000,0x0000000783700000,0x0000000783f00000) ParOldGen total 131072K, used 0K [0x0000000701400000, 0x0000000709400000, 0x0000000780700000) object space 131072K, 0% used [0x0000000701400000,0x0000000701400000,0x0000000709400000) Metaspace used 3363K, capacity 4566K, committed 4864K, reserved 1056768K class space used 371K, capacity 390K, committed 512K, reserved 1048576K 自己悟吧！ 关于状态可以看这里：Thread状态转换 线程的优先级成员变量priority控制优先级，范围1-10之间，数字越高优先级越高，缺省为5，创建线程时setPriotity（）可以设置优先级，不要指望他发挥作用。线程优先级由java虚拟机来决定，看人家怎么设计的。 Daemon线程守护型线程（如GC线程），程序里没有非Daemon线程时，java程序就会退出。一般用不上，也不建议我们平时开发时使用，因为Try/Finally里的代码不一定执行的。1234567891011121314151617181920212223242526272829package com.gengsc;import com.gengsc.threadstate.SleepUtils;/** * shichaogeng * 创建日期：2017/11/26 * 创建时间: 12:00 * 守护线程 */public class Daemon &#123; public static void main(String[] args) &#123; Thread thread = new Thread(new DaemonRunner()); thread.setDaemon(true); thread.start(); &#125; static class DaemonRunner implements Runnable &#123; @Override public void run() &#123; try &#123; SleepUtils.second(100); &#125; finally &#123; //finally里的代码不一定执行，因为虚拟机可能先退出了 System.out.println(&quot;DaemonThread finally run.&quot;); &#125; &#125; &#125;&#125; 具体理解请异步：java的守护线程与非守护线程 常用api深入理解run()和start()run就是一个普通的方法，跟其他类的实例方法没有任何区别。123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.gengsc;/** * shichaogeng * 创建日期：2017/11/26 * 创建时间: 21:51 * Run和start方法辨析 */public class RunAndStart &#123; private static class TestThread extends Thread&#123; private String name; public TestThread(String name) &#123; this.name = name; &#125; @Override public void run() &#123; int i =90; while(i&gt;0)&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;I am &quot;+Thread.currentThread().getName()+&quot; i= &quot;+i); &#125; &#125; &#125; public static void main(String[] args) &#123; /*TestThread beInvoked = new TestThread(&quot;beInvoked_thread&quot;); beInvoked.run();*/ TestThread parent = new TestThread(&quot;beInvoked&quot;); parent.setName(&quot;beInvoked_thread&quot;); parent.start(); &#125;&#125; Sleep不会释放锁，进入阻塞状态（休眠结束恢复就绪状态）.所以我们在用sleep时，要把sleep放在同步代码块的外面。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.gengsc;/** * shichaogeng * 创建日期：2017/11/26 * 创建时间: 22:00 * sleep方法是否会释放锁 */public class SleepTest &#123; //锁 private Object lock = new Object(); public static void main(String[] args) &#123; SleepTest sleepTest = new SleepTest(); Thread threadA = sleepTest.new ThreadSleep(); threadA.setName(&quot;ThreadSleep&quot;); Thread threadB = sleepTest.new ThreadNotSleep(); threadB.setName(&quot;ThreadNotSleep&quot;); threadA.start(); try &#123; Thread.sleep(1000); System.out.println(&quot; RunTest slept!&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; threadB.start(); &#125; private class ThreadSleep extends Thread&#123; @Override public void run() &#123; String threadName = Thread.currentThread().getName(); System.out.println(threadName+&quot; will take the lock&quot;); try &#123; //拿到锁以后，休眠 synchronized(lock) &#123; System.out.println(threadName+&quot; taking the lock&quot;); Thread.sleep(500000); System.out.println(&quot;Finish the work: &quot;+threadName); &#125;// Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; //e.printStackTrace(); &#125; &#125; &#125; private class ThreadNotSleep extends Thread&#123; @Override public void run() &#123; String threadName = Thread.currentThread().getName(); System.out.println(threadName+&quot; will take the lock time=&quot;+System.currentTimeMillis()); //拿到锁以后不休眠 synchronized(lock) &#123; System.out.println(threadName+&quot; taking the lock time=&quot;+System.currentTimeMillis()); System.out.println(&quot;Finish the work: &quot;+threadName); &#125; &#125; &#125;&#125; 运行结果如下1234ThreadSleep will take the lockThreadSleep taking the lock RunTest slept!ThreadNotSleep will take the lock time=1512035145141 yield()不释放锁，如果有同优先级线程，进入就绪状态当前线程出让cpu占有权，当前线程变成了可运行状态，下一时刻仍然可能被cpu选中，不会释放锁。 wait()和 notify()/notiyfAll()调用以前，当前线程必须要持有锁，调用了wait() notify()/notiyfAll()会释放锁。进入等待池（阻塞状态） notify之后进入等锁池 获取到锁进入就绪 等待通知机制：123线程 A调用了对象O的wait方法进入等待状态，线程 B调用了对象O的notify方法进行唤醒，唤醒的是在对象O上wait的线程（比如线程A）notify() 唤醒一个线程，唤醒哪一个完全看cpu的心情（谨慎使用）notiyfAll() 所有在对象O上wait的线程全部唤醒(应该用notiyfAll()) 线程间协作和通信每个线程有自己栈空间，孤立运行，对我们没有价值。如果多个线程能够相互配合完成工作，这将会带来巨大的价值。 volatile和synchronizedvolatile12345678910111213141516171819202122232425262728293031321. 先介绍JMM 主内存 各个线程的工作内存2. 然后是原子性 可见性(把修改立即刷新到主内存) 有序性(指令重排 为了提高单线程工作效率 单线程无问题 但多线程并发容易产生问题）3. volatile语义：（1）可见性线程修改之后更新到主内存线程修改之后其他线程缓存无效 CPU L1 &amp; L2（2）禁止指令重排（3）不保证原子性4.原理JVM会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写会到系统内存，并令CPU缓存失效，读取时不使用缓存而去主内存读取。这就是内存屏障（memory barrier）和volatile的关系。如果你的字段是volatile，Java内存模型将在写操作后插入一个写屏障指令，在读操作前插入一个读屏障指令。这意味着如果你对一个volatile字段进行写操作，你必须知道：1、一旦你完成写入，任何访问这个字段的线程将会得到最新的值。2、在你写入前，会保证所有之前发生的事已经发生，并且任何更新过的数据值也是可见的，因为内存屏障会把之前的写入值都刷新到缓存。那么volatile为什么没有原子性?明白了内存屏障（memory barrier）这个CPU指令，回到前面的JVM指令：从Load到store到内存屏障，一共4步，其中最后一步jvm让这个最新的变量的值在所有线程可见，也就是最后一步让所有的CPU内核都获得了最新的值，但中间的几步（从Load到Store）是不安全的，中间如果其他的CPU修改了值将会丢失。这个lock前缀指令相当于上述的内存屏障，提供了以下保证：1. 将当前CPU缓存行的数据写回到主内存；2. 这个写回内存的操作会导致在其它CPU里缓存了该内存地址的数据无效。5.应用适用场景：1、一个线程写，多个线程读；2、volatile变量的变化很固定，例如(1) 状态标识(2) AtomicInteger类中使用volatile来修饰value，保证多线程之间的可见性。(3) double check为什么要使用volatile 修饰instance？主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情:1.给 instance 分配内存2.调用 Singleton 的构造函数来初始化成员变量3.将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了）。但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。 具体可以看原文:你真的了解volatile关键字吗？ atomic是利用CAS来实现原子性操作的（Compare And Swap） synchronized关键字synchronized可以修饰方法或者以同步块的形式来进行使用，它主要确保多个线程在同一个时刻，只能有一个线程处于方法或者同步块中，它保证了线程对变量访问的可见性和排他性，又称为内置锁机制。Synchronized的类锁和对象锁，本质上是两把锁，类锁实际锁的是每一个类的class对象。对象锁锁的是当前对象实例。 使用javap反编译java的字节码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//代码，没有synchronizedpackage com.gengsc.syn;/** * shichaogeng * 创建日期：2017/11/28 * 创建时间: 20:39 */public class SynDetail &#123; public static void main(String[] args) &#123; /*synchronized (SynDetail.class)&#123; //do my work &#125;*/ &#125;&#125;//反编译，javap -v SynDetail.class，看下main方法public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=0, locals=1, args_size=1 0: return//可以看到，直接返回 //代码，带synchronizedpackage com.gengsc.syn;/** * shichaogeng * 创建日期：2017/11/28 * 创建时间: 20:39 */public class SynDetail &#123; public static void main(String[] args) &#123; synchronized (SynDetail.class)&#123; //do my work &#125; &#125;&#125;//反编译，javap -v SynDetail.class，看下main方法 public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: ldc #2 // class com/gengsc/syn/SynDetail 2: dup 3: astore_1 4: monitorenter//注意这里 5: aload_1 6: monitorexit//注意这里 7: goto 15 10: astore_2 11: aload_1 12: monitorexit 13: aload_2 14: athrow 15: return Exception table: from to target type 5 7 10 any 10 13 10 any synchronized是JVM实现的一种锁，其中锁的获取和释放分别是monitorenter和monitorexit指令，该锁在实现上分为了偏向锁、轻量级锁和重量级锁，其中偏向锁在1.6是默认开启的，轻量级锁在多线程竞争的情况下会膨胀成重量级锁，有关锁的数据都保存在对象头中… 在内部的监视器Monitor中有个存储id的数据结构。对象头的Lockword-&gt;Monitor-&gt;Owner(ThreadId) 偏向锁1会在对象头中存储当前线程id，访问之前只需查看对象头中存储的是否为当前线程。 轻量锁123获取锁的两种方式：1.无状态（标识01）的锁膨胀获取对象锁2.对象处于膨胀状态（标识00），但是Lockword指向为NULL，可以通过原子指令将Owner设为自己标识来指定 博客这里，有时间再看吧，好烦：深入浅出synchronized 等待和通知机制等待方原则：1、获取对象锁2、如果条件不满足，调用对象的wait方法，被通知后依然要检查条件是否满足3、条件满足以后，才能执行相关的业务逻辑123456Synchronized(对象)&#123; While(条件不满足)&#123; 对象.wait(); &#125; //业务逻辑处理&#125; 通知方原则：1、 获得对象的锁；2、 改变条件；3、 通知所有等待在对象的线程1234Synchronized(对象)&#123; //业务逻辑处理，改变条件 对象.notify/notifyAll();&#125; 阻塞队列简单实现12345678910111213141516171819202122232425262728293031323334353637383940414243package com.gengsc.bq;import java.util.LinkedList;import java.util.List;/** * shichaogeng * 创建日期：2017/11/28 * 创建时间: 21:07 * 有界阻塞队列 */public class BlockingQueueWN&lt;T&gt; &#123; private List queue = new LinkedList&lt;&gt;(); private final int limit; public BlockingQueueWN(int limit) &#123; this.limit = limit; &#125; //入队 public synchronized void enqueue(T item) throws InterruptedException &#123; while(this.queue.size()==this.limit)&#123; wait(); &#125; //将数据入队，可以肯定有出队的线程正在等待 if (this.queue.size()==0)&#123; notifyAll(); &#125; this.queue.add(item); &#125; //出队 public synchronized T dequeue() throws InterruptedException &#123; while(this.queue.size()==0)&#123; wait(); &#125; if (this.queue.size()==this.limit)&#123; notifyAll(); &#125; return (T)this.queue.remove(0); &#125;&#125; 测试类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.gengsc.bq;/** * shichaogeng * 创建日期：2017/11/28 * 创建时间: 21:13 */public class BqTest &#123; public static void main(String[] args) &#123; BlockingQueueWN bq = new BlockingQueueWN(10); Thread threadA = new ThreadPush(bq); threadA.setName("Push"); Thread threadB = new ThreadPop(bq); threadB.setName("Pop"); threadB.start(); threadA.start(); &#125; //推数据入队列 private static class ThreadPush extends Thread&#123; BlockingQueueWN&lt;Integer&gt; bq; public ThreadPush(BlockingQueueWN&lt;Integer&gt; bq) &#123; this.bq = bq; &#125; @Override public void run() &#123; String threadName = Thread.currentThread().getName(); int i = 20; while(i&gt;0)&#123; try &#123; Thread.sleep(1000); System.out.println(" i="+i+" will push"); bq.enqueue(i--); &#125; catch (InterruptedException e) &#123; //e.printStackTrace(); &#125; &#125; &#125; &#125; //取数据出队列 private static class ThreadPop extends Thread&#123; BlockingQueueWN&lt;Integer&gt; bq; public ThreadPop(BlockingQueueWN&lt;Integer&gt; bq) &#123; this.bq = bq; &#125; @Override public void run() &#123; while(true)&#123; try &#123; System.out.println(Thread.currentThread().getName() +" will pop....."); Integer i = bq.dequeue(); System.out.println(" i="+i.intValue()+" alread pop"); &#125; catch (InterruptedException e) &#123; //e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 一篇生产消费模型的超赞文章：Java实现生产者-消费者模型 管道输入输出流文件输入输出，网络输入输出，管道输入输出流用于线程中间的数据传递，传输媒介的内存pipedOutputStream/input 面向的字节pipedReader/Writer 面向的是字符只适合线程间一对一的通信，适用范围较狭窄。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.gengsc;import java.io.IOException;import java.io.PipedReader;import java.io.PipedWriter;/** * shichaogeng * 创建日期：2017/11/28 * 创建时间: 21:40 */public class PipeTransfer &#123; private static class Print implements Runnable&#123; private PipedReader in; public Print(PipedReader in) &#123; this.in = in; &#125; @Override public void run() &#123; int receive =0; try &#123; while((receive=in.read())!=-1)&#123; System.out.println((char) receive); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) throws Exception &#123; PipedWriter out = new PipedWriter(); PipedReader in = new PipedReader(); //必须进行连接 out.connect(in); Thread t1 = new Thread(new Print(in),"PrintThread"); t1.start(); int receive =0; try &#123; while((receive=System.in.read())!=-1)&#123; out.write(receive); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; out.close(); &#125; &#125;&#125; join方法join()实际是利用了wait()，只不过它不用等待notify()/notifyAll()。a线程阻塞，等待b执行完，a进入就绪（等待子线程对象销毁，再执行） ThreadLocal本质是个map，map的键就是每个线程对象，值就是每个线程所拥有的值(当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本)。 常用方法：12345initialValue()get()set()remove()：将当前线程局部变量的值删除，这个方法是JDK5.0新增的方法。当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。 ThreadLocal拥有的这个变量，在线程之间很独立的，相互之间没有联系。内存占用相对来说比较大。 找到一篇还可以的博客：解密ThreadLocal 性能问题串行化、无锁化、异步化编程是趋势之一，比如node.js，Vert.x。黄金原则：编码时候不要考虑性能优化的事情，先正确实现业务，发现性能不行，这个时候再来考虑性能优化。 等待超时模式调用场景：调用一个方法时等待一段时间（一般来说是给定一个时间段），如果该方法能够在给定的时间段之内得到结果，那么将结果立刻返回，反之，超时返回默认结果。假设等待时间段是T，那么可以推断出在当前时间now+T之后就会超时等待持续时间：REMAINING=T。·超时时间：FUTURE=now+T。123456789101112// 对当前对象加锁public synchronized Object get(long mills) throws InterruptedException &#123; long future = System.currentTimeMillis() + mills; long remaining = mills; // 当超时大于0并且result返回值不满足要求 while ((result == null) &amp;&amp; remaining &gt; 0) &#123; wait(remaining); remaining = future - System.currentTimeMillis(); &#125; //do work return result;&#125;]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring自定义标签]]></title>
    <url>%2F2017%2F11%2F25%2Fspring%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A0%87%E7%AD%BE%2F</url>
    <content type="text"><![CDATA[最近公司用到rpc框架，准备按照dubbo自己编写个简易框架有助于理解，然而发现需要在spring中自定义标签。像啥的。然后写下记录下吧。]]></content>
      <categories>
        <category>application-frame</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq]]></title>
    <url>%2F2017%2F11%2F20%2Frabbitmq%2F</url>
    <content type="text"><![CDATA[发现不记录几天完全忘记了，还是记录下。 安装配置首先当然是安装，我参考的是这篇博客：CentOS7下RabbitMQ服务安装配置 安装过程中也遇到些麻烦，但是我忘了，哎，想起来补充吧。 文章下面的命令也可使用，比如列出所有用户1234sbin]# rabbitmqctl list_users;Listing users ...shichaogeng [administrator]guest [administrator] 下面记录下安装的过程和关键点： 安装过程 wget https://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpm rpm -Uvh erlang-solutions-1.0-1.noarch.rpm yum install epel-release yum install erlang wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.6/rabbitmq-server-3.6.6-1.el7.noarch.rpm yum install rabbitmq-server-3.6.6-1.el7.noarch.rpm 安装完成后 service rabbitmq-server start service rabbitmq-server status Rabbitmq常用端口:1231. client端通信端口： 56722. 管理端口 ： 156723. server间内部通信端口： 25672 如端口出现不能访问，使用形如以下命令开启：1firewall-cmd --add-port=15672/tcp --permanent 可能问题运行rabbitmqctl status出现Error: unable to connect to node rabbit@controller: nodedown之类问题考虑如下几种解决办法： 重启服务 12service rabbitmq-server stopservice rabbitmq-server start 检查/var/lib/rabbitmq中是否存在.erlang.cookie，没有则新建一个，里面随便输入一段字符串 重新安装服务 管理rabbitmq日志一般放在：12/var/log/rabbitmq/rabbit@centosvm.log/var/log/rabbitmq/rabbit@centosvm-sasl.log 管理虚拟主机12rabbitmqctl add_vhosts [vhost_name] rabbitmqctl list_vhosts 启动和关闭rabbitmq1234rabbitmq-server会启动Erlang节点和Rabbitmq应用rabbitmqctl stop会关闭Erlang节点和Rabbitmq应用rabbitmqctl stop_app关闭Rabbitmq应用rabbitmqctl start_app启动Rabbitmq应用 Rabbitmq配置文件放在/etc/rabbitmq 下，名为rabbitmq.config，没有且需要使用则可以自己新建一个。 用户管理12rabbitmqctl add_user [username] [pwd]rabbitmqctl delete_user [username] 用户权限控制1rabbitmqctl set_permissions [-p &lt;vhostpath&gt;] &lt;user&gt; &lt;conf&gt; &lt;write&gt; &lt;read&gt; 如用户Mark在虚拟主机logHost上的所有权限：1rabbitmqctl set_permissions –p logHost Mark “.*” “.*” “.*” 查看Rabbitmq统计信息查看队列rabbitmqctl list_queues 查看交换器rabbitmqctl list_exchanges 查看绑定rabbitmqctl list_bindings 消息中间件有些什么使用场景？ 异步处理 用户注册（50ms），还需发送邮件（50ms）和短信（50ms）串行：（150ms）用户注册—》发送邮件—-》发送短信并行（100ms）：用户注册—》发送邮件 |----》发送短信 消息中间件（56ms）：用户注册（50ms）—》（6ms）消息中间件《—–发送邮件《—–发送短信 应用的解耦 订单系统—》库存系统（强耦合）消息中间件：订单系统—》消息中间件《—-库存系统（解耦） 流量的削峰 用户请求—–》秒杀应用应用的前端加入消息队列用户请求—–》消息队列《—-秒杀应用 日志处理 错误日志—》消息队列《—-日志处理用户行为日志–》消息队列(kafka)《—–日志的存储或流式处理 纯粹的消息通信 需要注意的问题如果消息达到无人订阅的队列会怎么办？1消息会一直在队列中等待，rabbitmq会默认队列是无限长度的。 多个消费者订阅到同一队列怎么办？1消息会轮询的方式发送给消费者，每个消息只会发送给一个消费者 消息路由到了不存在的队列怎么办？1会忽略，当消息不存在，消息丢失了。 消息的确认机制消费者收到的每一条消息都必须进行确认。（分为自动确认和消费者自行确认） 消费者在声明队列时，指定autoAck参数:true自动确认false时rabbitmq会等到消费者显示的发回一个ack信号才会删除消息。autoAck=false，有足够时间让消费者处理消息，直到消费者显示调用basicAck为止（防止消息丢失）。 Rabbitmq中消息分为了两部分：1、等待投递的消息；2、已经投递，但是还没有收到ack信号的。如果消费者断连了，服务器会把消息重新入队，投递给下一个消费者。未ack的消息是没有超时时间的。 如何明确拒绝消息？ 1、消费者断连 2、消费者使用reject命令（requeue=true,重新分发消息，false移除消息） 3、nack命令（批量的拒绝） 创建队列（生产/消费）declareQueue。消费者订阅了队列，不能再声明队列了。相关参数（exclusive 队列为应用程序私有，auto-delete 最后一个消费者取消订阅时，队列会自动删除，durable 队列持久化）检测队列是否存在 Declare 时的passive参数 消息持久化1、 队列必须是持久化的2、 交换器也必须是持久化的3、 消息的投递模式必须（int型） 2 以上条件全部满足，消息才能持久化 问题：性能（下降10倍） AMQP和JMS区别： 定义 Java api 协议 Model P2P Pub/Sub Direct Fanout Topic headers 支持消息类型 5种 Byte[] 自行消息序列化，Json化 综合评价 Java系统，模型满足要求，跨平台较差 协议，天然跨平台，跨语言 为什么设计成exchange易于归类生产者不需要关心队列和消费者，实现发送方和消费方的完全解耦1比如书上介绍的，用户上传图片需要清空相册缓存，你把消息发送到一个队列可以做到，假如这是需要新加入一个需求，同时会奖励用户一定量的积分，如果你想通过直接发送到队列而不是通过exchange来实现，那么就需要更改生产方的代码，而通过exchange，发送方不需要任何更改，只需要消费者新声明队列并绑定到exchange即可。从而实现发送方和消费方的完全解耦。 与Spring集成配置文件中增加命名空间:123xmlns:rabbit=&quot;http://www.springframework.org/schema/rabbit&quot;http://www.springframework.org/schema/rabbithttp://www.springframework.org/schema/rabbit/spring-rabbit-2.0.xsd 配置文件中的配置1234561、 连接工厂配置2、 &lt;rabbit:admin&gt;3、 声明队列4、 声明交换器5、 队列和交换器进行绑定6、 生产者端要声明RabbitmqTemplate 配置可以参照这个: spring集成rabbitMq(基于topic和fanout模式) 应用场景异步处理场景：1234用户注册，写入数据库成功以后，发送邮件和短信。串行模式 ************spend time : 251ms并行模式 ************spend time : 153ms消息队列模式：************spend time : 66ms 应用解耦场景：1订单订货，通知库存系统，有库存直接扣减，没有库存，可以扣减成功，这时通知（订单系统尽快调货，采购系统尽快采购）。 设计思路：1Rpc：库存系统失败，订单系统也失败，订单与库存系统耦合性太高。 12345678Rabbitmq：写一个扣减消息，保证消息的处理这时有三个问题需要解决： 发给mq的消息必须要被接收到 事物或者发送者确认模式 Mq拿到消息后在消息被处理以前不能丢失 持久化存储 库存服务出现异常，扣减库存的消息能被其他的库存服务处理 消费者ack 如果订单系统一定要知道库存系统是否成功怎么办，库存系统和订单系统建立一个通道，由库存系统同时订单系统。 项目github地址：库存系统订单系统 发送者确认模式配置发布者确认12&lt;!-- 发布确认必须配置在CachingConnectionFactory上 --&gt;&lt;property name=&quot;publisherConfirms&quot; value=&quot;true&quot;/&gt; 咋xml中配置,在消息模板中添加两个回调处理12345678&lt;!-- 创建rabbitTemplate 消息模板类 --&gt;&lt;bean id=&quot;rabbitTemplate&quot; class=&quot;org.springframework.amqp.rabbit.core.RabbitTemplate&quot;&gt; &lt;constructor-arg ref=&quot;rabbitConnectionFactory&quot;&gt;&lt;/constructor-arg&gt; &lt;!--消息确认监听回调 --&gt; &lt;property name=&quot;confirmCallback&quot; ref=&quot;confirmCallback&quot;/&gt; &lt;!--消息发送失败返回监听回调 --&gt; &lt;property name=&quot;returnCallback&quot; ref=&quot;sendReturnCallback&quot;/&gt;&lt;/bean&gt; 发送者确认回调’confirmCallback’，需要实现RabbitTemplate内部接口RabbitTemplate.ConfirmCallback12345678910111213141516171819202122232425262728293031package com.dongnaoedu.service.callback;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.amqp.rabbit.support.CorrelationData;import org.springframework.stereotype.Service;/** * @Description * @Author shichaogeng * @Create 2017-11-21 16:37 */@Servicepublic class ConfirmCallback implements RabbitTemplate.ConfirmCallback &#123; private Logger logger = LoggerFactory.getLogger(ConfirmCallback.class); public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; if (ack) &#123; logger.info(&quot;消息确认发送给mq成功&quot;); &#125; else &#123; //处理失败的消息 /** * 一般发送的失败设计： * 先重复发送三次，如果都发送失败，存到数据库中 * 编写一个定时任务程序，开启新的线程定时处理数据库中发送失败的任务。 */ logger.info(&quot;消息发送给mq失败,考虑重发:&quot;+cause); &#125; &#125;&#125; 消息发送失败回调’returnCallback’，需要实现RabbitTemplate内部接口RabbitTemplate.ReturnCallback12345678910111213141516171819202122232425262728package com.dongnaoedu.service.callback;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.stereotype.Service;/** * @Description * @Author shichaogeng * @Create 2017-11-21 16:37 */@Servicepublic class SendReturnCallback implements RabbitTemplate.ReturnCallback &#123; private Logger logger = LoggerFactory.getLogger(SendReturnCallback.class); public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; logger.info(&quot;Returned replyText：&quot;+replyText); logger.info(&quot;Returned exchange：&quot;+exchange); logger.info(&quot;Returned routingKey：&quot;+routingKey); String msgJson = new String(message.getBody()); logger.info(&quot;Returned Message：&quot;+msgJson); &#125;&#125; 持久化存储前面有提到，想要实现消息持久化，必须满足三个条件1231、队列必须是持久化的2、交换器也必须是持久化的3、消息的投递模式必须（int型） 2 队列持久化1&lt;rabbit:queue name=&quot;depot_queue&quot; durable=&quot;true&quot;/&gt; 交换器持久化123456&lt;rabbit:direct-exchange name=&quot;depot-amount-exchange&quot; xmlns=&quot;http://www.springframework.org/schema/rabbit&quot; durable=&quot;true&quot;&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue=&quot;depot_queue&quot; key=&quot;amount.depot&quot; &gt;&lt;/rabbit:binding&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:direct-exchange&gt; 消息投递模式设为持久化1234567891011121314151617181920212223242526272829303132333435363738394041package com.dongnaoedu.service;import com.dongnaoedu.vo.GoodTransferVo;import com.google.gson.Gson;import org.springframework.amqp.core.Message;import org.springframework.amqp.core.MessageDeliveryMode;import org.springframework.amqp.core.MessageProperties;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.stereotype.Service;/** * @Description * @Author shichaogeng * @Create 2017-11-21 16:37 */@Service@Qualifier(&quot;mq&quot;)public class MqMode implements IProDepot &#123; private final static String DEPOT_RK = &quot;amount.depot&quot;; private final static String DEPOT_EXCHANGE = &quot;depot-amount-exchange&quot;; @Autowired RabbitTemplate rabbitTemplate; private static Gson gson = new Gson(); public void processDepot(String goodsId, int amount) &#123; GoodTransferVo goodTransferVo = new GoodTransferVo(); goodTransferVo.setGoodsId(goodsId); goodTransferVo.setChangeAmount(amount); goodTransferVo.setInOrOut(false); String goods = gson.toJson(goodTransferVo); MessageProperties messageProperties = new MessageProperties(); messageProperties.setDeliveryMode(MessageDeliveryMode.PERSISTENT);//PERSISTENT表示持久化的投递方式 rabbitTemplate.send(DEPOT_EXCHANGE, DEPOT_RK, new Message(goods.getBytes(), messageProperties)); &#125;&#125; 消费者确认把确认模式配置为手动确认1234&lt;!-- 对消息要手动确认 --&gt;&lt;rabbit:listener-container connection-factory=&quot;rabbitConnectionFactory&quot; acknowledge=&quot;manual&quot;&gt; &lt;rabbit:listener queues=&quot;depot_queue&quot; ref=&quot;processDepot&quot; method=&quot;onMessage&quot; /&gt;&lt;/rabbit:listener-container&gt; 消息监听类要实现’ChannelAwareMessageListener’接口1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.dongnaoedu.mq;import com.dongnaoedu.service.DepotManager;import com.dongnaoedu.vo.GoodTransferVo;import com.google.gson.Gson;import com.rabbitmq.client.Channel;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.core.ChannelAwareMessageListener;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.io.IOException;/** * shichaogeng * 创建日期：2017/10/26 * 创建时间: 17:11 * 消息机制处理库存 */@Servicepublic class ProcessDepot implements ChannelAwareMessageListener &#123; private static Logger logger = LoggerFactory.getLogger(ProcessDepot.class); @Autowired private DepotManager depotManager; private static Gson gson = new Gson(); @Override public void onMessage(Message message, Channel channel) throws Exception &#123; try &#123; String msg = new String(message.getBody()); logger.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;接收到消息:&quot;+msg); GoodTransferVo goodTransferVo = gson.fromJson(msg,GoodTransferVo.class); try &#123; depotManager.operDepot(goodTransferVo); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); logger.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;库存处理完成，应答Mq服务&quot;); &#125; catch (Exception e) &#123; logger.error(e.getMessage()); channel.basicNack(message.getMessageProperties().getDeliveryTag(), false,true);//multiple参数表示批量处理 logger.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;库存处理失败，拒绝消息，要求Mq重新派发&quot;); throw e; &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage()); &#125; &#125;&#125; RabbitMq整合Springgithub地址 RabbitMq集群一些问题內建集群的设计目标：1客户端在节点崩溃的情况下可以运行，线性扩展来扩充消息的吞吐量 可以保证消息的万无一失吗？1当一个节点崩溃了以后，节点所有队列上的消息都会丢失。默认不会将队列的消息在集群中复制。 集群中的队列1在集群中不会复制，其他节点只会保存队列所处的节点和元数据，消息的传递给队列的所有者节点。 集群中的交换器1会进行复制。本质就是一个类似于hashmap的映射表。 集群中的节点1两种：内存节点，磁盘节点。单机情况下，一定是个磁盘节点。集群里面，要求每个集群必须有至少以一个磁盘节点，出于高可用考虑，建议配两个。 集群安装本机集群(不建议安装，有条件应在多个服务器上安装)：123456789101112131415161718192021RABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit rabbitmq-server -detached RABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit_1 rabbitmq-server -detached RABBITMQ_NODE_PORT=5674 RABBITMQ_NODENAME=rabbit_2 rabbitmq-server -detached rabbitmqctl -n rabbit_1@centosvm stop_apprabbitmqctl -n rabbit_1@centosvm resetrabbitmqctl -n rabbit_1@centosvm join_cluster rabbit@centosvmrabbitmqctl -n rabbit_1@centosvm start_apprabbitmqctl cluster_statusrabbitmqctl -n rabbit_2@centosvm stop_apprabbitmqctl -n rabbit_2@centosvm resetrabbitmqctl -n rabbit_2@centosvm join_cluster rabbit@centosvm --ram rabbitmqctl -n rabbit_2@centosvm start_apprabbitmqctl cluster_status从外部要访问虚拟机中的mq记得在防火墙中打开端口firewall-cmd --add-port=5673/tcp --permanent firewall-cmd --add-port=5674/tcp --permanent rabbitmqctl add_user mq mqrabbitmqctl set_permissions mq &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;rabbitmqctl set_user_tags mq administratorrabbitmq-plugins -n rabbit_1@centosvm enable rabbitmq_management 多机下的集群 修改/etc/hosts 123192.168.1.1 node1192.168.1.2 node2192.168.1.3 node3 Erlang Cookie 文件：/var/lib/rabbitmq/.erlang.cookie。将 node1 的该文件复制到 node2、node3，由于这个文件权限是 400，所以需要先修改 node2、node3 中的该文件权限为 777，然后将 node1 中的该文件拷贝到 node2、node3，最后将权限和所属用户/组修改回来。 运行各节点 在node2、node3上分别运行 12345[root@node2 ~]# rabbitmqctl stop_app[root@node2 ~]./rabbitmqctl reset[root@node2 ~]# rabbitmqctl join_cluster rabbit@node1[root@node2 ~]# rabbitmqctl start_app内存节点则是rabbitmqctl join_cluster rabbit@node1 –ram 移除集群中的节点123[root@node2 ~]# rabbitmqctl stop_app[root@node2 ~]./rabbitmqctl reset[root@node2 ~]# rabbitmqctl start_app 镜像队列什么是镜像队列123如果RabbitMQ集群是由多个broker节点构成的，那么从服务的整体可用性上来讲，该集群对于单点失效是有弹性的，但是同时也需要注意：尽管exchange和binding能够在单点失效问题上幸免于难，但是queue和其上持有的message却不行，这是因为queue及其内容仅仅存储于单个节点之上，所以一个节点的失效表现为其对应的queue不可用。引入RabbitMQ的镜像队列机制，将queue镜像到cluster中其他的节点之上。在该实现下，如果集群中的一个节点失效了，queue能自动地切换到镜像中的另一个节点以保证服务的可用性。在通常的用法中，针对每一个镜像队列都包含一个master和多个slave，分别对应于不同的节点。slave会准确地按照master执行命令的顺序进行命令执行，故slave与master上维护的状态应该是相同的。除了publish外所有动作都只会向master发送，然后由master将命令执行的结果广播给slave们，故看似从镜像队列中的消费操作实际上是在master上执行的。RabbitMQ的镜像队列同时支持publisher confirm和事务两种机制。在事务机制中，只有当前事务在全部镜像queue中执行之后，客户端才会收到Tx.CommitOk的消息。同样的，在publisher confirm机制中，向publisher进行当前message确认的前提是该message被全部镜像所接受了。 镜像队列的使用1234567891011121314151617181920212223242526添加policyRabbitmqctl set_policy Name Pattern DefinitionName:策略的名字Pattern：队列匹配模式（正则表达式）Definition：镜像的定义：ha-mode,ha-params,ha-sycn-modeha-mode: all/exactly/nodesha-params: n表示几个节点上复制/节点名称ha-sycn-mode：automatic manual对队列名称以“queue_”队列进行镜像，只在两个节点上完成复制 Rabbitmqctl set_policy ha_queue_two “^queue_” ‘&#123;“ha-mode”:”exactly”,”ha-params”:2,”ha-sycn-mode“：“atuomatic”&#125;’在代码中也要进行编写使用HAProxy(以下步骤仅供参考) 作用：安装配置：1.下载最新haproxy安装包，官网：http://www.haproxy.org2.上传到linux的haproxy用户根目录下，并解压： tar -zxvf haproxy-1.5.8.tar.gz 创建目录/home/haproxy/haproxy3.安装cd haproxy-1.5.8make TARGET=linux26 ARCH=x86_64 PREFIX=/home/haproxy/haproxy #将haproxy安装到/home/haproxy/haproxy ,TARGET是指定内核版本make install PREFIX=/home/haproxy/haproxy 进入/home/haproxy/haproxy 目录,创建/home/haproxy/haproxy/conf目录，复制配置examplescp /home/haproxy/haproxy-1.5.8/examples/haproxy.cfg /home/haproxy/haproxy/conf/4、配置修改(以haproxy rabbitmq 配置为关键字搜索) 互联网时代的消息中间件看到一个各种假设情况的博客 消息发送一致性是指产生消息的业务动作与消息发送的一致。（如果业务操作成功，那么由这个业务操作所产生的消息一定要成功投递出去，否则就丢消息）1234567Void busi&#123;//业务操作//写库//发送消息&#125;业务成功，消息发送也要成功业务失败，消息不应该发送 可以使用事物或者amqp的发送者确认模式 消息的重复 让处理消息的服务具有幂等性 1Update a set zz = 12; Update a set zz = zz+12(无幂等性); db或者缓存保存消息的处理状况，消息id作为唯一性索引 消息中间件与RPC的关系两者并不是水火不容的关系，两者可以很好的进行融合，结合起来使用。Rpc客户端调用rpc服务，或者rpc服务返回处理结果，就完全可以通过消息中间件进行。使用消息中间件做rpc有何好处：自动将消息路由到合适的地方，通过消息中间件可以在rpc服务集群中做到负载均衡，甚至当rpc服务中某台服务挂了，可以做到自动重发。 消息中间件的缺点：消息的数据量不能太大。]]></content>
      <categories>
        <category>amqp</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己实现链表]]></title>
    <url>%2F2017%2F11%2F16%2F%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[自己实现一个链表，并对关键点进行记录。 主要有两个实现思路121.首先链表的任何操作都设计递归问题2.把操作分为重载的两个方法，其中一个增加传入节点参数，对节点进行递归操作。 贴上代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181package com.gengsc.algorithms.link;/** * @Description * @Author shichaogeng * @Create 2017-11-16 11:43 */public class RealLink&lt;Item&gt; &#123; private Node root; private int count; private int index; private Item[] array; private class Node &#123; private Item data; private Node next; public Node(Item data) &#123; this.data = data; &#125; &#125; public void add(Item item) &#123; if (item == null) return; Node node = new Node(item); if (root == null) &#123; root = node; &#125; else &#123; add(root, node); &#125; this.count++; &#125; private void add(Node current, Node newNode) &#123; if (current.next == null) &#123; current.next = newNode; &#125; else &#123; add(current.next, newNode); &#125; &#125; public void print() &#123; print(root); &#125; private void print(Node node) &#123; if (node != null) &#123; System.out.println(node.data); print(node.next); &#125; &#125; public int size() &#123; return this.count; &#125; public boolean isEmpty() &#123; return root == null; &#125; public boolean contains(Item data) &#123; if (data == null) &#123; return false; &#125; return contains(root, data); &#125; private boolean contains(Node node, Item data) &#123; if (node == null) return false; if (data.equals(node.data)) &#123; return true; &#125; else &#123; return contains(node.next, data); &#125; &#125; public Item get(int index) &#123; if (index &gt; (this.count - 1) || index &lt; 0) &#123; return null; &#125; //索引从0开始 this.index = 0; return get(this.root, index); &#125; private Item get(Node node, int index) &#123; if (index == this.index++) &#123; return node.data; &#125; else if (node.next != null) &#123; return get(node.next, index); &#125; return null; &#125; public void set(int index, Item data) &#123; if (index &gt; (this.count - 1) || index &lt; 0) &#123; return; &#125; this.index = 0; set(this.root, index, data); &#125; private void set(Node node, int index, Item data) &#123; if (index == this.index++) &#123; node.data = data; &#125; else if (node.next != null) &#123; set(node.next, index, data); &#125; &#125; /** * 删除节点分为两种情况 * 1.删除的节点为根节点，需要root = root.next * 2.删除的节点不在根节点，需要preNode.next = currNode.next; * @param data */ public void remove(Item data) &#123; if (!contains(data)) return; //分两种情况，1.在根节点中2.不在根节点中 if (data.equals(this.root.data)) &#123; this.root = this.root.next; &#125; else &#123; remove(this.root, this.root.next, data); &#125; this.count--; &#125; private void remove(Node pre, Node current, Item data) &#123; if (data.equals(current.data)) &#123; pre.next = current.next; &#125; else &#123; remove(current, current.next, data); &#125; &#125; public Item[] toArray() &#123; if (isEmpty()) return null; this.index = 0; this.array = (Item[]) new Object[this.count]; toArray(this.root); return this.array; &#125; private void toArray(Node node) &#123; if (node == null) return; array[index++] = node.data; toArray(node.next); &#125; /** * 分为两种情况 * 1. 只有一个节点，在根节点中，直接删除根节点root = null * 2. 两个及以上节点，递归找到currNode.next == null,删除当前节点preNode.next = null */ public void removeLast() &#123; if (this.isEmpty()) &#123; return; &#125; if (this.root.next == null) &#123; this.root = null; &#125; else &#123; removeLast(this.root, this.root.next); &#125; this.count--; &#125; private void removeLast(Node preNode, Node currNode) &#123; if (currNode.next == null) &#123; preNode.next = null; &#125; else &#123; removeLast(currNode, currNode.next); &#125; &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>Algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java-concurrent]]></title>
    <url>%2F2017%2F11%2F14%2Fjava-concurrent%2F</url>
    <content type="text"><![CDATA[对遇到的并发问题汇总整理和一些常见的面试题的总结 Synchronized的实现原理ynchronized是JVM实现的一种锁，其中锁的获取和释放分别是monitorenter和monitorexit指令，该锁在实现上分为了偏向锁、轻量级锁和重量级锁，其中偏向锁在1.6是默认开启的，轻量级锁在多线程竞争的情况下会膨胀成重量级锁，有关锁的数据都保存在对象头中… 在内部的监视器Monitor中有个存储id的数据结构。对象头的Lockword-&gt;Monitor-&gt;Owner(ThreadId) 偏向锁1会在对象头中存储当前线程id，访问之前只需查看对象头中存储的是否为当前线程。 轻量锁123获取锁的两种方式：1.无状态（标识01）的锁膨胀获取对象锁2.对象处于膨胀状态（标识00），但是Lockword指向为NULL，可以通过原子指令将Owner设为自己标识来指定 博客这里，有时间再看吧，好烦：深入浅出synchronized AQS象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch…。 队列同步器AQS是用来构建锁或其他同步组件的基础框架，内部使用一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作，其中内部状态state，等待队列的头节点head和尾节点head，都是通过volatile修饰，保证了多线程之间的可见。 访问资源acquire方法，贴上源码12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 处理流程如下： 释放资源release方法… 哎，具体的看这里吧：Java并发之AQS详解 阻塞与等待的区别阻塞1当一个线程试图获取对象锁（非java.util.concurrent库中的锁，即synchronized），而该锁被其他线程持有，则该线程进入阻塞状态。它的特点是使用简单，由JVM调度器来决定唤醒自己，而不需要由另一个线程来显式唤醒自己，不响应中断。 等待1当一个线程等待另一个线程通知调度器一个条件时，该线程进入等待状态。它的特点是需要等待另一个线程显式地唤醒自己，实现灵活，语义更丰富，可响应中断。例如调用：Object.wait()、Thread.join()以及等待Lock或Condition。 需要强调的是虽然synchronized和JUC里的Lock都实现锁的功能，但线程进入的状态是不一样的。synchronized会让线程进入阻塞态，而JUC里的Lock是用LockSupport.park()/unpark()来实现阻塞/唤醒的，会让线程进入等待态。但话又说回来，虽然等锁时进入的状态不一样，但被唤醒后又都进入runnable态，从行为效果来看又是一样的。 关于状态可以看这里：Thread状态转换 线程状态变换APIsleep1不释放锁，进入阻塞状态（休眠结束恢复就绪状态） a.join(b)1join()实际是利用了wait()，只不过它不用等待notify()/notifyAll()。a线程阻塞，等待b执行完，a进入就绪（等待子线程对象销毁，再执行） yield1不释放锁，如果有同优先级线程，进入就绪状态 wait1释放锁，进入等待池（阻塞状态） notify之后进入等锁池 获取到锁进入就绪 CASCAS原理123456789CAS有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，将内存值修改为B并返回true，否则什么都不做并返回false。AtomicInteger如何使用cas：1. 首先，要获取value内存偏移量，并用volatile修饰保证value的可见性。2. 当累加操作时，比较线程副本中的值，与内存偏移量上面的值是否相同(1). 相同，修改值为新值(2). 不同，从新获取内存偏移量对应的值（主内存中的值）cas方法是一个native,源码用c++编写，禁止指令重排和刷新到主内存 具体情况，可以点这里的链接：java中的CAS CAS指令缺点1CAS存在ABA问题，一个变量初次读取时A，再次检查发现还是A，有可能被修改过，要解决这个问题，可以使用带有标记的原子引用类AtomicStampedReference，他可以控制变量的版本来保证CAS。 线程池如何设置线程池的大小123cpu核数 内存大小 cpu密集型还是io密集型 有没有其他的资源限制 比如说数据库连接池 任务是同构还是异构 是独立的还是相互依赖的计算越密集 线程数设的越小 io越密集 为了防止线程在阻塞时cpu空闲造成资源的浪费 应加大线程池数量 让cpu忙碌起来 线程池的构造类的五个参数的具体意义是什么？1234567corePoolSize 线程池的线程数量maximumPoolSize 允许的最大线程数keepAliveTime 超过coreSize的线程空闲的最大时间unit 时间单位workQueue 工作队列初始化无线程，然后创建线程直到线程池满，然后放入工作队列，工作队列满，然后创建线程直到最大线程数，线程闲置超时即销毁直到核心线程数。 单机上一个线程池突然断电的处理机制（正在处理的请求和阻塞队列里的请求如何处理）12shutdown方法，平滑的关闭，不再接受新的任务，同时等待提交任务完成。shutdownNow方法，粗暴的关闭，尝试取消实行的任务，并不再启动未开始执行的任务。返回等待执行的任务。 栅栏机制1所有线程必须到达栅栏的位置才能继续执行，等待其他线程到达之前一直阻塞。 队列使用无界阻塞队列会出现什么问题1newFixedThreadPool 使用的是无界LinkedBlokingQueue 如果任务到达速率高于处理速度,那么工作队列会无限制的增加,最终导致内存耗尽 有界队列1234567在使用有界队列时,可以解决资源耗尽的问题,然而,队列满了之后如何处理就要看[饱和策略了].而且,使用有界队列时,线程池大小要与队列大小一同调节,如果线程池小而队列大,那么可以节省内存,降低cpu的使用率,减少上下文切换,但是也限制了服务器的吞吐量newCachedThreadPool使用Synchrnous Queue作为工作队列 synchrnous不是一个真正的队列,他用于把一个任务从一个线程移交到另外一个线程.synchrnous比LinkedBlokingQueue有更好的性能 设置有界的队列不适合相互依赖的任务,会导致线程"饥饿"死锁问题另一种解决方式是用Synchrnous Queue有界队列,并使用caller-runs饱和策略(不懂) 如何保证共享变量修改时的原子性1synchronized lock volatile123456789101112131415161718191. 先介绍JMM 主内存 各个线程的工作内存2. 然后是原子性 可见性(把修改立即刷新到主内存) 有序性(指令重排 为了提高单线程工作效率 单线程无问题 但多线程并发容易产生问题）3. volatile语义：（1）可见性线程修改之后更新到主内存线程修改之后其他线程缓存无效 CPU L1 &amp; L2（2）禁止指令重排（3）不保证原子性4.原理JVM会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写会到系统内存，并令CPU缓存失效，读取时不使用缓存而去主内存读取5.应用(1) 状态标识(2) AtomicInteger类中使用volatile来修饰value，保证多线程之间的可见性。(2) double check为什么要使用volatile 修饰instance？主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情:1.给 instance 分配内存2.调用 Singleton 的构造函数来初始化成员变量3.将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了）。但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。 具体可以看原文:你真的了解volatile关键字吗？ atomic是利用CAS来实现原子性操作的（Compare And Swap） 活跃性问题死锁不放弃拥有的资源，等待他人拥有的资源，并不放弃手中的资源。 锁顺序死锁（持有锁的时候调用外部方法，外部方法持有锁，就会导致锁顺序死锁） 资源死锁，与锁顺序一样，只不过锁换成了资源，比如数据连接，如一个任务需要两个数据库连接D1，D2。a线程持有D1等待D2，B线程持有D2等待D1。 活锁重复执行相同操作，并不阻塞，但一直占用，或者相互礼让 如，一个任务处理某个消息，一直失败，失败后又重新放到队列的开头，重新执行并失败，又放到队列的开头，重复执行这个过程 又如，网络上两台机器使用相同载波发送数据，失败后又重新发送，会一直失败，这时候引入随机机制，让他们不同时发送 饥饿一直得不到资源，饿死了。 aqs框架线程池中的工作队列中的线程和线程池中的线程 Locksynchronized无法中断一个等待锁的线程。lock要在finally中主动释放锁。 为什么要用lock代替synchronized内置锁无法中断正在等待的线程，Lock#lockInterruptibly()能够在获取锁的同时保持对中断的响应定时的tryLock同样能响应中断，当需要同时满足定时和中断时，可以使用带时间的tryLock无法无限等待一个锁无法实现非阻塞加锁 什么时候使用ReentrantLck而不是synchronized？一些高级功能，比如说可轮询的，计时的，可中断的锁的获取。公平队列，非区块的锁。 如何防止死锁内置锁：避免出现不一致的锁顺序 可定时锁和轮询锁：避免死锁发生 trylock(时间限制的tryLock，当没有想要的结果，就会使程序提前结束，内置锁不能办到这点)。 公平锁和非公平锁持有锁的时间较长，或者请求锁的平均时间较长，那么应该使用公平锁。 ReentrantLock默认非公平 遇到的疑问解决lock#lockInterruptibly和lock#lock1234567/* 执行可中断的锁获取操作,即意味着如果线程由于获取 锁而处于Blocked状态时，线程是可以被中断而不再继 续等待，这也是一种避免死锁的一种方式，不会因为 发现到死锁之后而由于无法中断线程最终只能重启应用。*/putLock.lockInterruptibly(); .为什么在每个类里重新引用如final ReentrantLock takeLock = this.takeLock;1找到答案： Note: convention in all put/take/etc is to preset local var 未解决LinkedBlockingQueue head表头为什么为transient 并发开销线程之间的协调1加锁，触发信号，内存同步 内存同步1刷新缓存 同步机制会消耗共享内存总线带宽 上下文切换123线程数量大于cpu数量，就会导致线程调度，需要保存执行的上下文jvm 操作系统 占用cpu，上下文切换时，处理器缓存可能并没有当前线程的数据。无阻塞算法增加吞吐量（阻塞会触发线程切换，增加cpu调度，发生上下文切换，降低吞吐量） 线程创建和销毁 线程的调度 如何减少锁的竞争减少锁的请求频率（锁的平均数量=锁的请求频率*锁的持有时间）减小锁的持有时间减小锁的范围（把大量的计算或者阻塞操作从同步移出）使用带有协调机制的独占锁 同步工具类信号量SemaphoreSemaphore用来控制某个特定资源的数量。 Semaphore管理这一批管理许可，由构造函数来指定。执行操作之前可以获得许可，使用之后释放许可。acquire讲阻塞直到有许可，release方法将返回一个许可。 使用Semaphore为容器设置边界，可以将容器变成有界阻塞队列。12345678910111213141516171819202122232425262728293031323334353637383940package com.gsc.tools;import java.util.Collections;import java.util.HashSet;import java.util.Set;import java.util.concurrent.Semaphore;public class BoundedHashSet&lt;T&gt; &#123; private final Set&lt;T&gt; set; private final Semphore sem; public BoundedHashSet(int bound) &#123; this.set = Collections.synchronizedSet(new HashSet&lt;T&gt;()); this.sem = new Semaphore(bound); &#125; public boolean add(E e) throws InterruptedException &#123; sem.acquire(); boolean wasAdded = false; try &#123; wasAdded =set.add(e); return wasAdded; &#125; finally &#123; if (!wasAdded) &#123; sem.release(); &#125; &#125; &#125; public boolean remove(Object o) &#123; boolean wasRemoved = set.remove(o); if (wasRemoved) &#123; sem.release(); &#125; return wasRemoved; &#125;&#125; 栅栏Barrier栅栏CyclicBarrier 闭锁LatchCountDownLatchLockCountDownLatchLock是一种灵活的闭锁实现，可以使一个或多个线程等待一组事物完成。维护一个计数器，初始化一个整数表示事物的数量，countDown事物完成减1，await阻塞等待直到计数器归零。12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.gsc.tools;import java.util.concurrent.CountDownLatch;/** * 闭锁CountDownLatch * 计算并发执行某个任务所需时间 * * @author shichaogeng * * 2017年9月27日 */public class TestHarness &#123; public long TimeTask(int nThread, final Runnable task) throws InterruptedException &#123; final CountDownLatch startGate = new CountDownLatch(1); final CountDownLatch endGate = new CountDownLatch(nThread); for (int i = 0; i &lt; nThread; i++) &#123; new Thread()&#123; public void run() &#123; try &#123; //线程阻塞等待所有线程准备完成 startGate.await(); try &#123; task.run(); &#125; finally &#123; //表示当前线程执行结束 endGate.countDown(); &#125; &#125; catch (InterruptedException e) &#123;&#125; &#125;; &#125;.start(); &#125; long start = System.nanoTime(); //准备完成，开始所有线程，await阻塞消失 startGate.countDown(); //等待所有线程释放完毕 endGate.await(); long end = System.nanoTime(); return end -start; &#125;&#125; FutureTask#get()FutureTask听过callable来实现，get()方法会阻塞直到任务走到完成状态，就获取callable的结果。参见Java Concurrency in Practise page 80。 AbstractQueuedSynchronizer]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
      <tags>
        <tag>concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python]]></title>
    <url>%2F2017%2F11%2F07%2Fpython%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[zookeeper-分布式的关键]]></title>
    <url>%2F2017%2F10%2F24%2Fzookeeper-%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%85%B3%E9%94%AE%2F</url>
    <content type="text"><![CDATA[感觉这篇要写的太多了，没法写，不用看了，没什么价值 安装配置下载地址 下载1$ wget http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz 解压1234$ tar xvzf zookeeper-3.4.9.tar.gz$ mv ./zookeeper-3.4.9 /lab/dev/zookeeper$ cd /lab/dev/zookeeper$ ln -s zookeeper-3.4.9 zookeeper 修改配置文件配置文件位置：${ZOOKEEPER_HOME}/conf/zoo_sample.cfg 分布式配置dataDir指定当前服务器数据存放的路径(目录)clientPort 指定当前服务器服务器的端口server.1/server.2/server.3 指定服务器的集群情况（有几台服务器） myid必须手动建立且指定在zk数据目录，也就是dataDir指定的路径123$ echo 1 &gt;&gt; /lab/dev/zookeeper/zk1/myid$ echo 2 &gt;&gt; /lab/dev/zookeeper/zk2/myid$ echo 3 &gt;&gt; /lab/dev/zookeeper/zk3/myid 在{ZOOKEEPER_HOME}/conf下拷贝zoo_sample.cfg出三个配置文件zoo1.cfg zoo2.cfg zoo3.cfg zoo1.cfg配置123456789tickTime=2000initLimit=10syncLimit=5dataDir=/lab/dev/zookeeper/zk1(这个目录可以自行指定)clientPort=2181server.1=127.0.0.1(ip):2888(通讯端口):3888（选举端口）server.2=127.0.0.1127.0.0.1:2889:3889server.3=127.0.0.1:2890:3890 zoo2.cfg配置123456789tickTime=2000initLimit=10syncLimit=5dataDir=/lab/dev/zookeeper/zk2clientPort=2182server.1=127.0.0.1:2888:3888server.2=127.0.0.1:2889:3889server.3=127.0.0.1:2890:3890 zoo3.cfg配置123456789tickTime=2000initLimit=10syncLimit=5dataDir=/lab/dev/zookeeper/zk3clientPort=2183server.1=127.0.0.1:2888:3888server.2=127.0.0.1:2889:3889server.3=127.0.0.1:2890:3890 Zookeeper及其API的使用启动Zookeeper我把三个启动做成个脚本start.sh1234567ZOO_HOME=/lab/dev/zookeeper/zookeeper$ZOO_HOME/bin/zkServer.sh start $ZOO_HOME/conf/zoo1.cfg$ZOO_HOME/bin/zkServer.sh start $ZOO_HOME/conf/zoo2.cfg$ZOO_HOME/bin/zkServer.sh start $ZOO_HOME/conf/zoo3.cfg# 运行start.shsh start.sh 停止Zookeeper三个停止也做成脚本stop.sh123456$ zkServer.sh stop /usr/local/zookeeper-3.4.6/conf/zoo1.cfg$ zkServer.sh stop /usr/local/zookeeper-3.4.6/conf/zoo2.cfg$ zkServer.sh stop /usr/local/zookeeper-3.4.6/conf/zoo3.cfg# 运行脚本sh stop.sh 查看zookeeper状态查看状态脚本12345678ZOO_HOME=/lab/dev/zookeeper/zookeeper$ZOO_HOME/bin/zkServer.sh status $ZOO_HOME/conf/zoo"$1".cfg# 查看zk2的运行状态,它是leader$ sh status.sh 2ZooKeeper JMX enabled by defaultUsing config: /lab/dev/zookeeper/zookeeper/conf/zoo2.cfgMode: leader ZK SHELL使用zkCli.sh [-server ip:port]进入命令行shell 进入之后可以用help命令查看帮助信息，并选择你要使用的命令1234567891011121314151617181920212223[zk: localhost:2181(CONNECTED) 1] helpZooKeeper -server host:port cmd args stat path [watch] set path data [version] ls path [watch] delquota [-n|-b] path ls2 path [watch] setAcl path acl setquota -n|-b val path history redo cmdno printwatches on|off delete path [version] sync path listquota path rmr path get path [watch] create [-s] [-e] path data acl addauth scheme auth quit getAcl path close connect host:port Zookeeper使用–命令行 ephemeralOwner = 0x15f4d0ecaf60002判断是否临时节点 setquota -n|-b val path 某个Znode指定多少存储空间或者允许创建多少个节点n 指定可以设置多少个子节点b 指定可以设置多大空间（byte） listquota path对于配额不是硬性的提示，超过配额还是可以继续创建，只不过在日志里面有提示 错误日志122017-10-24 16:33:08,151 [myid:1] - WARN [CommitProcessor:1:DataTree@301] - Quota exceeded: /zk-123 count=6 limit=52017-10-24 16:33:13,958 [myid:1] - WARN [CommitProcessor:1:DataTree@301] - Quota exceeded: /zk-123 count=7 limit=5 stat path查看节点的状态]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试问题整理]]></title>
    <url>%2F2017%2F10%2F23%2F%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[对一些常见的面试题的总结 数据结构&amp;算法JAVA开发中常用的数据结构有哪些？快速排序 广度优先搜索（队列实现） 谈谈对HashMap的理解，底层的基本实现。HashMap怎么解决碰撞问题的？数据结构是线程安全的吗？假如你回答HashMap不是线程安全的，HashTabl是线程安全的，有没有线程安全的Map，concurrent包concurrentmap的机制 treemap HashMap的底层原理12345678910键值对集合Entry,分单存储在一个数组中。# HashMap#put()的原理运行hash算法，计算在数据中的位置(数组的索引)。当hash冲突的时候，就使用链表来存储，当新的碰撞节点到来时，就会插入链表头。# HashMap链表为什么把最近put的元素放在表头HashMap的发明者认为，后插入的数据被查找的可能性更大(这是个概率问题)# HashMap#get()原理首先用hash算法算出数组索引，然后从链表头遍历依次next直到找到 HashMap的默认初始长度是多少，为什么这么规定。12初始长度是16，并且每次初始化时，必须是2的幂数这是为了服务key映射到index的Hash算法的，公式index=hashcode(key)&amp;(length-1)，初始长度(16-1)，二进制为1111&amp;hashcode结果为hashcode最后四位，能最大程度保持平均，二的幂数保证二进制为1，保持hashcode最后四位。这种算法在保持分布均匀之外，效率也非常高。 HashMap的reHash12345扩容条件：HashMap.size &gt;= capacity(默认16)*loadFactor(默认0.75)步骤：1. 扩容：数组长度扩大为原来的两倍2. rehash：重新计算hash值 高并发情况下，为什么hashmap会出现死锁1并发时同时rehash可能形成环形链表，当在环形链表中查找一个不存在的元素，就会造成死循环，导致cpu利用率100%。 java8中，对HashMap的数据结构做了什么优化12 JVM对JVM熟不熟悉？简单说说类加载过程，里面执行的哪些操作？问了GC和内存管理，平时在tomcat里面有没有进行过相关配置JVM内存模型JVM新生代和老年代的比例YFC和FGC的具体场景jstack，jmap，jutil分别的意义，如何排查线上相关问题 通信协议http协议 get和post区别 tcp/ip协议 三次握手 窗口滑动机制 接口如何处理重复请求，具体的处理方案是什么。如何保障请求执行顺序设计一个对外接口实现类，在三个主机ip上实现轮循和负载均衡（考虑并发） 数据库开发中用了哪些数据库？mysql存储引擎有哪些？悲观锁和乐观锁问题使用场景、分布式集群实现原理数据库垂直和水平拆分 redis基本存储类型 事物 使用场景 框架spring和mybatis实现原理 底层源码Mybatis如何分页；如何设置缓存；Mysql分页执行某操作，前50次成功，51次失败，a全回滚b前50次提交51次抛出异常 ab场景如何设置spring传播行为 分布式Dubbo超时重试 超时时间设置dubbo的底层原理，zookeeper是什么zookeeper作用分布式事物和分布式锁（扣款不要出现负数）分布式session设置分布式session一致性分布式接口的幂等设计[不能重复扣款] 业务最近做的比较熟悉的项目技术架构图 并发见 java-concurrent]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA使用简记]]></title>
    <url>%2F2017%2F10%2F19%2FIntelliJ-IDEA%E4%BD%BF%E7%94%A8%E7%AE%80%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[感觉IntelliJ IDEA现在比较流行的开发ide，同事大部分也使用这个，只有我用eclipse有点low，打算学习下，把常用的配置记录下，把常用配置放到github上，以后直接使用就可以了。 下载地址 破解：（切换license server 然后输入网址：http://idea.iteblog.com/key.php即可） JVM配置文件idea64.exe.vmoptions是 64 位可执行文件的 JVM 配置文件内容 使用 IDEA 自带菜单中的 Help -&gt; Edit Custom VM Options 来进行个性化配置，而不是直接修改安装目录中的该文件！ -Xms128m，16 G 内存的机器可尝试设置为 -Xms512m -Xmx750m，16 G 内存的机器可尝试设置为 -Xmx1500m -XX:MaxPermSize=350m，16G内存的机器可尝试设置为-XX:MaxPermSize=500m -XX:ReservedCodeCacheSize=225m，16G内存的机器可尝试设置为-XX:ReservedCodeCacheSize=500m 属性配置文件idea.properties是 IntelliJ IDEA 一些属性配置，修改原则主要根据个人对 IntelliJ IDEA 的个性化配置情况来分析。 在阅读了安装目录中的带注释的配置文件后，使用 IDEA 自带菜单中的 Help -&gt; Edit Custom Properties 来进行个性化配置！常修改的就是下面 4 个参数： idea.config.path=${user.home}/.IntelliJIdea/config，该属性主要用于指向 IntelliJ IDEA 的个性化配置目录，默认是被注释，打开注释之后才算启用该属性，这里需要特别注意的是斜杠方向，这里用的是正斜杠。 idea.system.path=${user.home}/.IntelliJIdea/system，该属性主要用于指向 IntelliJ IDEA 的系统文件目录，默认是被注释，打开注释之后才算启用该属性，这里需要特别注意的是斜杠方向，这里用的是正斜杠。如果你的项目很多，则该目录会很大，如果你的 C 盘空间不够的时候，还是建议把该目录转移到其他盘符下。 idea.max.intellisense.filesize=2500，该属性主要用于提高在编辑大文件时候的代码帮助。IntelliJ IDEA 在编辑大文件的时候还是很容易卡顿的。 idea.cycle.buffer.size=1024，该属性主要用于控制控制台输出缓存。有遇到一些项目开启很多输出，控制台很快就被刷满了没办法再自动输出后面内容，这种项目建议增大该值或是直接禁用掉，禁用语句 idea.cycle.buffer.size=disabled。 必要配置全局配置File-&gt;Other Setting-&gt;Default Setting可以进行全局设置 ToolBarView-&gt;ToolBar/Tool Buttons EncodingFile-&gt;Setting-&gt;Editor-&gt;File Encoding设置Project Encoding别忘了下面的properties Encoding 并勾选后面的选项（能查看中文） Compiler Heap SizeFile-&gt;Setting-&gt;Build-&gt;Compiler设置Compiler heap大小 JDKFile-&gt;Project Structure-&gt;Platform Settings-&gt;SDKs 包层级设置点击右上角齿轮，在弹出的菜单中去掉选项：Compact Empty Middle Packages GitFile-&gt;Setting-&gt;Version Control-&gt;Git确定系统已安装git并git路径正确。 教程IntelliJ IDEA 简体中文专题教程 提示忽略大小写setting-&gt;Editor-&gt;General-&gt;Code Completion-&gt;Case sensitive completion设为None 文件和导航关联小齿轮-&gt;AtuoScroll from source/AtuoScroll to source 添加xml模板settting-&gt;Editor-&gt;Code Stype-File &amp; Code Template&gt;新建一个xml模板 记录下常用快捷键main函数1psvm print1sout for循环1fori foreach1iter 创建包，类 构造方法1alter+insert 类似ctrl+1,提示帮助1alt+enter 删除一行1ctrl+Y 窗口左右切换1alt+→/← 重命名1shift+F6 进入方法、变量声明，相当于eclipse f31ctrl+b File Structure，相当于eclipse CTRL+O1ctrl+F12 查找类，相当于eclipse ctrl+shift+t1ctrl+n 进入父类1ctrl+u 进入子类1ctrl+alt+b 上次浏览位置1ctrl+alt+left/right Find Usage1alt+f7 上下移动1ctrl+shift+↑/↓ Hide All Tool Windows1ctrl+shift+f12 自动补全（好东西，我喜欢用来补全括号）1ctrl+shift+enter surround with1ctrl+alt+t 抽取1234567891011#抽取变量ctrl+alt+v#抽取方法ctrl+alt+f#抽取字段ctrl+alt+f#抽取常量ctrl+alt+c 在整个idea中替换1ctrl+shift+r Debug技巧快捷键进入方法F7 下一步F8 调到下一断点（突然理解eclipse为啥叫resume了，恢复运行啊）F9 ALT+F8调试状态下对选中对象进行运算 Ctrl + Shift + F8指定断点进入条件 还有一个小技巧，可以重新调用一个方法，进入方法之后，可以使用Drop Frame会到方法的调用者，就像没有进入执行过方法一样。比如代码是这样的123456789101112131415161718192021222324252627282930@Testpublic void test1_1_8() &#123; Person person = new Person(); person.setName(&quot;tom&quot;); person.setAge(23); System.out.println(person);&#125; &#125;class Person &#123; private String name; private int age; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 我在person.setAge(23);这里加个断点，然后我进入123public void setAge(int age) &#123; this.age = age;&#125; 在界面的右下角有个debugger窗口，右键当前的方法栈，选择Drop Frame,就可以会退到person.setAge(23);方法。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git]]></title>
    <url>%2F2017%2F10%2F17%2Fgit%2F</url>
    <content type="text"><![CDATA[git 通过使用基于 P2P 网络的源码库，使得多人维护数字化工作变得可能。git 支持分布式工作流，允许一部分工作被分发出去，或是合并回来。 git安装git 我yum安装时报错，然后就百度一番，也记录下吧。 123456# 错误Not using downloaded repomd.xml because it is older than what we have# 解决（清空缓存）yum clean allyum makecache 安装 1234567yum -y install git# 测试git --version# 查看帮助git --help 查看帮助所有的命令都可以通过帮助查到 查看全局帮助1git --help 注意最下面这句话123'git help -a' and 'git help -g' lists available subcommands and someconcept guides. See 'git help &lt;command&gt;' or 'git help &lt;concept&gt;'to read about a specific subcommand or concept. 意思是可以通过如下命令来查看命令具体配置1git help &lt;command&gt; 查看git配置帮助1git config 比如配置用户名邮箱12git config --global user.name shichaogenggit config --global user.email shichaogeng@gmail.com Git一些概念git init命令同时会创建 .git 子目录：1234567891011121314151617181920212223.git/|-- HEAD|-- config|-- description|-- hooks| |-- applypatch-msg.sample| |-- commit-msg.sample| |-- post-commit.sample| |-- post-receive.sample| |-- post-update.sample| |-- pre-applypatch.sample| |-- pre-commit.sample| |-- pre-rebase.sample| |-- prepare-commit-msg.sample| |-- update.sample|-- info| |-- exclude|-- objects| |-- info| |-- pack|-- refs |-- heads |-- tags .git 包含以下文件和目录： 配置：.git/config, .git/description, .git/info/exclude 用来配置本地代码库 钩子：.git/hooks 包含在代码库各个周期时会被执行的脚本 临时区域：.git/index 提供当前工作目录的临时区 对象数据库：.git/objects 是默认的git对象数据库，它包含本地内容或指向本地内容的指针。这些对象均为只读 引用：.git/refs 用来存储本地/远程的分支，标签，以及 head 的引用。引用是指向对象的指针，一般为 tag 或 commit .git 是实际的代码库。而保存当前文件的目录被称为 工作目录。 使用 git init --bare 创建不包含工作目录的代码库。 .git/index 是另一个重要的文件：它提供了一个当前工作目录和当前代码库之间的缓冲区，用来存储当前未提交的一个或多个文件。 git checkout [branch] 把 HEAD 引用移到指定分支，然后通过索引文件见当前工作目录中的文件恢复至该分支的状态。 git add [files] 会交叉引用索引文件中的校验和来检查当前未提交文件是否需要更新工作目录的版本，git 目录不受影响。 git工作区域图 从图中可以看出，所有操作都保存在缓存区中，commit之后才保存修改到版本库。其中head是游标，表示当前的分支是master（指向当前分支的最新提交点，所谓的提交点就是时间为主线，每次提交都是一次提交点）。 Git 创建仓库1git init Git 使用 git init 命令来初始化一个 Git 仓库，Git 的很多命令都需要在 Git 的仓库中运行，所以 git init 是使用 Git 的第一个命令。 在执行完成 git init 命令后，Git 仓库会生成一个 .git 目录，该目录包含了资源的所有元数据，其他的项目目录保持不变（不像 SVN 会在每个子目录生成 .svn 目录，Git 只在仓库的根目录生成 .git 目录）。 使用当前目录作为Git仓库，我们只需使它初始化。 常用命令把文件添加到缓存区12# filename为 . 表示把工作区中所有文件加入缓存区git add filename 查看版本状态信息，可以看现工作区中文件的状态1234567891011121314[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git status# On branch master## Initial commit## Changes to be committed:# (use "git rm --cached &lt;file&gt;..." to unstage)## new file: start.sh## Untracked files:# (use "git add &lt;file&gt;..." to include in what will be committed)## vip 加入参数-s获得精简的信息123[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git status -sA start.sh?? vip 版本提交，提交到版本库(某种程度上相当于git add和git commit -m的组合技，前提是被改动文件已经是tracked)1234git commit –m &lt;message&gt;# 加入缓存区并提交git commit –am &lt;message&gt; git diff命令 比较工作区和缓存区差异1git diff 比较缓存区和版本库（HEAD）之间的差异1git diff --cached 比较工作区和版本库（HEAD）的差别1git diff HEAD -- &lt;filename&gt; 比较两个版本号码的src 文件夹的差异1git diff 版本号码1 版本号码2 版本克隆123git clone &lt;repo&gt; &lt;directory&gt;git clone https://github.com/alibaba/dubbo.git dubbogit clone git@github.com:shichaogeng/gitskills.git 其中，git开头的表示使用的是git协议，https当然使用的是https协议。 命令用于取消已缓存的内容1git reset HEAD 分支管理几乎每一种版本控制系统都以某种形式支持分支。使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。 创建分支命令(创建分支会复制当前提交点)1git branch (branchname) 查看分支1234[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git branch jack* master# 上面的*代表当前所在分支 切换分支命令1git checkout (branchname) 删除分支1git branch -d (branchname) 合并分支命令12345678910# 如果a分支要合并b分支，首先切换到a分支git checkout master# 查看当前分支git branch jack* master# 合并jack分支git merge jack 合并的内容不需要提交，直接合并进来。 如果合并时遇到冲突，比如像下面这样1234[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git merge jackAuto-merging vipCONFLICT (content): Merge conflict in vipAutomatic merge failed; fix conflicts and then commit the result. 编辑冲突文件，解决冲突，然后提交到版本库1git commit -am 'conflict resolved' 关于另一种命令git rebase,网上找到博客 git rebase简介(基本篇) Git提交历史查看提交历史1git log 查看提交历史简单版本（一行展示）1git log –oneline 查看分支情况，–graph图形表示，可以看到当前哪里创建的节点，以及节点的提交合并情况123456789[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git log --oneline --graph* 3d6c89d conflict resolved|\ | * aeb2e8d jack-conflict* | 8bbe83f master-conflict|/ * 909958a jack commit 1* a0af866 brach jack* 40d8ffb first commit Git 标签如果你达到一个重要的阶段，并希望永远记住那个特别的提交快照，你可以使用 git tag 给它打上标签。某个时刻的提交点有特殊的意义，可以在分支打上标签。 首先决定在哪个提交点打标签1234567[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git log --oneline3d6c89d conflict resolvedaeb2e8d jack-conflict8bbe83f master-conflict909958a jack commit 1a0af866 brach jack40d8ffb first commit 我选择在倒数第二个提交点打标签1git tag -a v1.0 a0af866 查看tag1git log --decorate 在当前提交点打标签1git tag -a v0.9 Git回退命令12[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git reset --hard 40d8ffbHEAD is now at 40d8ffb first commit 回退的原理：HEAD的指针指向id所在的提交点。 也可以使用git reset --hard HARD|HARD^|HARD酱紫的命令，其中HARD代表当前提交点，HARD^代表上一个提交点，HARD^^代表上两个提交点，HARD~100代表100个以前的这种，额 这时候还是用commit id比较好。 查看历史123456[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git logcommit 40d8ffbc45c8b37c260b67a6c728cfb37a60da34Author: shichaogeng &lt;shichaogeng@gmail.com&gt;Date: Tue Oct 17 15:43:45 2017 +0800 first commit 发现回退点以后的log都消失了。表示回退提交点以后的记录都删除了。如果发现删除错误了，需要恢复，这个时候就要使用git reflog1234567891011121314151617181920git reflog40d8ffb HEAD@&#123;0&#125;: reset: moving to 40d8ffb3d6c89d HEAD@&#123;1&#125;: reset: moving to 3d6c89d40d8ffb HEAD@&#123;2&#125;: reset: moving to 40d8ffb3d6c89d HEAD@&#123;3&#125;: checkout: moving from jack to masteraeb2e8d HEAD@&#123;4&#125;: checkout: moving from master to jack3d6c89d HEAD@&#123;5&#125;: commit (merge): conflict resolved8bbe83f HEAD@&#123;6&#125;: checkout: moving from jack to masteraeb2e8d HEAD@&#123;7&#125;: commit: jack-conflict909958a HEAD@&#123;8&#125;: checkout: moving from master to jack8bbe83f HEAD@&#123;9&#125;: commit: master-conflict909958a HEAD@&#123;10&#125;: checkout: moving from master to master909958a HEAD@&#123;11&#125;: merge jack: Fast-forward40d8ffb HEAD@&#123;12&#125;: checkout: moving from jack to master909958a HEAD@&#123;13&#125;: commit: jack commit 1a0af866 HEAD@&#123;14&#125;: checkout: moving from master to jack40d8ffb HEAD@&#123;15&#125;: checkout: moving from jack to mastera0af866 HEAD@&#123;16&#125;: commit: brach jack40d8ffb HEAD@&#123;17&#125;: checkout: moving from master to jack40d8ffb HEAD@&#123;18&#125;: commit (initial): first commit reflog显示整个本地仓储的commit, 包括所有branch的commit, 甚至包括已经撤销的commit, 只要HEAD发生了变化, 就会在reflog里面看得到. git log只包括当前分支的commit. 然后可以再使用git reset回退到已被删除的提交点12[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git reset --hard 3d6c89dHEAD is now at 3d6c89d conflict resolved 查看log，发现已经恢复1234567[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git log --oneline3d6c89d conflict resolvedaeb2e8d jack-conflict8bbe83f master-conflict909958a jack commit 1a0af866 brach jack40d8ffb first commit github用户配置我要用github上的项目做测试，配置github用户名密码12git config --global user.name shichaogenggit config --global user.email shichaogeng@gmail.com 配置秘钥 git在部署github时使用SSH协议连接和验证远程服务器和服务。为避免暴露账户密码，最好使用证书认证。使用SSH密钥，可以连接到GitHub，而无需在每次访问时提供用户名或密码。 查看密匙执行cd ~/.ssh命令，如果存在该目录，表明之前生成果SSH Key，利用ll命令即可以查看。123[root@iZ2zehu64p5eabr7fp9t0iZ .ssh]# lltotal 0-rw------- 1 root root 0 Sep 15 13:20 authorized_keys 看一下有没有id_rsa和id_rsa.pub(或者是id_dsa和id_dsa.pub之类成对的文件)，有.pub 后缀的文件就是公钥，另一个文件则是密钥。 假如没有这些文件，甚至连.ssh 目录都没有，可以用 ssh-keygen 来创建。该程序在 Linux/Mac 系统上由 SSH 包提供，而在 Windows 上则包含在 MSysGit 包里。 生成私钥12345678910111213141516171819202122[root@iZ2zehu64p5eabr7fp9t0iZ .ssh]# ssh-keygen -t rsa -C "shichaogeng@gmail.com"Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:4f:e4:71:c2:89:92:03:80:41:1c:c2:11:cc:06:ff:ea shichaogeng@gmail.comThe key's randomart image is:+--[ RSA 2048]----+|@B=.. ||oB . . o . ||. . + . * . || . o o + || . S o || . o || . . || . || E |+-----------------+# 本地密匙生成成功！ 查看生成的公钥1ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7+EsE7t+TmI9AA16QQMNnwB3fbogZGznD18jttNvANvkYITlNnty2a/qiFdVuaSvPHbwW5djKT8fwVpieJStlefEsdAXg+r7DPgyttFf2vHYdHULdZNc48aNy/GN1hZFvPU1PwsV/xAL8phFER4aFhQYygcnkY1/KbfSZOHo+9uL+oc7bBQZYTEhfdl+twwesnAt3erSPIl1U0Cv5tkCdj2WRnLGiLXdnUfK7Zq5jtfQiXWeXCXjt3+wB0zWS1W6HysQ4pJ5f7OuuzG8sHj44KTYqSf5hSHuGVXX5P7x9OiKT4zDyZ/rBsGJAehyxDRd3ErAP2D4IY1zmpzgEBkgx shichaogeng@gmail.com github公钥登陆github帐户。点击头像，然后 Settings -&gt; 左栏点击 SSH and GPG keys -&gt; 点击 New SSH key，向下面酱紫的界面 然后你复制上面的公钥内容，粘贴进“Key”文本域内。 title域，自己随便起个名字。点击 Add key。 完成以后，验证下这个key是不是正常工作123456[root@iZ2zehu64p5eabr7fp9t0iZ .ssh]# ssh -T git@github.comThe authenticity of host 'github.com (192.30.255.112)' can't be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added 'github.com,192.30.255.112' (RSA) to the list of known hosts.Hi shichaogeng! You've successfully authenticated, but GitHub does not provide shell access. 搞定！ 远程操作在github上创建项目，之后 会看到如下帮助信息 …or create a new repository on the command line1234567echo "# gitvip" &gt;&gt; README.mdgit initgit add README.mdgit commit -m "first commit"# 添加远程库git remote add origin https://github.com/shichaogeng/gitvip.gitgit push -u origin master …or push an existing repository from the command line12git remote add origin https://github.com/shichaogeng/gitvip.gitgit push -u origin master 可以查看远程连接信息123[root@iZ2zehu64p5eabr7fp9t0iZ gitvip]# git remote -vorigin https://github.com/shichaogeng/gitvip.git (fetch)`origin https://github.com/shichaogeng/gitvip.git (push)` 其中，fetch和push都是https://github.com/shichaogeng/gitvip.git Git中从远程的分支获取最新的版本到本地有这样2个命令git fetch,git pull git fetch：相当于是从远程获取最新版本到本地，不会自动merge123git fetch origin mastergit log -p master..origin/mastergit merge origin/master 以上命令的含义： 首先从远程的origin的master主分支下载最新的版本到origin/master分支上然后比较本地的master分支和origin/master分支的差别最后进行合并 上述过程其实可以用以下更清晰的方式来进行123git fetch origin master:tmpgit diff tmp git merge tmp 从远程获取最新的版本到本地的test分支上，之后再进行比较合并 git pull：相当于是从远程获取最新版本并merge到本地1git pull origin master 上述命令其实相当于git fetch 和 git merge在实际使用中，git fetch更安全一些因为在merge前，我们可以查看更新情况，然后再决定是否合并结束 看这里写完之后，发现一个超有用的教程，写的超好，感觉自己白写了，又把他的教程又刷了一遍 Git教程]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis需要注意的点]]></title>
    <url>%2F2017%2F10%2F11%2FRedis%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E7%82%B9%2F</url>
    <content type="text"><![CDATA[关于redis使用中需要注意的地方，记录下。 API命令查看键总数127.0.0.1:6379&gt; keys *1) “name” 12127.0.0.1:6379&gt; dbsize(integer) 1 dbsize命令在计算键总数时不会遍历所有键，而是直接获取Redis内置的键总数变量，所以dbsize命令的时间复杂度是O（1）。 而keys命令会遍历所有键，所以它的时间复杂度是O（n），当Redis保存了大量键时，线上环境禁止使用。 查询数据结构内部编码12127.0.0.1:6379&gt; object encoding name&quot;embstr 单线程模型因为Redis是单线程来处理命令的，所以一条命令从客户端达到服务端不会立刻被执行，所有命令都会进入一个队列中，然后逐个被执行。 为什么单线程还能这么快 纯内存访问，Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，这是Redis达到每秒万级别访问的重要基础。 非阻塞I/O，Redis使用epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间。 单线程避免了线程切换和竞态产生的消耗。单线程能带来几个好处：第一，单线程可以简化数据结构和算法的实现。如果对高级编程语言熟悉的读者应该了解并发数据结构实现不但困难而且开发测试比较麻烦。第二，单线程避免了线程切换和竞态产生的消耗，对于服务端开发来说，锁和线程切换通常是性能杀手。 字符串最大512M mget命令假如没有mget这样的命令，要执行n次get命令1n次get时间 = n次网络时间 + n次命令时间 使用mget命令后，要执行n次get命令1n次get时间 = 1次网络时间 + n次命令时间 1000次get命令，网络耗时1ms，执行命令0.1ms,1000次get和一次met对比 使用批量操作，有助于提高业务处理效率，但是要注意的是每次批量操作所发送的命令数不是无节制的，如果数量过多可能造成Redis阻塞或者网络拥塞。 SETNX1234127.0.0.1:6379&gt; set company go+OK127.0.0.1:6379&gt; setnx company go+(integer) 0 因为键hello已存在，所以setnx失败，返回结果为0 由于Redis的单线程命令处理机制，如果有多个客户端同时执行setnx key value，根据setnx的特性只有一个客户端能设置成功，setnx可以作为分布式锁的一种实现方案，Redis官方给出了使用setnx实现分布式锁的方法：http://redis.io/topics/distlock。 redis数据迁移]]></content>
      <categories>
        <category>no-</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven小总结]]></title>
    <url>%2F2017%2F09%2F29%2FMaven%E5%B0%8F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[maven是项目管理工具，用的也比较熟练了，但是还是有记不到的和常用的不了解的内容，在这里记录下。 单元测试构建项目打包上传时经常需要跳过测试，如果确定项目没有问题（你要确定哦），因为测试需要跑你的每个测试方法，非常耗时间，而且方法写错了，还要报错等等…… maven-surefire-plugin简介Maven本身并不是一个单元测试框架，它只是在构建执行到特定生命周期阶段的时候，通过插件来执行JUnit或者TestNG的测试用例。这个插件就是maven-surefire-plugin，也可以称为测试运行器(Test Runner)，它能兼容JUnit 3、JUnit 4以及TestNG。 在默认情况下，maven-surefire-plugin的test目标会自动执行测试源码路径（默认为src/test/java/）下所有符合一组命名模式的测试类。这组模式为： 123**/Test*.java：任何子目录下所有命名以Test开关的Java类。**/*Test.java：任何子目录下所有命名以Test结尾的Java类。**/*TestCase.java：任何子目录下所有命名以TestCase结尾的Java类。 跳过测试命令可以才命令行中mvn输入，也可以在eclipse的右键-run-maven build..-Goals中输入 命令行中1mvn package -DskipTests eclipse中（我用的是eclipse）1package -DskipTests 也可以酱紫，不过我都用上面的1mvn package -Dmaven.test.skip=true 也可以配置插件 pom配置插件跳过测试在pom文件中加入如下配置12345678&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.18.1&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;/configuration&gt;&lt;/plugin&gt; 动态指定要运行的测试用例maven-surefire-plugin提供了一个test参数让Maven用户能够在命令行指定要运行的测试用例。如：1mvn test -Dtest=RandomGeneratorTest 也可以使用通配符：1mvn test -Dtest=Random*Test 或者也可以使用“，”号指定多个测试类：1mvn test -Dtest=Random*Test,AccountCaptchaServiceTest 包含与排除测试用例在pom文件中配置要包含和排除的测试用例1234567891011121314&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.18.1&lt;/version&gt; &lt;configuration&gt; &lt;includes&gt; &lt;include&gt;**/*Tests.java&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;**/*ServiceTest.java&lt;/exclude&gt; &lt;exclude&gt;**/TempDaoTest.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt;&lt;/plugin&gt; 生成测试报告默认情况下，maven-surefire-plugin会在项目的target/surefire-reports目录下生成两种格式的错误报告。 简单文本格式——内容十分简单，可以看出哪个测试项出错。 与JUnit兼容的XML格式——XML格式已经成为了Java单元测试报告的事实标准，这个文件可以用其他的工具如IDE来查看。 maven-model-builder插件仓库配置大家都应该明白依赖的查找路径：本地仓库–&gt;远程仓库 但是，插件的依赖有所不同，插件依赖的查找路径：本地仓库–&gt;插件远程仓库 Maven的父POM中也是有内置一个插件仓库的，我现在用的电脑安装的是Maven 3.1.1版本，我们可以找到这个文件：${M2_HOME}/lib/maven-model-builder-3.1.1.jar，打开该文件，能找到超级父POM：\org\apache\maven\model\pom-4.0.0.xml，它是所有Maven POM的父POM，所有Maven项目都继承该配置。 我们来看看默认的远程插件仓库配置的是啥：1234567891011121314&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;http://repo.maven.apache.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; 默认插件仓库的地址就是中央仓库咯，它关闭了对snapshots的支持，防止引入snapshots版本的插件而导致不稳定的构件。一般来说，中央仓库所包含的插件完全能够满足我们的需要，只有在少数情况下才要配置，比如项目的插件无法在中央仓库找到，或者自己编写了插件才会配置自己的远程插件仓库。 这个文件中还有一些其他的配置，自己看吧 依赖的范围和传递性关于依赖范围和传递依赖果然还是不理解，用时候百度吧。 比如这样的： compile：编译依赖范围（默认），使用此依赖范围对于编译、测试、运行三种 classpath 都有效，即在编译、测试和运行的时候都要使用该依赖jar包； 啥叫三种classpath啊，不懂不懂不懂 还有依赖的传递，有时候传递有时候不传递，有个表格，就不贴了，自己查吧。 pom的一些标签relativePath&lt;relativePath&gt;: 表示父模块POM的相对路径，在构建的时候，Maven会先根据relativePath检查父POM，如果找不到，再从本地仓库查找 relativePath的默认值： ../pom.xml finalName打包的时候，打包的名称 查看maven-model-builder.jar的pom文件可以看到（这个是超级父工程）下面的标签1&lt;finalName&gt;$&#123;project.artifactId&#125;-$&#123;project.version&#125;&lt;/finalName&gt; 工程是这样的12345678&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;maven-test&lt;/artifactId&gt; &lt;parent&gt;&lt;groupId&gt;com.gengsc.practise&lt;/groupId&gt;&lt;artifactId&gt;maven-test-parent&lt;/artifactId&gt;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 打包之后的jar包就是这样的(默认jar包)1maven-test-0.0.1-SNAPSHOT.jar 现在添加finalName标签，也就是覆盖了父pom文件1&lt;finalName&gt;maven-test&lt;/finalName&gt; 再次打包，jar文件变成酱紫1maven-test.jar 依赖树查看pom文件呢的依赖树可以在eclipse的pom文件中打开Dependency Hierarchy。像酱紫 也可用命令查看1mvn dependency:tree 也可导出到文件中分析1mvn dependency:tree -Doutput=db.txt 常用骨架我平时都直接选Create a simple project(skip archetype selection)，没选骨架，记下最常用的两个吧 maven-archetype-quickstart 打jar包 maven-archetype-webapp 打war包 配置阿里云镜像12345678910111213&lt;!--配置阿里云国内镜像 --&gt;&lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt;&lt;mirror&gt; &lt;id&gt;central&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;url&gt;http://repo1.maven.org/maven2/&lt;/url&gt;&lt;/mirror&gt; 配置文件动态切换pom build节点下面添加resource配置：123456789101112131415161718&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;!-- 设置对auto-config.properties，jdbc.properties进行过虑，即这些文件中的$&#123;key&#125;会被替换掉为真正的值 --&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;jdbc.properties&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt;&lt;/resources&gt; resource的filtering属性用来表示资源文件中的占位符是否需要被替换，true为需要替换。上面的定义是jdbc.properties文件中的EL表达式占位符都会在打包时动态替换，所有的其他文件则不会替换占位符。 接下来我们配置三个profile,一个是测试环境，一个开发环境，一个是正式环境配置：12345678910111213141516171819202122232425262728293031323334353637383940&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;test&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;jdbc.driver&gt;test.mysql&lt;/jdbc.driver&gt; &lt;jdbc.url&gt;test.url&lt;/jdbc.url&gt; &lt;jdbc.username&gt;test.username&lt;/jdbc.username&gt; &lt;jdbc.password&gt;test.password&lt;/jdbc.password&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;false&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;jdbc.driver&gt;dev.mysql&lt;/jdbc.driver&gt; &lt;jdbc.url&gt;dev.url&lt;/jdbc.url&gt; &lt;jdbc.username&gt;dev.username&lt;/jdbc.username&gt; &lt;jdbc.password&gt;dev.password&lt;/jdbc.password&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;product&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;jdbc.driver&gt;product.mysql&lt;/jdbc.driver&gt; &lt;jdbc.url&gt;product.url&lt;/jdbc.url&gt; &lt;jdbc.username&gt;product.username&lt;/jdbc.username&gt; &lt;jdbc.password&gt;product.password&lt;/jdbc.password&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 我们再在src/main/resources目录下面创建一个jdbc.properties文件，内容如下：1234jdbc.driver = $&#123;jdbc.driver&#125;jdbc.url = $&#123;jdbc.url&#125;jdbc.username = $&#123;jdbc.username&#125;jdbc.password = $&#123;jdbc.password&#125; 然后我们执行maven打包命令：clean package -DskipTests -Pdev 查看对应的jar包里面的jdbc.properties文件，可以发现占位符已经被替换成了profile dev中配置的值了。 私服Nexus 是Maven仓库管理器，如果你使用Maven，你可以从Maven中央仓库 下载所需要的构件（artifact），但这通常不是一个好的做法，你应该在本地架设一个Maven仓库服务器，在代理远程仓库的同时维护本地仓库，以节省带宽和时间，Nexus就可以满足这样的需要。此外，他还提供了强大的仓库管理功能，构件搜索功能，它基于REST，友好的UI是一个extjs的REST客户端，它占用较少的内存，基于简单文件系统而非数据库。这些优点使其日趋成为最流行的Maven仓库管理器。 下载nexus参照这个博客吧，懒得自己写了：【Maven】Nexus（Maven仓库私服）下载与安装 Nexus使用及配置这个也参照上面同学的博客吧：【Maven】Nexus配置和使用 特别说明下：Public Repositories：该仓库组将上述所有策略为Release的仓库聚合并通过一致的地址提供服务。可以认为这个公共仓库是多个仓库的组合,里面包含了很多个仓库。确保能下载到jar包它按照下面的顺序寻找依赖 国内镜像地址：http://maven.oschina.net/content/groups/public/ Maven手动添加jar包假如遇到依赖下载不到的情况，我们可以手动把jar包添加到本地仓库中，命令如下：1mvn install:install-file -Dfile=IKAnalyzer3.2.8.jar -DgroupId=org.wltea.ik-analyzer -DartifactId=ik-analyzer -Dversion=3.2.8 -Dpackaging=jar 详细配置网上找了个写的比较全的，看到没用过的可以到这里查查 史上最全的Maven Pom文件标签详解]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker初探]]></title>
    <url>%2F2017%2F09%2F21%2Fdocker%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[弄完了springboot，接下来就可以通过springboot快速搭建springcloud组件了，配合docker完成传说中的微服务架构，但。。。docker是撒啊，决定搞一搞。整体下来操作感觉比较简单，但是理解那个镜像与容器的关系有点费劲。还有什么镜像分层的东东。。。 为啥用dockerDocker到底是什么看看官方的介绍 Docker provides a way to run applications securely isolated in a container, packaged with all its dependencies and libraries. 意思就是为应用提供一个安全隔绝的运行容器，打包它所有的依赖和类库。 Docker是Docker公司开源的一个基于轻量级虚拟化技术的容器引擎项目,整个项目基于Go语言开发，并遵从Apache 2.0协议。目前，Docker可以在容器内部快速自动化部署应用，并可以通过内核虚拟化技术（namespaces及cgroups等）来提供容器的资源隔离与安全保障等。由于Docker通过操作系统层的虚拟化实现隔离，所以Docker容器在运行时，不需要类似虚拟机（VM）额外的操作系统开销，提高资源利用率，并且提升诸如IO等方面的性能。 以前，如果想尝试新的编程语言/数据库/命令行工具，会先找找apt的源里有没有相应的包，没有的话再看看是否有PPA源可以用，再没有就只能尝试从源码编译，编译成功前可能还要经历一遍安装编译工具链，依赖库等过程，而这个过程中遇到下代码被墙，依赖库版本太老/太新等麻烦也不少见。 比如说要安装个nginx，模块依赖性Nginx需要依赖下面3个包1.gzip 模块需要 zlib 库 ( 下载: http://www.zlib.NET/ )2.rewrite 模块需要 pcre 库 ( 下载: http://www.pcre.org/ )3.ssl 功能需要 openssl 库 ( 下载: http://www.openssl.org/ )依赖包安装顺序依次为:openssl、zlib、pcre, 然后安装Nginx包 假如有一步出错，就呵呵，一天就没了，话说我自己装个rabbitmq，弄两天没弄好，编译各种失败。技术烂的，各种搞不定，搞定了也没用，对我有什么好处？docker镜像都搞好了，你只需要一行命令，成了。不过这种隔绝了编译过程，可能对软件的理解有一定影响。不过一般人不需要这些，而是快速搞定。如果想要了解，再去查资料好了，而不是我用的时候，先要学习他的原理。 知乎里面有比较形象的解释docker的概念如何通俗解释Docker是什么？ docker的名言: docker:Build Ship and Run Any App, Anywhere! 软件的生态圈Docker有自己的软件生态圈，应用是以镜像的方式存在于仓库上。然后用户可以根据需要去下载对应的镜像 比如说docker官方库https://hub.docker.com/ 再比如阿里云的管理控制台–&gt;产品服务–容器服务–&gt;镜像里提供的镜像下载。这里也可以进行搜索。我的阿里云链接 版本控制使用docker可以灵活的控制镜像的版本，前进或者回退 Docker的安装Docker对操作系统的要求是，必须是64位的、以及是linux 3.8以上版本的内核 我用的是阿里云服务器Centos7(内核是3.10，centos6的好像内核在3.8以下，安装docker会失败):12~]# uname -aLinux iZ2zehu64p5eabr7fp9t0iZ 3.10.0-514.6.2.el7.x86_64 #1 SMP Thu Feb 23 03:04:39 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux 配置yum软件库为保证安装的成功，首先使用yum update更新Yum包，耐心等候吧。然后在yum软件库中新增docker的配置：12# 更新yumyum update 安装启动有了yum软件库的配置之后，安装也变得异常的简单，只需要以下一句即可：12# 安装yum install docker 一切就绪之后，使用start命令来启动Docker守护进程12# 启动docker引擎systemctl start docker 验证输出hello-world，其实就是利用人家已经写好的hello-world镜像，下载到本地，然后把他运行起来1docker run hello-world 出现如下提示表示安装成功1234...Hello from Docker!This message shows that your installation appears to be working correctly.... docker的国内镜像配置一个阿里云、另一个是DaoCloud; 都是免费的 这里用是阿里的镜像，上面也有提到 阿里容器服务 进入容器服务之后，右上角有个镜像仓库管理控制台的按钮，戳它 点进去之后，点击Doker Hub镜像站点，可以看到加速服务地址和镜像配置 编辑配置文件，添加如下内容12345678# 编辑vi /etc/docker/damon.json#添加&#123; "live-restore":true, "registry-mirrors":["https://lh4kbgp2.mirror.aliyuncs.com"]&#125; 重启服务123systemctl daemon-reload systemctl restart docker 下面，我们以安装tomcat为例，来展开docker的使用。 Docker的操作指令repository、image and ContainerDocker中有三个重要的点：仓库（repository）、镜像（image）、容器（Container） 仓库是存储镜像的（类似appstore）而镜像是软件包（app）容器是基于镜像去创建的，基于一个镜像可以创建若干个不同名字但功能相同的容器 先看下docker的架构了解三个点的执行流程 关于容器和镜像的理解，我贫乏的语言就不进行赘述了，找到一个介绍的好理解的大白话Docker入门（二），尤其是里面AUFS的介绍。 安装tomcat假如我们要使用tomcat镜像，首先我们要到仓库中找到它，阿里云提供了 搜索到tomcat，点击详情，翻到下面就可以看到使用tomcat镜像的指令 按照上面的指令运行tomcat吧1Docker run -it -d -p 8084:8080 tomcat:8.0 日志是酱紫的1You can test it by visiting http://container-ip:8080 in a browser or, if you need access outside the host, on port 8888: 在浏览器上访问吧:http://ip:8084/ 那么这些指令参数究竟都是什么意思呢 docker的指令帮助先查看帮助吧1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768docker --helpUsage: docker [OPTIONS] COMMAND [arg...] docker [ --help | -v | --version ]A self-sufficient runtime for containers.Options: --config=~/.docker Location of client config files -D, --debug Enable debug mode -H, --host=[] Daemon socket(s) to connect to -h, --help Print usage -l, --log-level=info Set the logging level --tls Use TLS; implied by --tlsverify --tlscacert=~/.docker/ca.pem Trust certs signed only by this CA --tlscert=~/.docker/cert.pem Path to TLS certificate file --tlskey=~/.docker/key.pem Path to TLS key file --tlsverify Use TLS and verify the remote -v, --version Print version information and quitCommands: attach Attach to a running container build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container diff Inspect changes on a container's filesystem events Get real time events from the server exec Run a command in a running container export Export a container's filesystem as a tar archive history Show the history of an image images List images import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on a container, image or task kill Kill one or more running containers load Load an image from a tar archive or STDIN login Log in to a Docker registry. logout Log out from a Docker registry. logs Fetch the logs of a container network Manage Docker networks node Manage Docker Swarm nodes pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart a container rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images service Manage Docker services start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers swarm Manage Docker Swarm tag Tag an image into a repository top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information volume Manage Docker volumes wait Block until a container stops, then print its exit codeRun 'docker COMMAND --help' for more information on a command. 帮助已经写的非常明白了，这么使用指令1docker [OPTIONS] COMMAND [arg...] COMMAND有这些，后面都有详细的功能介绍1234567Commands: attach Attach to a running container build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container ... 每个指令的使用也可以查看帮助1Run 'docker COMMAND --help' for more information on a command. 比如说，我想查查刚才运行tomcat容器的-it、-d、-p都是啥意思啊,就酱紫1234567891011~]# docker run --helpUsage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]Run a command in a new containerOptions: -i, --interactive Keep STDIN open even if not attached -t, --tty Allocate a pseudo-TTY -d, --detach Run container in background and print container ID -p, --publish value Publish a container's port(s) to the host (default []) 再看下命令1Docker run -it -d -p 8084:8080 tomcat:8.0 诺，-it大概就是命令行的意思，-d表示后台运行呗，-p表示映射端口到服务器，在容器里的8080端口映射到外部服务器8084端口，然后咱就可以输入外部服务器的ip:8084访问啦。 指令分类docker的指令大概可以分为四个种类，分类之后有助于使用，不然到帮助里遍历可能会比较慢 针对守护进程的系统资源设置和全局信息的获取 12docker infodocker daemon 针对docker仓库的查询、下载 12docker searchdocker pull 针对docker镜像的查询、创建、删除 1234docker imagesdocker builddocker deletedocker rmi [image id] 针对docker容器的查询、开启、停止 123docker rundocker psdocker stop [image id /container id] 操作tomcat这里我们操作使用tomcat来熟练下使用 我们已经运行了tomcat容器，那么我们查看下tomcat的运行情况吧，查看帮助12~]# docker --help ps List containers ps命令会列出现有的容器123456789~]# docker ps --helpUsage: docker ps [OPTIONS]List containersOptions: -a, --all Show all containers (default shows just running) --no-trunc Don't truncate output 看到了吧，-a表示列出所有的容器，不写默认显示正在运行的容器123456~]# docker psCONTAINER ID IMAGE PORTS NAMES7b3e73e5c624 tomcat:8.0 0.0.0.0:8084-&gt;8080/tcp clever_shaw04120a965a49 wordpress 0.0.0.0:8082-&gt;80/tcp mywordPress2adb8da207e2 mariadb 3306/tcp mydbee42fdb74565 tomcat:8.0 0.0.0.0:8083-&gt;8080/tcp Atomcat 前面的是CONTAINER ID，用来标识不同的容器 停止tomcat12345~]# docker stop 7b3e73e5c6247b3e73e5c624~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 发现运行的容器找不到了，查看所有容器123~]# docker ps -aCONTAINER ID IMAGE STATUS NAMES7b3e73e5c624 tomcat:8.0 Exited (143) About a minute ago clever_shaw 删掉这个容器12~]# docker rm 7b3e73e5c6247b3e73e5c624 查看镜像1234567~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/redis latest aaf79d45ddb1 2 days ago 106.6 MBdocker.io/wordpress latest 2c69ebee76a8 6 days ago 408.3 MBdocker.io/tomcat 8.0 4b4d4b37d587 7 days ago 453.8 MBdocker.io/mariadb latest eb7b193b1631 7 days ago 397.1 MBdocker.io/hello-world latest 05a3bd381fc2 8 days ago 1.84 kB 删除镜像（以helloworld为例，tomcat在用）12~]# docker rmi 05a3bd381fc2Error response from daemon: conflict: unable to delete 05a3bd381fc2 (must be forced) - image is being used by stopped container 97531974bb1d 发现删不了，因为有容器在使用镜像，所以先要删除容器123456~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES97531974bb1d hello-world "/hello" 4 hours ago Exited (0) 4 hours ago thirsty_chandrasekhar~]# docker rm 97531974bb1d97531974bb1d 然后再删除镜像12345~]# docker rmi 05a3bd381fc2Untagged: docker.io/hello-world:latestUntagged: docker.io/hello-world@sha256:1f19634d26995c320618d94e6f29c09c6589d5df3c063287a00e6de8458f8242Deleted: sha256:05a3bd381fc2470695a35f230afefd7bf978b566253199c4ae5cc96fafa29b37Deleted: sha256:3a36971a9f14df69f90891bf24dc2b9ed9c2d20959b624eab41bbf126272a023 上述操作也可以通过names来完成（上面操作的是id）,给容器起个别名,默认也有名123456~]# docker run --name Atomcat -it -d -p 8083:8080 tomcat:8.0ee42fdb74565e80ff262b40cb172f23b610f4d156c907e04cab5d13e59f1073b~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESee42fdb74565 tomcat:8.0 "catalina.sh run" 6 seconds ago Up 4 seconds 0.0.0.0:8083-&gt;8080/tcp Atomcat 单个容器的详细信息1docker inspect f6071fc4ccc9 查看tomcat日志1docker logs -f Atomcat Docker容器管理容器标识符每个容器被创建以后，都会分配一个Container Id作为容器唯一的标识符，后续对容器的所有操作命令都是通过container id来执行 传说中有128位字符，现在它只显示在当前服务器能够区别开来的字符长度，想看全部的话，加–no-trunc参数123~]# docker ps --no-trunc | awk '&#123;print $1&#125;'CONTAINER7b3e73e5c6243d0d504af7f07f61d052fbc95c8450b6582d384681a0dbfbd577 变的好长。。。 容器内部命令有时候我们需要登录到容器内部执行一些命令或者配置，那么docker可以通过原生的方式去登录到容器 进入容器内部1234567891011121314151617# 查看帮助~]# docker exec --helpUsage: docker exec [OPTIONS] CONTAINER COMMAND [ARG...]Run a command in a running container -d, --detach Detached mode: run command in the background --detach-keys Override the key sequence for detaching a container --help Print usage -i, --interactive Keep STDIN open even if not attached --privileged Give extended privileges to the command -t, --tty Allocate a pseudo-TTY -u, --user Username or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;])# 进入容器内部~]# docker exec -it Atomcat /bin/bash 容器的结构12/]# lsbin boot dev docker-java-home etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 执行完以后，通过exit来退出 多容器管理假设一个场景，加入我现在想用wordpress搭建个人博客在我的服务器上，需要多长时间呢，你会搭建的很顺利吗？这些，通过docker只需要2到3min即可完成。 安装mariaDb12# mydb 表示的自定义的那么 、 --env配置数据的帐号密码Docker run --name mydb –env MYSQL_ROOT_PASSWORD=example -d mariadb 安装wordpress并关联mariaDb12# myWordPress 自定义名称，mydb表示的是第一步所运行的容器名称Docker run –name myWordPress –link mydb:mysql -p 8080:80 -d wordpress 查看下容器1234# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES04120a965a49 wordpress "docker-entrypoint.sh" 16 hours ago Up 16 hours 0.0.0.0:8082-&gt;80/tcp mywordPress2adb8da207e2 mariadb "docker-entrypoint.sh" 16 hours ago Up 16 hours 3306/tcp mydb 可以看到，数据库和wordpress已经跑起来了，找个浏览器访问下吧。 根据引导，你的个人博客就搭建起来了，肿么样，快不快。 Docker compose容器编排工具Docker提供了一个容器编排工具 docker compose,允许用户在一个YAML的文件中定义一组相关联的应用容器 下载地址在这里，都有帮助信息的 查看帮助 借鉴下别人的博客，编辑yaml模板 Run this command to download the latest version of Docker Compose1~]# curl -L https://github.com/docker/compose/releases/download/1.16.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose Apply executable permissions to the binary1local]# chmod +x /usr/local/bin/docker-compose 创建文件~/wordpress/docker-compose.yml这就是个配置文件123456789101112~]# vim docker-compose.yml compose-wordpress: image: wordpress links: - 'compose-db:mysql' ports: - '8086:80'compose-db: image: mariadb environment: MYSQL_ROOT_PASSWORD: example 文件意义：a. 定义了两个服务分别叫做compose_wordpress和compose_dbb. 使用image定义每个服务的镜像名c. MySQL容器的环境变量定义在environmentd. MySQL容器使用links和WildFly容器链接e. 使用ports实现端口转发 补充:这个yaml格式的文件，我写的时候疯狂报错，害我又耽误时间查yaml的语法，结果镜像仓库里有这个代码，早知道就抄过来了。不过springboot也可以用这个写配置文件，学了也不吃亏。 后台模式启动12345~]# docker-compose up -dCreating root_compose-db_1 ... Creating root_compose-db_1 ... doneCreating root_compose-wordpress_1 ... Creating root_compose-wordpress_1 ... done 查看1234~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES32d75b04dfeb wordpress &quot;docker-entrypoint.sh&quot; 11 seconds ago Up 7 seconds 0.0.0.0:8086-&gt;80/tcp root_compose-wordpress_11394b6ee28b0 mariadb &quot;docker-entrypoint.sh&quot; 11 seconds ago Up 11 seconds 3306/tcp root_compose-db_1 浏览器访问就可以了。 停止服务1docker-compose start/stop 删除服务1docker-compose ~/wordpress/docker-compose.yml down 检查日志1docker-compose logs 检查运行的实例1docker-compose ps 镜像分层设计docker特点docker image的体积非常的小 docker的系统启动的耗时为0 docker系统占用资源极少 为什么呢基于aufs实现镜像分层大量复用已有的镜像资源，嗯，差不多就酱紫，话说我也一直半解。 镜像的层的特性 已有的分层只能读不能修改 上层镜像的优先级高于底层镜像 可以通过在上层增加新的镜像，来覆盖底层镜像以达到修改的目的 资料网上有很多大牛的博客写的很好或者写的非常精巧便于理解，放在这里做个索引 官方文档使用的时候查这个最方便了 理解docker架构有助于了解docker的运行流程 docker架构 这篇文章通俗的讲解了aufs系统的原理，对于理解镜像分层概念很有帮助 Docker入门 阿里云仓库 ali-rep]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot]]></title>
    <url>%2F2017%2F09%2F19%2Fspring-boot%2F</url>
    <content type="text"><![CDATA[spring-boot新框架，大量默认配置简化开发， Spring Boot是为了简化Spring应用的创建、运行、调试、部署等而出现的，使用它可以做到专注于Spring应用的开发，而无需过多关注XML的配置。简单来说，它提供了一堆依赖打包，并已经按照使用习惯解决了依赖问题—习惯大于约定。 Spring Boot默认使用tomcat作为服务器，使用logback提供日志记录。 Spring Boot提供了一系列的依赖包，所以需要构建工具的支持：maven 或 gradle。 这里做个记录。demo项目放在github上，点我 官方文档去官网找，这里发现个翻译版的，好矛盾，是不是不应该看中文的。 找到一个写的比较完整的教程:springboot-%E5%85%A5%E9%97%A8%E7%AF%87.html) 常用配置Spring boot 四个核心：Starter，autoconfiguration，actuator，CLI 常用配置属性配置可以在application.properties或者application.yml中配置属性，比如说12server.port=8888server.context-path=/demo 导入xml配置@importResouce 如果在实际项目中，存在特殊场景必须使用xml配置，那么可以通过这个注解来加载xml配置 外部配置使用@ConfigurationProperties将properties属性和一个bean中的属性做关联，比如想把两个常量配置注入到controller中使用，先在properties中配置12demo.student.name=tomdemo.student.age=23 然后写个专门注入常量的类，用@ConfigurationProperties注解来注入properties中的常量，可以用prefix来配置前缀。123456789101112131415161718192021222324252627282930313233343536373839@ConfigurationProperties(prefix = "demo.student")@Componentpublic class StudentConstants &#123; private String name; private Integer age; /** * @return the name */ public String getName() &#123; return name; &#125; /** * @param name * the name to set */ public void setName(String name) &#123; this.name = name; &#125; /** * @return the age */ public Integer getAge() &#123; return age; &#125; /** * @param age * the age to set */ public void setAge(Integer age) &#123; this.age = age; &#125;&#125; 在controller中注入常量类对象来获取常量的值1234567891011121314@RestControllerpublic class StudentController &#123; @Autowired private StudentConstants studentConstants; @RequestMapping("/getStudent") public Student getStudent() &#123; Student student = new Student(); student.setName(studentConstants.getName()); student.setAge(studentConstants.getAge()); return student; &#125;&#125; 使用profile在多环境下切换实际开发中可能遇到不同环境需要不同配置的情况，这样的情况下可以定义不同的配置文件而在需要相应的开发环境时做切换。 首先在application.properties中定一个spring.profiles.active={profile}然后在application-{profile}.properties中写入不同环境的变量就可以了，比如我开发、生产环境的student默认name和age不同 先在application.properties中定义活跃的profile 12345spring.profiles.active=dev# 注意此时定义的属性值demo.student.name=tomdemo.student.age=23 然后在application-dev中添加常量属性 12demo.student.name=jerrydemo.student.age=24 运行下试试吧 12345//没有设spring.profiles.active=dev时值是这样的&#123;"id":null,"name":"tom","age":23,"sex":null&#125;//设置spring.profiles.active=dev时值是这样的&#123;"id":null,"name":"jerry","age":24,"sex":null&#125; 组件(SpringBoot启动器) spring-boot-starter:这是SpringBoot的核心启动器，包含了自动配置、日志和YAML。 spring-boot-starter-actuator:帮助监控和管理应用。 spring-boot-starter-amqp:通过spring-rabbit来支持AMQP协议（Advanced Message Queuing Protocol）。 spring-boot-starter-aop:支持面向方面的编程即AOP，包括spring-aop和AspectJ。 spring-boot-starter-artemis:通过Apache Artemis支持JMS的API（Java Message Service API）。 spring-boot-starter-batch:支持Spring Batch，包括HSQLDB数据库。 spring-boot-starter-cache:支持Spring的Cache抽象。 spring-boot-starter-cloud-connectors:支持Spring Cloud Connectors，简化了在像Cloud Foundry或Heroku这样的云平台上连接服务。 spring-boot-starter-data-elasticsearch:支持ElasticSearch搜索和分析引擎，包括spring-data-elasticsearch。 spring-boot-starter-data-gemfire:支持GemFire分布式数据存储，包括spring-data-gemfire。 spring-boot-starter-data-jpa:支持JPA（java Persistence API），包括spring-data-jpa、spring-orm、hibernate。 spring-boot-starter-data-MongoDB:支持mongodb数据，包括spring-data-mongodb。 spring-boot-starter-data-rest:通过spring-data-rest-webmvc，支持通过REST暴露Spring Data数据仓库。 spring-boot-starter-data-solr:支持Apache Solr搜索平台，包括spring-data-solr。 spring-boot-starter-freemarker:支持FreeMarker模板引擎。 spring-boot-starter-groovy-templates:支持Groovy模板引擎。 spring-boot-starter-hateoas:通过spring-hateoas支持基于HATEOAS的RESTful Web服务。 spring-boot-starter-hornetq:通过HornetQ支持JMS。 spring-boot-starter-integration:支持通用的spring-integration模块。 spring-boot-starter-jdbc:支持JDBC数据库。 spring-boot-starter-jersey:支持Jersey RESTful Web服务框架。 spring-boot-starter-jta-atomikos:通过Atomikos支持JTA分布式事务处理。 spring-boot-starter-jta-bitronix:通过Bitronix支持JTA分布式事务处理。 spring-boot-starter-mail:支持javax.mail模块。 spring-boot-starter-mobile:支持spring-mobile。 spring-boot-starter-mustache:支持Mustache模板引擎。 spring-boot-starter-Redis:支持redis键值存储数据库，包括spring-redis。 spring-boot-starter-security:支持spring-security。 spring-boot-starter-social-facebook:支持spring-social-facebook spring-boot-starter-social-linkedin:支持pring-social-linkedin spring-boot-starter-social-twitter:支持pring-social-twitter spring-boot-starter-test:支持常规的测试依赖，包括JUnit、Hamcrest、Mockito以及spring-test模块。 spring-boot-starter-thymeleaf:支持Thymeleaf模板引擎，包括与Spring的集成。 spring-boot-starter-velocity:支持Velocity模板引擎。 spring-boot-starter-web:S支持全栈式Web开发，包括Tomcat和spring-webmvc。 spring-boot-starter-websocket:支持WebSocket开发。 spring-boot-starter-ws:支持Spring Web Services。 自己实现starter来理解启动器原理创建个maven工程，导入依赖spring-boot12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot&lt;/artifactId&gt; &lt;version&gt;1.5.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; 创建service类1234567891011121314package com.gsc.springboot.starter.demo;/** * @author shichaogeng * * 2017年9月22日 */public class HelloService &#123; public String sayHello() &#123; System.out.println("Hello Starter"); return "hello starter"; &#125;&#125; 创建自动配置类1234567891011121314151617181920package com.gsc.springboot.starter.demo;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author shichaogeng * * 2017年9月22日 */@Configuration//@EnableAutoConfiguration会自动扫描管理@Configuration的类完成初始化配置public class HelloAtuoConfiure &#123; @Bean //@Bean表示这个方法创建的类，会交给spirng容器 public HelloService sayHello() &#123; return new HelloService(); &#125;&#125; 在resources目录下创建/META-INF/spring.factories文件，加入如下配置1org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.gsc.springboot.starter.demo.HelloAtuoConfiure 使用maven install打成jar包，在springboot项目中导入依赖，就可以当做一个starter来使用了。1234567891011121314151617181920212223242526package com.gsc.demo.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import com.gsc.demo.config.StudentConstants;import com.gsc.demo.domain.Student;import com.gsc.springboot.starter.demo.HelloService;/** * @author shichaogeng * * 2017年9月22日 */@RestControllerpublic class StudentController &#123; @Autowired private HelloService HelloService; @RequestMapping("/hellostarter") public String helloStarter() &#123; return HelloService.sayHello(); &#125;&#125; 启动工程，访问结果如下1hello starter actuator默认终端导入依赖12345&lt;!-- 监控 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 在application.properties中打开配置，就可以看到一些springboot项目的运行状况123endpoints.env.sensitive=falseendpoints.trace.sensitive=falseendpoints.beans.sensitive=false 访问localhost：8888/demo/env /info /metrics /health /beans /trace 等等 也可以自己扩展定义个类继承AbstractEndpoint就可以实现扩展1234567891011121314151617181920212223242526272829303132333435package com.gsc.demo.endpoint;import java.text.SimpleDateFormat;import java.util.Date;import org.springframework.boot.actuate.endpoint.AbstractEndpoint;import org.springframework.boot.context.properties.ConfigurationProperties;/** * @author shichaogeng * * 2017年9月22日 */@ConfigurationProperties(prefix="endpoints.servertimes")public class ServerTimeEndPoint extends AbstractEndpoint&lt;String&gt;&#123; /** * @param id */ public ServerTimeEndPoint() &#123; super("servertimes"); &#125; /** * @author shichaogeng * @date 2017年9月22日 * @return */ @Override public String invoke() &#123; return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new Date()); &#125;&#125; invoke方法中定义自己要实现的检测内容，然后实例化你的类交给spring管理123456789101112131415161718192021package com.gsc.demo.config;import org.springframework.boot.actuate.endpoint.Endpoint;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import com.gsc.demo.endpoint.ServerTimeEndPoint;/** * @author shichaogeng * * 2017年9月22日 */@Configurationpublic class EndpointCofig &#123; @Bean public Endpoint&lt;String&gt; serverTimes() &#123; return new ServerTimeEndPoint(); &#125;&#125; 配置文件中打开配置，默认是true，在父类构造中1endpoints.servertimes.sensitive=false 访问 localhost:8888/demo/servertimes看到12017-09-22 16:11:56 一个检测时间的就写好了 spring CLI一个自动化管理的脚本，具体的去官网看吧 Installing the Spring Boot CLI pom配置 Springboot父工程依赖 123456&lt;parent&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;&lt;version&gt;1.3.1.RELEASE&lt;/version&gt;&lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt; Springboot web启动器依赖 1234&lt;dependency&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 常用注解 @SpringBootApplication：包含了@ComponentScan、@Configuration和@EnableAutoConfiguration注解。其中@ComponentScan让spring Boot扫描到Configuration类并把它加入到程序上下文。 @Configuration 等同于spring的XML配置文件；使用Java代码可以检查类型安全。 @EnableAutoConfiguration 自动配置。 @ComponentScan 组件扫描，可自动发现和装配一些Bean。 @Component可配合CommandLineRunner使用，在程序启动后执行一些基础任务。 @RestController注解是@Controller和@ResponseBody的合集,表示这是个控制器bean,并且是将函数的返回值直接填入HTTP响应体中,是REST风格的控制器。 @Autowired自动导入。 @PathVariable获取参数。 @JsonBackReference解决嵌套外链问题。 @RepositoryRestResourcepublic配合spring-boot-starter-data-rest使用。 @EnableAutoConfiguration：SpringBoot自动配置（auto-configuration）：尝试根据你添加的jar依赖自动配置你的Spring应用。例如，如果你的classpath下存在HSQLDB，并且你没有手动配置任何数据库连接beans，那么我们将自动配置一个内存型（in-memory）数据库”。你可以将@EnableAutoConfiguration或者@SpringBootApplication注解添加到一个@Configuration类上来选择自动配置。如果发现应用了你不想要的特定自动配置类，你可以使用@EnableAutoConfiguration注解的排除属性来禁用它们。 这个注释告诉SpringBoot“猜”你将如何想配置Spring,基于你已经添加jar依赖项。如果spring-boot-starter-web已经添加Tomcat和Spring MVC,这个注释自动将假设您正在开发一个web应用程序并添加相应的spring设置。 自动配置被设计用来和“Starters”一起更好的工作,但这两个概念并不直接相关。您可以自由挑选starter依赖项以外的jar包，springboot仍将尽力自动配置您的应用程序。 @Bean:相当于XML中的bean,放在方法的上面，而不是类，意思是产生一个bean,并交给spring管理。 SpringBoot启动123456789import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class SpringBootSampleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootSampleApplication.class, args); &#125; &#125; 配置文件去官网看吧 SpringBoot支持JSP 配置application.properties 1234# 页面默认前缀目录spring.mvc.view.prefix=/WEB-INF/jsp/# 响应页面默认后缀spring.mvc.view.suffix=.jsp 加入依赖 123456789&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; SpringBoot支持freemarker 配置application.properties 12345678spring.freemarker.allow-request-override=falsespring.freemarker.cache=truespring.freemarker.check-template-location=truespring.freemarker.charset=UTF-8spring.freemarker.content-type=text/htmlspring.freemarker.expose-request-attributes=falsespring.freemarker.expose-session-attributes=falsespring.freemarker.expose-spring-macro-helpers=false 加入依赖 12345&lt;!-- 引入freeMarker的依赖包. --&gt;&lt;dependency&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;&lt;/dependency&gt; SpringBoot-Servlet注册Springboot中有两种方式可以添加 Servlet、Filter、Listener 代码注册通过ServletRegistrationBean、 FilterRegistrationBean 和 ServletListenerRegistrationBean 获得控制 1234@Bean public ServletRegistrationBean servletRegistrationBean() &#123; return new ServletRegistrationBean(new MyServlet(), "/xs/*");&#125; 在 SpringBootApplication 上使用@ServletComponentScan 注解后，Servlet、Filter、Listener 可以直接通过 @WebServlet、@WebFilter、@WebListener 注解自动注册，无需其他代码。 1234567@SpringBootApplication@ServletComponentScanpublic class SpringBootSampleApplication &#123; public static void main(String[] args)&#123; SpringApplication.run(SpringBootSampleApplication.class, args); &#125; &#125; SpringBoot拦截器 创建我们自己的拦截器类并实现 HandlerInterceptor 接口。 创建一个Java类继承WebMvcConfigurerAdapter，并重写 addInterceptors 方法。 实例化我们自定义的拦截器，然后将对像手动添加到拦截器链中（在addInterceptors方法中添加）。 SpringBoot静态资源处理 Spring Boot 的默认资源映射 其中默认配置的 /** 映射到 /static （或/public、/resources、/META-INF/resources） 其中默认配置的 /webjars/**映射到classpath:/META-INF/resources/webjars/..上面的 static、public、resources 等目录都在 classpath: 下面（如 src/main/resources/static）。 自定义资源映射 继承 WebMvcConfigurerAdapter 并重写方法 addResourceHandlers 12registry.addResourceHandler("/image/**").addResourceLocations("file:H:/image/");registry.addResourceHandler("/image1/**").addResourceLocations("classpath:/img1/") 通过配置文件映射 使用 spring.mvc.static-path-pattern 可以重新定义pattern，如修改为 /image/** 使用 spring.resources.static-locations 可以重新定义 pattern 所指向的路径，支持 classpath: 和 file: 注意 spring.mvc.static-path-pattern 只可以定义一个，目前不支持多个逗号分割的方式。 默认值为 /映射: spring.mvc.static-path-pattern= /image/ 默认值为 classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/映射: spring.resources.static-locations=classpath:/image/ SpringBoot启动加载数据实际应用中，我们会有在项目服务启动的时候就去加载一些数据或做一些事情这样的需求。 为了解决这样的问题，spring Boot 为我们提供了一个方法，通过实现接口 CommandLineRunner 来实现。 SpringBoot日志spring boot内部使用Commons Logging来记录日志，但也保留外部接口可以让一些日志框架来进行实现，例如Java Util Logging,Log4J2还有Logback。如果你想用某一种日志框架来进行实现的话，就必须先配置，默认情况下，spring boot使用Logback作为日志实现的框架。 ${LOG_PATH}, Spring Boot配置文件中logging.path的值 配置logging.level.*来具体输出哪些包的日志级别logging.level.root=INFOlogging.level.org.springframework.web=DEBUGlogging.level.org.hibernate=ERROR 将日志输出到文件中logging.path=D:\demologging.file=demo.loglogging.level.root=info 关于logback使用请参照从零开始玩转logback SpringBoot-JDBC 属性配置文件（application.properties） 1234spring.datasource.url=jdbc:mysql://localhost:3306/test spring.datasource.username=root spring.datasource.password=123456 spring.datasource.driver-class-name=com.mysql.jdbc.Driver pom.xml 配置maven依赖 1&lt;!-- MYSQL --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot JDBC --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; Springboot-Mybatis pom.xml 配置maven依赖 1&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; 一定要在启动的地方加上@MapperScan(“com.dongnao.jack.dao”) 配置文件中加上配置 12mybatis.typeAliasesPackage=com.dongnao.jack.beanmybatis.mapperLocations=classpath:com/dongnao/jack/xml/*Mapper.xml SpringBoot动态数据源抄的这里 启动类注册动态数据源 123456@SpringBootApplication@Import(&#123;DynamicDataSourceRegister.class&#125;) // 注册动态多数据源public class SpringBootSampleApplication &#123; // 省略其他代码&#125; 配置文件中配置多个数据源(application.properties) 1234567891011121314151617# 主数据源，默认的spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.url=jdbc:mysql://localhost:3306/testspring.datasource.username=rootspring.datasource.password=123456# 更多数据源custom.datasource.names=ds1,ds2custom.datasource.ds1.driver-class-name=com.mysql.jdbc.Drivercustom.datasource.ds1.url=jdbc:mysql://localhost:3306/test1custom.datasource.ds1.username=rootcustom.datasource.ds1.password=123456custom.datasource.ds2.driver-class-name=com.mysql.jdbc.Drivercustom.datasource.ds2.url=jdbc:mysql://localhost:3306/test2custom.datasource.ds2.username=rootcustom.datasource.ds2.password=123456 在方法用注解指定数据源 123456789101112131415@Servicepublic class StudentService &#123; // MyBatis的Mapper方法定义接口 @Autowired private StudentMapper studentMapper; @TargetDataSource(name=&quot;ds2&quot;) public List&lt;Student&gt; likeName(String name)&#123; return studentMapper.likeName(name); &#125; public List&lt;Student&gt; likeNameByDefaultDataSource(String name)&#123; return studentMapper.likeName(name); &#125; 这个博客讲的好明白Spring(AbstractRoutingDataSource)实现动态数据源切换 这里记下运行流程代码地址点spring-boot动态数据源github代码 通知spring注册动态数据源(DemoApplication)123456789@SpringBootApplication@MapperScan(basePackages="com.gsc.demo.mapper")@Import(&#123;DynamicDataSourceRegister.class&#125;) // 注册动态多数据源public class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 动态数据源注册(DynamicDataSourceRegister)12public class DynamicDataSourceRegister implements ImportBeanDefinitionRegistrar, EnvironmentAware &#123;&#125; spring调用EnvironmentAware.setEnvironment()接口读取配置文件，加载数据源 12345678/** * 加载多数据源配置 */@Overridepublic void setEnvironment(Environment env) &#123; initDefaultDataSource(env); initCustomDataSources(env);&#125; 在spring中加载registerBeanDefinitions的bean 1public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123;&#125; aop切换数据源(DynamicDataSourceAspect) 在StudentServiceImpl中调用方法之前，看到注解@TargetDataSource 1234567891011/** * @author shichaogeng * @date 2017年9月20日 * @param name * @return */@Override@TargetDataSource(name="ds1")public List&lt;Student&gt; likeName(String name) &#123; return studentMapper.likeName(name);&#125; 动态代理，先执行切面(DynamicDataSourceAspect)增强方法@Before，设置数据源 12345678910111213141516171819202122232425/** * * 切换数据源Advice * @author shichaogeng * * 2017年9月20日 */@Aspect@Order(-1)// 保证该AOP在@Transactional之前执行@Componentpublic class DynamicDataSourceAspect &#123; private static final Logger logger = LoggerFactory.getLogger(DynamicDataSourceAspect.class); @Before("@annotation(ds)") public void changeDataSource(JoinPoint point, TargetDataSource ds) throws Throwable &#123; String dsId = ds.name(); if (!DynamicDataSourceContextHolder.containsDataSource(dsId)) &#123; logger.error("数据源[&#123;&#125;]不存在，使用默认数据源 &gt; &#123;&#125;", ds.name(), point.getSignature()); &#125; else &#123; logger.debug("Use DataSource : &#123;&#125; &gt; &#123;&#125;", ds.name(), point.getSignature()); DynamicDataSourceContextHolder.setDataSourceType(dsId); &#125; &#125;&#125; 获取数据源 执行studentMapper.likeName(name)，这里需要获取数据源 12345678910111213public List&lt;Student&gt; likeName(String name) &#123; return studentMapper.likeName(name);&#125;/** * @author shichaogeng * * 2017年9月20日 */public interface StudentMapper &#123; List&lt;Student&gt; likeName(String name);&#125; 执行AbstractRoutingDataSource数据源路由获取连接getConnection() 1234@Overridepublic Connection getConnection() throws SQLException &#123; return determineTargetDataSource().getConnection();&#125; 可以看到要调用determineTargetDataSource获取数据源 123456789101112protected DataSource determineTargetDataSource() &#123; Assert.notNull(this.resolvedDataSources, "DataSource router not initialized"); Object lookupKey = determineCurrentLookupKey(); DataSource dataSource = this.resolvedDataSources.get(lookupKey); if (dataSource == null &amp;&amp; (this.lenientFallback || lookupKey == null)) &#123; dataSource = this.resolvedDefaultDataSource; &#125; if (dataSource == null) &#123; throw new IllegalStateException("Cannot determine target DataSource for lookup key [" + lookupKey + "]"); &#125; return dataSource;&#125; 其中关键代码就是获取数据源的key 1Object lookupKey = determineCurrentLookupKey(); 这里就调用AbstractRoutingDataSource的实现类DynamicDataSource 123456789101112131415/** * * 动态数据源 * @author shichaogeng * * 2017年9月20日 */public class DynamicDataSource extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; return DynamicDataSourceContextHolder.getDataSourceType(); &#125;&#125; 就酱紫了，结束了，一切都结束了。]]></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>动态数据源切换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins牛刀小试]]></title>
    <url>%2F2017%2F09%2F15%2FJenkins%E7%89%9B%E5%88%80%E5%B0%8F%E8%AF%95%2F</url>
    <content type="text"><![CDATA[想用jenkins完成项目自动部署，结果搞了一下午各种失败，没办法，买了个阿里云服务器，以后在这上面玩吧。从头弄下，搭建个基本环境，然后记录下，故有此文。 环境12[root@test105 /usr/local/tomcat/webapps]# uname -aLinux test105.server 2.6.32-504.el6.x86_64 #1 SMP Wed Oct 15 04:27:16 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux Jdk tomcat运行需要jdk环境，网上下个jdk1.8。下载地址 有自带的jdk就卸了 12345java –versionrpm -qa | grep javarpm -e --nodeps java-1.7.0-openjdk-1.7.0.45-2.4.3.3.el6.x86_64rpm -e --nodeps java-1.6.0-openjdk-1.6.0.0-1.66.1.13.0.el6.x86_64 上传jdk到服务器，解压 1234567tar -zxvf jdk-8u144-linux-x64.tar.gzcp -r jdk1.8.0_144/ /lab/dev/[root@iZ2zehu64p5eabr7fp9t0iZ dev]# cd /lab/dev/ &amp;&amp; lltotal 4drwxr-xr-x 8 root root 4096 Sep 15 15:09 jdk1.8.0_144 第三步：配置环境变量 123456789101112vim /etc/profile# 在文件末尾追加JAVA_HOME=/usr/jdkexport CLASSPATH=.:$JAVA_HOME/libexport PATH=$JAVA_HOME/bin:$PATH# 保存退出:wq#重启source /etc/profile 检验，看成了没 1234567[root@iZ2zehu64p5eabr7fp9t0iZ dev]# echo $PATH/lab/dev/jdk1.8.0_144/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin[root@iZ2zehu64p5eabr7fp9t0iZ dev]# java -versionjava version "1.8.0_144"Java(TM) SE Runtime Environment (build 1.8.0_144-b01)Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode) Tomcat 下载 上传，解压 12345tar -zxvf apache-tomcat-8.0.46.tar.gz [root@iZ2zehu64p5eabr7fp9t0iZ source]# cp -rf apache-tomcat-8.0.46 /lab/dev/tomcat-jenkins[root@iZ2zehu64p5eabr7fp9t0iZ source]# cp -rf apache-tomcat-8.0.46 /lab/dev/tomcat-server01 配置下server01用tomcat端口号 配置下server01用tomcat用户权限（jenkins部署用）` 12345678910# 编辑vim tomcat-users.xml #添加&lt;role rolename="tomcat"/&gt;&lt;role rolename="role1"/&gt;&lt;role rolename="manager-gui"/&gt;&lt;role rolename="manager-script"/&gt;&lt;role rolename="manager-status"/&gt;&lt;user username="tomcat" password="tomcat" roles="manager-gui,manager-script,manager-status"/&gt; 启动下，找个浏览器看能不能访问 Maven 下载 上传服务器，解压 123tar -zxvf apache-maven-3.5.0-bin.tar.gz cp -r apache-maven-3.5.0 /lab/dev/ 配置maven 1234567891011121314151617# 编辑# 添加&lt;localRepository&gt;/lab/dev/apache-maven-3.5.0/repository&lt;/localRepository&gt;&lt;!--配置阿里云国内镜像 --&gt;&lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;&lt;/mirror&gt; &lt;mirror&gt; &lt;id&gt;central&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;url&gt;http://repo1.maven.org/maven2/&lt;/url&gt;&lt;/mirror&gt; 环境变量 12345678910# 编辑vim /etc/profile# 添加MAVEN_HOME=/lab/dev/apache-maven-3.5.0PATH=$PATH:$MAVEN_HOME/binexport PATH MAVEN_HOME# 加载source /etc/profile Git安装git 我yum安装时报错，然后就百度一番，也记录下吧。 123456# 错误Not using downloaded repomd.xml because it is older than what we have# 解决（清空缓存）yum clean allyum makecache 安装 1234567yum -y install git# 测试git --version# 查看帮助git --help 配置github用户配置我要用github上的项目做测试，配置github用户名密码12git config --global user.name shichaogenggit config --global user.email shichaogeng@gmail.com 配置秘钥 git在部署github时使用SSH协议连接和验证远程服务器和服务。为避免暴露账户密码，最好使用证书认证。使用SSH密钥，可以连接到GitHub，而无需在每次访问时提供用户名或密码。 查看密匙执行cd ~/.ssh命令，如果存在该目录，表明之前生成果SSH Key，利用ll命令即可以查看。123[root@iZ2zehu64p5eabr7fp9t0iZ .ssh]# lltotal 0-rw------- 1 root root 0 Sep 15 13:20 authorized_keys 看一下有没有id_rsa和id_rsa.pub(或者是id_dsa和id_dsa.pub之类成对的文件)，有.pub 后缀的文件就是公钥，另一个文件则是密钥。 假如没有这些文件，甚至连.ssh 目录都没有，可以用 ssh-keygen 来创建。该程序在 Linux/Mac 系统上由 SSH 包提供，而在 Windows 上则包含在 MSysGit 包里。 生成私钥12345678910111213141516171819202122[root@iZ2zehu64p5eabr7fp9t0iZ .ssh]# ssh-keygen -t rsa -C "shichaogeng@gmail.com"Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:4f:e4:71:c2:89:92:03:80:41:1c:c2:11:cc:06:ff:ea shichaogeng@gmail.comThe key's randomart image is:+--[ RSA 2048]----+|@B=.. ||oB . . o . ||. . + . * . || . o o + || . S o || . o || . . || . || E |+-----------------+# 本地密匙生成成功！ 查看生成的公钥1ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7+EsE7t+TmI9AA16QQMNnwB3fbogZGznD18jttNvANvkYITlNnty2a/qiFdVuaSvPHbwW5djKT8fwVpieJStlefEsdAXg+r7DPgyttFf2vHYdHULdZNc48aNy/GN1hZFvPU1PwsV/xAL8phFER4aFhQYygcnkY1/KbfSZOHo+9uL+oc7bBQZYTEhfdl+twwesnAt3erSPIl1U0Cv5tkCdj2WRnLGiLXdnUfK7Zq5jtfQiXWeXCXjt3+wB0zWS1W6HysQ4pJ5f7OuuzG8sHj44KTYqSf5hSHuGVXX5P7x9OiKT4zDyZ/rBsGJAehyxDRd3ErAP2D4IY1zmpzgEBkgx shichaogeng@gmail.com github公钥登陆github帐户。点击头像，然后 Settings -&gt; 左栏点击 SSH and GPG keys -&gt; 点击 New SSH key，向下面酱紫的界面 然后你复制上面的公钥内容，粘贴进“Key”文本域内。 title域，自己随便起个名字。点击 Add key。 完成以后，验证下这个key是不是正常工作123456[root@iZ2zehu64p5eabr7fp9t0iZ .ssh]# ssh -T git@github.comThe authenticity of host 'github.com (192.30.255.112)' can't be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added 'github.com,192.30.255.112' (RSA) to the list of known hosts.Hi shichaogeng! You've successfully authenticated, but GitHub does not provide shell access. 搞定！ Jenkins下载安装还是先下载 把下的war包，上传服务器，放到tomat下1cp jenkins.war /lab/dev/tomcat-jenkins/webapps/ 浏览器访问”http://47.94.170.46:8080/jenkins&quot;，出现如下界面 让你输入密匙，tomcat日志查到这个12345# 我的密匙1d4989effd224179a60709f5e5fbda3d# 密匙路径This may also be found at: /root/.jenkins/secrets/initialAdminPassword 输入密匙，就开始初始化，然后让你选择插件，我就选推荐安装，等吧（有点久）。。。 装插件继续装插件 单独添加两个插件 Maven Integration pluginPublish Over SSH 装完得重启（等。。。） Global Tool Configurationconfiguration jdk配置 git配置 maven配置 系统设置系统设置 Publish over SSH 设置 构建项目（只挑重要的截图啦）源码管理 构建 构建后操作 服务器上执行的bash脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/bin/bash #定义变量export JAVA_HOME=/lab/dev/jdk1.8.0_144TOMCAT_PORT=8081TOMCAT_HOME="/lab/dev/tomcat-server01"PROJECT="$1"SERVER="/lab/publish"#参数验证if [ $# -lt 1 ]; then echo "you must use like this : ./publish.sh &lt;projectname&gt; [tomcat port] [tomcat home dir]" exitfiif [ "$2" != "" ]; then TOMCAT_PORT=$2fiif [ "$3" != "" ]; then TOMCAT_HOME="$3"fiif [ ! -e "$SERVER"/"$PROJECT".war ]; then echo "$PROJECT".war "文件不存在，结束当前执行" exit;fi#关闭 tomcat "$TOMCAT_HOME"/bin/shutdown.sh#杀进程kill -9 $(lsof -i:'$TOMCAT_PORT' |awk '&#123;print $2&#125;'| tail -1)echo "tomcat shutdown" #替换war包 rm -rf "$TOMCAT_HOME"/webapps/"$PROJECT"*mv /lab/publish/$PROJECT.war "$TOMCAT_HOME"/webapps/$PROJECT.warecho "替换webapps下的war包"#备份项目 BAK_DIR=/lab/publish/bak/$PROJECT/`date +%Y%m%d`mkdir -p "$BAK_DIR"cp "$TOMCAT_HOME"/webapps/$PROJECT.war "$BAK_DIR"/"$PROJECT"_`date +%H%M%S`.war#启动 tomcat"$TOMCAT_HOME"/bin/startup.shecho "tomcat is starting,please try to access $PROJECT conslone url" 再记录下平时重启服务的命令1ps -ef | grep flm | grep -v grep | awk '&#123;print $2&#125;' | xargs kill -9 &amp;&amp; rm -r logs/* &amp;&amp; rm -rf work/* &amp;&amp; ./bin/startup.sh &amp;&amp; tail -f logs/catalina.out 差不多就酱紫，反正我是自动部署成功了，还有一些其他的功能，这里只完成基本的。有精力再弄吧!]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>Jenkins</tag>
        <tag>github</tag>
        <tag>jdk</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化（一）--- MySQL参数优化]]></title>
    <url>%2F2017%2F09%2F12%2FMySQL%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[一些没营养的东西，懒得弄了，有时间再补充下吧，先记录下。 操作系统的优化优化网络连接使用netstat查看连接1234567891011[root@localhost ~]# netstat -anActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN tcp 0 0 192.168.25.143:22 192.168.25.1:58527 ESTABLISHEDtcp 0 0 192.168.25.143:22 192.168.25.1:57553 ESTABLISHEDtcp 0 52 192.168.25.143:22 192.168.25.1:58078 ESTABLISHEDtcp 0 0 192.168.25.143:22 192.168.25.1:63590 ESTABLISHEDtcp6 0 0 :::3306 :::* LISTEN tcp6 0 0 :::22 :::* LISTEN tcp6 0 0 192.168.25.143:3306 192.168.25.139:48938 ESTABLISHED state参数：ESTABLISHED：正在通讯 TIME_WAIT: 主动关闭 CLOSE_WAIT:被动关闭time_wait会导致服务器error：Too Many Open files 优化思路：让服务器能够自动快速回收和重复利用Time_Wait资源 编辑vi /etc/sysctl.conf，加入的内容：12345678# 开启重用：允许将TIME_WAIT socket资源重新用于新的TCP连接，默认是0，关闭 net.ipv4.tcp_rw_reuse=1# 开启回收:net.ipv4.tcp_tw_recycle=1# 使配置生效：sysctl –p Open files查看用户默认打开的最大文件数，默认1024：12[root@localhost ~]# ulimit -n1024 修改打开文件数，vi /etc/profile，加入如下内容 1234ulimit –n 65535# 使配置生效source /etc/profile vi /etc/security/limits.conf，在末尾加入如下内容： 1234* soft nofile 65535* hard nofile 65535* soft nproc 65535* hard nproc 65535 MySQL对多核CPU利用特点MySQL5.1之后，支持多核心5.6,5.7都支持64核CPU 架构设计scale up ： 向上扩展，也叫纵向扩展scale out： 向外扩展，也叫水平扩展 内存使用建议：MySQL内存配置位物理内存的70%左右 MySQL配置优化大部分情况下使用innodb作为表存储引擎,以下参数配置在my.cnf中 innodb的缓冲池配置1innodb_buffer_pool_size 这对Innodb表来说非常重要。Innodb相比MyISAM表对缓冲更为敏感。MyISAM可以在默认的key_buffer_size设置下运行的可以，然而Innodb在默认的 innodb_buffer_pool_size设置下却跟蜗牛似的。由于Innodb把数据和索引都缓存起来，无需留给操作系统太多的内存，因此如果只需要用Innodb的话则可以设置它高达 70-80% 的可用内存。一些应用于 key_buffer 的规则有 — 如果你的数据量不大，并且不会暴增，那么无需把 innodb_buffer_pool_size 设置的太大了。 innodb log 缓存配置1innodb_log_buffer_size 此参数确定些日志文件所用的内存大小，以M为单位。缓冲区更大能提高性能，但意外的故障将会丢失数据.MySQL开发人员建议设置为1－8M之间 配置缓冲池个数1innodb_buffer_pool_instances 默认情况下只有一个 在提交事务的时候，是否刷新日志缓冲（重要，对性能影响较大）1innodb_flush_log_at_trx_commit 有3个值：0：不会主动触发日志缓冲写入磁盘1（默认）：每次提交事务的时候，同时会把日志缓冲刷新到磁盘2：每次提交事务的时候，会把日志缓冲刷新到磁盘，但是他不是同时进行的，而是每秒钟刷新一次 怎么配置考虑两个点： 考虑安全性：如果对数据安全性较高，配置成1 考虑性能：建议配置成2 理由：再高并发事务下，如果执行事务的同时就把缓存中刷新到磁盘，就会大量的对磁盘进行写操作，导致大量的IO innodb读写IO的线程数12innodb_read_io_threadsinnodb_write_io_threads 默认都是4个 独立表空间配置1innodb_file_per_table 默认是打开的 查询缓存1query_cache_size 参考可以找别人博客中的介绍，或者自己到官网去看具体配置 常用的sql写法和优化数据准备 为保证大数据操作执行速度，添加mysql参数配置 1234innodb_flush_log_at_trx_commit=2innodb_buffer_pool_instances=4innodb_buffer_pool_size=2048Minnodb_log_buffer_size=16M 重启服务 12[root@localhost mysql]# service mysqld restart;Redirecting to /bin/systemctl restart mysqld.service 插入数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051create database db5;use db5;/* 用户表 */drop table if exists users;create table users( id int primary key auto_increment, name varchar(20));insert into users(name) values ('A');insert into users(name) values ('B');insert into users(name) values ('C');insert into users(name) values ('D');insert into users(name) values ('E');insert into users(name) values ('F');insert into users(name) values ('G');insert into users(name) values ('H');insert into users(name) values ('I');insert into users(name) values ('J');/* 订单表 */drop table if exists orders;create table orders( id int primary key auto_increment,/*订单id*/ order_no varchar(20) not null,/*订单编号*/ title varchar(20) not null,/*订单标题*/ goods_num int not null,/*商品数量*/ money decimal(7,4) not null,/*订单金额*/ user_id int not null /*订单所属用户id*/)engine=innodb default charset=utf8 ;delimiter $$drop procedure if exists batch_orders $$create procedure batch_orders(in max int)begindeclare start int default 0;declare i int default 0;set autocommit = 0; while i &lt; max do set i = i + 1; insert into orders(order_no,title,goods_num,money,user_id) values (concat('NCS-',floor(1 + rand()*1000000000004 )),concat('订单title-',i),i%50,(100.0000+(i%50)),i%10); end while;commit;end $$delimiter ;/* 3百万数据*/call batch_orders(3000000); Max()在money上面加索引解决性能问题 12345678910111213141516171819mysql&gt; create index idx_money on orders(money);Query OK, 0 rows affected (16.46 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; explain select max(money) from orders\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: NULL partitions: NULL type: NULLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: NULL filtered: NULL Extra: Select tables optimized away1 row in set, 1 warning (0.00 sec) “Select tables optimized away”，介是啥意思呢，官方解释： For explains on simple count queries (i.e. explain select count(*) from people) the extra section will read “Select tables optimized away.” This is due to the fact that MySQL can read the result directly from the table internals and therefore does not need to perform the select. 意思就是记录已经保存了，不需要查询物理表或者索引，直接返回结果。 count()需求：分别查询出A用户和B用户各自的订单总数A B3 20 12345678910111213141516171819mysql&gt; create index idx_user_id on orders(user_id);Query OK, 0 rows affected (19.25 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; explain select count(case when user_id=1 then id end),count(case when user_id=2 then id end ) from orders\G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: orders partitions: NULL type: indexpossible_keys: NULL key: idx_user_id key_len: 4 ref: NULL rows: 2987346 filtered: 100.00 Extra: Using index1 row in set, 1 warning (0.00 sec) limitlimit limit ?,? limit 555,5 limit 55555555,5 从rows可以看出来，limit的开始位置越大，必须检索的行就越多，就会对性能产生影响而且如果太大了，会产生using filesort 可以设置下面的参数来解决：12分配的排序的空间大小max_length_for_sort_data 默认为1024字节如果排序的字段的空间大于这个设置的值，就不会使用索引排序，而会使用using filesort可以设置大点，这样就不会产生文件内排序 行列转换行转列：name total_goods_numA 100B 20把上面的结果转换成下面的结果：A B100 20 SQL如下：1234567891011select sum(case when u.id=1 then goods_num end) as 'A',sum(case when u.id=2 then goods_num end) as 'B',sum(case when u.id=3 then goods_num end) as 'C',sum(case when u.id=4 then goods_num end) as 'D',sum(case when u.id=5 then goods_num end) as 'E',sum(case when u.id=6 then goods_num end) as 'F',sum(case when u.id=7 then goods_num end) as 'G',sum(case when u.id=8 then goods_num end) as 'H',sum(case when u.id=9 then goods_num end) as 'I',sum(case when u.id=10 then goods_num end) as 'J'from users u inner join orders o on u.id=o.user_id;]]></content>
      <categories>
        <category>MySQL优化</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FirewalldAndTelnet]]></title>
    <url>%2F2017%2F09%2F07%2FFirewalldAndTelnet%2F</url>
    <content type="text"><![CDATA[操作MySQL主从复制时候需要设定防火墙规则，决定还是总结记录一下。操作系统CentOs7 firewalld防火墙firewalld是centos7的一大特性，最大的好处有两个：支持动态更新，不用重启服务；第二个就是加入了防火墙的“zone”概念 firewalld的字符界面管理工具是 firewall-cmd firewalld默认配置文件有两个：/usr/lib/firewalld/ （系统配置）和 /etc/firewalld/ （用户配置） zone概念硬件防火墙默认一般有三个区，firewalld引入这一概念系统默认存在以下区域： drop：任何流入网络的包都被丢弃，不作出任何响应。只允许流出的网络连接。block：任何进入的网络连接都被拒绝，并返回 IPv4 的 icmp-host-prohibited 报文或者 IPv6 的 icmp6-adm-prohibited 报文。只允许由该系统初始化的网络连接。public：用以可以公开的部分。你认为网络中其他的计算机不可信并且可能伤害你的计算机。只允许选中的连接接入。external：用在路由器等启用伪装的外部网络。你认为网络中其他的计算机不可信并且可能伤害你的计算机。只允许选中的连接接入。dmz：用以允许隔离区（dmz）中的电脑有限地被外界网络访问。只接受被选中的连接。work：用在工作网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。home：用在家庭网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。internal：用在内部网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。 安装、运行、停止、禁用、重启firewalld 安装 1yum -y install firewalld firewall-config 启动 1systemctl start firewalld 查看状态 1systemctl status firewalld 或者 firewall-cmd --state 停止 1systemctl disable firewalld 禁用 1systemctl stop firewalld 更新防火墙规则(不会重启服务) 1firewall-cmd --reload 更新防火墙规则（会重启服务） 1firewall-cmd --complete-reload 配置firewalld 查看版本 1firewall-cmd --version 查看帮助 1firewall-cmd --help 查看区域信息 1firewall-cmd --get-active-zones 查询默认区域 1firewall-cmd --get-default-zone 设置默认区域 1firewall-cmd --set-default-zone=public 查看所有打开的端口 1firewall-cmd --zone=dmz --list-ports 查询端口是否启用 1firewall-cmd [--zone=&lt;zone&gt;] --query-port=&lt;port&gt;[-&lt;port&gt;]/&lt;protocol&gt; 添加指定端口 12firewall-cmd --zone=&lt;zone&gt; --add-port=&lt;port&gt;[-&lt;port&gt;]/&lt;protocol&gt; [--timeout=&lt;seconds&gt;]# 要使定义的协议永久生效，需要加一句--permanent，--zone不写则使用默认区域 移除允许的端口： 1firewall-cmd [--zone=&lt;zone&gt;] --remove-port=&lt;port&gt;[-&lt;port&gt;]/&lt;protocol&gt; 参考资料 官方文档 wiki 安装telnet 先检查CentOS7.0是否已经安装以下两个安装包:telnet-server、xinetd。 12[root@localhost sysconfig]# rpm -qa telnet-server[root@localhost sysconfig]# rpm -qa xinetd 如果没有安装，则先安装。安装命令 1234567891011121314151617[root@localhost ~]# yum list | grep telnettelnet.x86_64 1:0.17-60.el7 base telnet-server.x86_64 1:0.17-60.el7 base [root@localhost ~]# yum -y install telnet-server.x86_64[root@localhost ~]# yum -y install telnet.x86_64[root@localhost ~]# yum list |grep xinetdxinetd.x86_64 2:2.3.15-13.el7 base [root@localhost ~]# yum -y install xinetd.x86_64``` 1. 安装完成后，将xinetd服务加入开机自启动```bash[root@localhost ~]# systemctl enable xinetd.service 最后，启动以上两个服务即可： 12[root@localhost ~]# systemctl start telnet.socket[root@localhost ~]# systemctl start xinetd 将telnet服务加入开机自启动 12[root@localhost ~]# systemctl enable telnet.socketCreated symlink from /etc/systemd/system/sockets.target.wants/telnet.socket to /usr/lib/systemd/system/telnet.socket. 使用的时候，用telnet测试下端口是否可以访问 1234567891011121314151617181920[root@localhost ~]# ping 192.168.25.143PING 192.168.25.143 (192.168.25.143) 56(84) bytes of data.64 bytes from 192.168.25.143: icmp_seq=1 ttl=64 time=0.529 ms64 bytes from 192.168.25.143: icmp_seq=2 ttl=64 time=0.473 ms64 bytes from 192.168.25.143: icmp_seq=3 ttl=64 time=0.473 ms64 bytes from 192.168.25.143: icmp_seq=4 ttl=64 time=0.496 ms^C--- 192.168.25.143 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3001msrtt min/avg/max/mdev = 0.473/0.492/0.529/0.035 ms# 网络连接成功，下面测试端口[root@localhost ~]# telnet 192.168.25.143 3306Trying 192.168.25.143...Connected to 192.168.25.143.Escape character is '^]'.N5.7.14-log gBI8)"ÿ󿾂uc49BQ,emysql_native_password123456!#08S01Got packets out of orderConnection closed by foreign host.]]></content>
      <categories>
        <category>Linux设置</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化（一）--- MySQL主从复制]]></title>
    <url>%2F2017%2F08%2F30%2FMySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[MySQL Replication是MySQL官方提供的主从同步方案，用于将一个MySQL实例的数据，同步到另一个实例中。Replication为保证数据安全做了重要保证，也是现在运用最广的MySQL容灾方案。Replication用两个或以上的实例搭建MySQL主从复制集群，提供单点写入，多点读取的服务，实现了读的scale out。 主从复制的原理MySQL内建的复制功能是构建大型，高性能应用程序的基础。将MySQL的数据分布到多个系统上去，这种分布的机制，是通过将MySQL的某一台主机的数据复制到其它主机（slaves）上，并重新执行一遍来实现的。复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。主服务器将更新写入二进制日志文件，并维护文件的一个索引以跟踪日志循环。这些日志可以记录发送到从服务器的更新。当一个从服务器连接主服务器时，它通知主服务器从服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，然后封锁并等待主服务器通知新的更新。 MySQL主从复制相关有3个线程 slave上的I/O线程：向master请求数据 master上的Binlog Dump线程：读取binlog事件并把数据发送给slave上的I/O线程 slave上的SQL线程：读取中继日志并执行，更新数据库 下图描述了复制的过程： 从上图分析的主从复制的3个步骤： master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）。 在每个事务更新数据完成之前，master在二日志记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。 slave将master的binary log events拷贝到它的中继日志(relay log)。 首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，然后开始binlog dump process。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。 slave重做中继日志中的事件，将改变反映它自己的数据。该过程的第一部分就是master记录二进制日志。 SQL slave thread（SQL从线程）处理该过程的最后一步。SQL线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致。只要该线程与I/O线程保持一致，中继日志通常会位于OS的缓存中，所以中继日志的开销很小。 复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。 主从复制的配置 准备环境有两台MySQL数据库服务器master和slave，master为主服务器，slave为从服务器，初始状态时，通过MySQL备份机制令master和slave中的数据信息相同，当Master中的数据发生变化时，slave也跟着发生相应的变化，使得master和slave的数据信息同步，达到备份的目的。要点：负责在主、从服务器传输各种修改动作的媒介是主服务器的二进制变更日志，这个日志记载着需要传输给从服务器的各种修改动作。因此，主服务器必须激活二进制日志功能。从服务器必须具备足以让它连接主服务器并请求主服务器把二进制变更日志传输给它的权限。 环境：master和slave的MySQL数据库版本同为5.7.14操作系统：CentOs 3.10.0-514.el7.x86_64IP地址：master=’192.168.25.143’,slave=’192.168.25.138’ 首先保证两台机器网络上互通然后对端口进行防火墙设置。（防火墙设置及Telnet安装） 123456789101112131415161718192021# 开启端口[root@localhost ~]# firewall-cmd --zone=public --add-port=3306/tcp --permanentsuccess# 不需重启服务重新加载防火墙规则[root@localhost ~]# firewall-cmd --reloadsuccess# 查询端口是否启用：[root@localhost ~]# firewall-cmd --zone=public --query-port=3306/tcpyes# 使用telnet测试端口链接[root@localhost ~]# telnet 192.168.25.143 3306Trying 192.168.25.143...Connected to 192.168.25.143.Escape character is '^]'.N5.7.14-log gBI8)"ÿ󿾂uc49BQ,emysql_native_password123456!#08S01Got packets out of orderConnection closed by foreign host. 真实场景肯定是已经有很多历史数据在老数据库中，而且服务器正在运行并对外提供服务，我们模拟下这个环境。在master机数据库上创建库表。 123456789101112mysql&gt; create database db1;Query OK, 1 row affected (0.00 sec)mysql&gt; use db1;Database changedmysql&gt; create table t1(id int);Query OK, 0 rows affected (0.01 sec)mysql&gt; insert into t1 values(1),(2),(3);Query OK, 3 rows affected (0.00 sec)Records: 3 Duplicates: 0 Warnings: 0 配置master先要复制master上已有的数据到slave上，而且master服务不能停，这就需要基于二进制日志来操作。在master上开启二进制日志。包括打开二进制日志，指定唯一的servr-id。 修改my.cnf,添加如下配置（设置服务id，开启二进制日志） 12server-id=1log-bin=/var/lib/mysql/mysql-bin 重启服务 12[root@localhost ~]# service mysqld restart;Redirecting to /bin/systemctl restart mysqld.service 查看master二进制日志状态 12345678mysql&gt; show master status;+------------------+----------+--------------+--------------- ---+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+--------------- ---+-------------------+| mysql-bin.000001 | 154 | | | |+------------------+----------+--------------+--------------- ---+-------------------+1 row in set (0.00 sec)# 注意，position位置就是二进制日志复制的起点。 在/var/lib/mysql文件夹下生成如下二进制日志文件 1-rw-r-----. 1 mysql mysql 154 8月 30 22:07 mysql-bin.000001 查看二进制文件的内容 1[root@localhost mysql]# mysqlbinlog --no-defaults mysql-bin.000001 如果想要清空master二进制日志 1reset master; 拷贝数据关停master服务器，将master中的数据拷贝到slave服务器中，使得master和slave中的数据同步。 备份 1[root@localhost charsets]# mysqldump -uroot -p --single-transaction --master-data=2 --triggers --routines --all-databases &gt; ~/abc.sql 生成备份文件如下 1-rw-r--r--. 1 root root 767934 8月 30 23:01 abc.sql 查看此文件，注意看MASTER_LOG_POS 12-- CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000004', MASTER_LOG_POS=154;# 它标记了从154位置之前的数据已经备份到abc.sql中，以后的数据要从154开始，我们会在slave里用到。 在slave上操作，把abc.sql从master远程拷贝到salve 123456789[root@localhost ~]# scp root@192.168.25.143:/root/abc.sql ~The authenticity of host '192.168.25.143 (192.168.25.143)' can't be established.ECDSA key fingerprint is 1f:eb:16:4e:2e:34:e1:7f:79:a4:b2:e7:51:b7:83:9d.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '192.168.25.143' (ECDSA) to the list of known hosts.root@192.168.25.143's password: Permission denied, please try again.root@192.168.25.143's password: abc.sql 100% 750KB 749.9KB/s 00:00 在slave上执行abc.sql（重定向） 12[root@localhost ~]# mysql -uroot -p &lt; ~/abc.sqlEnter password: 查看slave数据库，发现导入成功 1234567891011mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || db1 || mysql || performance_schema || sys |+--------------------+5 rows in set (0.00 sec) 这时备份时点的数据已经拷贝到从服务器上了 创建复制帐号在master的数据库中建立一个备份帐户：每个slave使用标准的MySQL用户名和密码连接master。进行复制操作的用户会授予REPLICATION SLAVE权限。用户名的密码都会存储在文本文件master.info中。 创建授权用户 123456789? grant# 上面是查看授权语法mysql&gt; grant replication slave on *.* to 'slave'@'192.168.25.138' identified by 'Gengsc_123';Query OK, 0 rows affected, 1 warning (0.00 sec)# 注意上面的密码因为密码策略的原因要大小写字母特殊符号数字同时具备（我记得是这样）mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 查看是否成功 12345mysql&gt; select * from mysql.user where host = '192.168.25.138'\G;*************************** 1. row *************************** Host: 192.168.25.138 User: slave Repl_slave_priv: Y 执行完授权后，我们来查看下master状态 12345678mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000005 Position: 154 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec) 配置slave配置在下面，其中，server_id：是必须的，而且唯一。slave：没有必要开启二进制日志，但是在一些情况下，必须设置，例如，如果slave为其他slave的master，必须设置log-bin。在这里，我们开启二进制日志。relay_log：配置中继日志。log_slave_updates：表示slave将复制事件写进自己的二进制日志。有些人开启了slave的二进制日志，却没有设置log_slave_updates，这是一种错误的配置。原因：从库开启log-bin参数，如果直接往从库写数据，是可以记录log-bin日志的，但是从库通过I0线程读取主库二进制日志文件，然后通过SQL线程写入的数据，是不会记录binlog日志的。也就是说从库从主库上复制的数据，是不写入从库的binlog日志的。所以从库做为其他从库的主库时需要在配置文件中添加log-slave-updates参数。 编辑my.cnf 1234server-id=2log-bin=/var/lib/mysql/mysql-binrelay_log=/var/lib/mysql/mysql-relay-binlog_slave_updates=1 重启MySQL服务 12[root@localhost ~]# service mysqld restart;Redirecting to /bin/systemctl restart mysqld.service 启动slave接下来就是让slave连接master，并开始重做master二进制日志中的事件。使用CHANGE MASTER TO语句不需要停止服务器。如下： 如果之前这台slave已经做过从机，先停止主从复制 1stop slave; 如果之前这台slave已经做过从机，先清空之前的relay-log 1reset slave; 为slave指定master 123456789mysql&gt; change master to master_host='192.168.25.143',-&gt; master_user='slave',-&gt; master_password='Gengsc_123',-&gt; master_log_file='mysql-bin.000004',-&gt; master_log_pos=154;Query OK, 0 rows affected, 2 warnings (0.03 sec)# 具体命令参数可以通过下面的命令查看(里面有例子)? change master to 启动Slave开始复制 12mysql&gt; start slave;Query OK, 0 rows affected (0.01 sec) 检查主从同步状态，主要查看io线程和sql线程状态(Slave_IO_Running和Slave_SQL_Running) 123456789101112131415mysql&gt; show slave status\G*************************** 1. row ***************************Slave_IO_State: Waiting for master to send eventMaster_Host: 192.168.25.143Master_User: slaveMaster_Port: 3306Connect_Retry: 60Master_Log_File: mysql-bin.000004Read_Master_Log_Pos: 2167Relay_Log_File: localhost-relay-bin.000002Relay_Log_Pos: 2333Relay_Master_Log_File: mysql-bin.000004Slave_IO_Running: YesSlave_SQL_Running: YesReplicate_Do_DB: 常见错误：Slave_IO_Running=NO：检查change master语句中ip log_file log_pos等所有参数Slave_SQL_Running=NO：因为主从同步需要创建用户，查看当前登录用户是否有此权限。可以查看show slave status查看错误日志，一般都是表不存在就操作DML啥的。 查看线程你可已查看master和slave上的线程状态 在master上，你可以看见slave的io线程创建的链接（dump线程） 12345678910mysql&gt; show processlist\G;*************************** 1. row *************************** Id: 4 User: slave Host: 192.168.25.138:53396 db: NULLCommand: Binlog Dump Time: 172 State: Master has sent all binlog to slave; waiting for more updates Info: NULL 在slave上，你可以看到io线程状态和sql线程状态 12345678910111213141516171819mysql&gt; show processlist\G;*************************** 1. row *************************** Id: 4 User: system user Host: db: NULLCommand: Connect Time: 599068 State: Waiting for master to send event Info: NULL*************************** 2. row *************************** Id: 5 User: system user Host: db: NULLCommand: Connect Time: 598967 State: Slave has read all relay log; waiting for more updates Info: NULL 验证主从同步 在master中操作 123456789101112mysql&gt; create database db2;Query OK, 1 row affected (0.01 sec)mysql&gt; use db2;Database changedmysql&gt; create table user(id int,name varchar(20));Query OK, 0 rows affected (0.03 sec)mysql&gt; insert into user values (1,'张三'),(2,'李四');Query OK, 2 rows affected (0.09 sec)Records: 2 Duplicates: 0 Warnings: 0 在slave中查看 1234567891011121314151617181920212223242526mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || db1 || db2 || mysql || performance_schema || sys |+--------------------+6 rows in set (0.00 sec)mysql&gt; use db2;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select * from user;+------+--------+| id | name |+------+--------+| 1 | 张三 || 2 | 李四 |+------+--------+2 rows in set (0.00 sec) 查看二进制日志变化 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 开始状态，此时位置是2509mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000005 Position: 2509 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec)# 执行dml sqlmysql&gt; update user set name = '王舞' where id = 3;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0# 再次查看master状态，position变了mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000005 Position: 2785 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec)# 查看bin-log日志增量[root@localhost mysql]# mysqlbinlog --no-defaults --start-position=2509 --stop-position=2789 --base64-output=decode-rows -v mysql-bin.000005BEGIN/*!*/;# at 2645#170908 11:50:13 server id 1 end_log_pos 2694 CRC32 0xfacee981 Table_map: `db2`.`user` mapped to number 114# at 2694#170908 11:50:13 server id 1 end_log_pos 2754 CRC32 0x9d44a8e3 Update_rows: table id 114 flags: STMT_END_F### UPDATE `db2`.`user`### WHERE### @1=3### @2='王五'### SET### @1=3### @2='王舞'# at 2754#170908 11:50:13 server id 1 end_log_pos 2785 CRC32 0xd7a8cc0a Xid = 707COMMIT/*!*/; 大功告成。 一致性问题数据同步其实可以使用冷备份的方案，但冷备存在以下问题： 1. 冷备时要停止mysql服务 2. 冷备都是基于某一确定的时间点，如果备份之后的一段时间，数据遭到破坏，那么这段时间的数据将无法恢复。 但是主从复制就能保证数据一致性吗，使用复制技术实现读写分离，主库插入以后，马上去从库中读数据，主从同步延时的原因可能得到不一致的结果。 产生延迟的几个因素： 1. 网络状态 2. 大并发写操作特别多。 3. 读服务器压力过大 为解决一致性问题，看这里吧戳我，人家写的挺好，懒的写了。 binlog内容解析开这章的意义本来在于向看懂binlog中的内容，但是但是感觉知识好多啊 复制的类型首先，还是先看下mysql支持哪几种复制方式吧 Statement-Based Replication在主服务器上执行的SQL语句，在从服务器上执行同样的语句。MySQL默认采用Statement-Based复制，效率比较高。一旦发现没法精确复制时， 会自动选着Row-Based复制。 MySQL 5.0及之前的版本仅支持基于语句的复制，这在数据库并不常见。master记录下改变数据的查询，然后，slave从中继日志中读取事件，并执行它，这些SQL语句与master执行的语句一样。 这种方式的优点就是实现简单。此外，基于语句的复制的二进制日志可以很好的进行压缩，而且日志的数据量也较小，占用带宽少——例如，一个更新GB的数据的查询仅需要几十个字节的二进制日志。而mysqlbinlog对于基于语句的日志处理十分方便。 但是，基于语句的复制并不是像它看起来那么简单，因为一些查询语句依赖于master的特定条件，例如，master与slave可能有不同的时间。所以，MySQL的二进制日志的格式不仅仅是查询语句，还包括一些元数据信息，例如，当前的时间戳。即使如此，还是有一些语句，比如，CURRENT USER函数，不能正确的进行复制。此外，存储过程和触发器也是一个问题。 另外一个问题就是基于语句的复制必须是串行化的。这要求大量特殊的代码，配置，例如InnoDB的next-key锁等。并不是所有的存储引擎都支持基于语句的复制。 Row-Based Replication把改变的内容复制过去，而不是把命令在从服务器上执行一遍，从mysql5.0开始支持 MySQL增加基于记录的复制，在二进制日志中记录下实际数据的改变，这与其它一些DBMS的实现方式类似。这种方式有优点，也有缺点。优点就是可以对任何语句都能正确工作，一些语句的效率更高。主要的缺点就是二进制日志可能会很大，而且不直观，所以，你不能使用mysqlbinlog来查看二进制日志。 对于一些语句，基于记录的复制能够更有效的工作，如：1234mysql&gt; INSERT INTO summary_table(col1, col2, sum_col3) -&gt; SELECT col1, col2, sum(col3) -&gt; FROM enormous_table -&gt; GROUP BY col1, col2; 假设，只有三种唯一的col1和col2的组合，但是，该查询会扫描原表的许多行，却仅返回三条记录。此时，基于记录的复制效率更高。 另一方面，下面的语句，基于语句的复制更有效：1mysql&gt; UPDATE enormous_table SET col1 = 0; 此时使用基于记录的复制代价会非常高。 Mixed-Based Replication默认采用Statement-Based复制，一旦发现基于语句的无法精确的复制时，就会采用Row-Based复制。 由于两种方式不能对所有情况都能很好的处理，所以，MySQL 5.1支持在基于语句的复制和基于记录的复制之前动态交换。你可以通过设置session变量binlog_format来进行控制。 Binary Logging Formats这一节，我们尝试查看bin-log的内容，解读bin-log中的重要信息 binlog_format=statement环境准备1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465mysql&gt; set binlog_format = 'statement';Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like 'binlog_format'\G;*************************** 1. row ***************************Variable_name: binlog_format Value: STATEMENT1 row in set (0.01 sec)# 关闭当前的二进制日志文件并创建一个新文件，新的二进制日志文件的名字在当前的二进制文件的编号上加1mysql&gt; flush logs;Query OK, 0 rows affected (0.02 sec)mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000007 Position: 154 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec)# 此时记录下log_file=mysql-bin.000007,log_pos=154mysql&gt; create table t1 ( -&gt; id int auto_increment primary key, -&gt; name varchar(20) not null, -&gt; uuids varchar(45) not null -&gt; ) engine = InnoDB;Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into t1(name,uuids) values('tom',uuid());Query OK, 1 row affected, 1 warning (0.01 sec)# 发现有一个警告# 查看警告mysql&gt; show warnings\G;*************************** 1. row *************************** Level: Note Code: 1592Message: Unsafe statement written to the binary log using statement format since BINLOG_FORMAT = STATEMENT. Statement is unsafe because it uses a system function that may return a different value on the slave.1 row in set (0.00 sec)# 提示statement方式使用uuid()可能会导致从库数据与主库数据不一样mysql&gt; update t1 set name = 'jerry' where id = 1;Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; insert into t1(name,uuids) values('jack',uuid());Query OK, 1 row affected, 1 warning (0.01 sec)mysql&gt; delete from t1 where id = 2;Query OK, 1 row affected (0.01 sec)mysql&gt; drop table t1;Query OK, 0 rows affected (0.02 sec)mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000007 Position: 1539 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec)# 此时记录下log_file=mysql-bin.000007,log_pos=1539 分析日志内容DDL跟DML操作执行后，得到当前的binlog文件是mysql-bin.000007，开始的position是154 ，结束的position是1539，所以直接读取整个文件从position=154到1539之间的操作记录，使用mysqlbinlog读取。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118[root@localhost mysql]# mysqlbinlog --no-defaults --start-position=154 --stop-position=1539 mysql-bin.000007# at 154#170908 15:30:24 server id 1 end_log_pos 219 CRC32 0x3a8142fc Anonymous_GTID last_committed=0 sequence_number=1SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 219#170908 15:30:24 server id 1 end_log_pos 296 CRC32 0x501abf9e Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855824/*!*/;SET @@session.pseudo_thread_id=24/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1436549152/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\C utf8 *//*!*/;SET @@session.character_set_client=192,@@session.collation_connection=192,@@session.collation_server=192/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 296--------------------------------------------------------------# at 328#170908 15:30:24 server id 1 end_log_pos 328 CRC32 0xcc1e8509 IntvarSET INSERT_ID=1/*!*/;#170908 15:30:24 server id 1 end_log_pos 447 CRC32 0x58f1bfa0 Query thread_id=24 exec_time=0 error_code=0use `db2`/*!*/;SET TIMESTAMP=1504855824/*!*/;insert into t1(name,uuids) values('tom',uuid())/*!*/;# at 447#170908 15:30:24 server id 1 end_log_pos 478 CRC32 0x37e68e4b Xid = 731COMMIT/*!*/;--------------------------------------------------------------# at 478#170908 15:31:32 server id 1 end_log_pos 543 CRC32 0x0e416741 Anonymous_GTID last_committed=1 sequence_number=2SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 543#170908 15:31:32 server id 1 end_log_pos 620 CRC32 0x58bc6f80 Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855892/*!*/;BEGIN/*!*/;# at 620#170908 15:31:32 server id 1 end_log_pos 733 CRC32 0x2dd8d9a4 Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855892/*!*/;update t1 set name = 'jerry' where id = 1/*!*/;# at 733#170908 15:31:32 server id 1 end_log_pos 764 CRC32 0xa3ab9727 Xid = 733COMMIT/*!*/;--------------------------------------------------------------# at 764#170908 15:32:46 server id 1 end_log_pos 829 CRC32 0xa0d31904 Anonymous_GTID last_committed=2 sequence_number=3SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 829#170908 15:32:46 server id 1 end_log_pos 906 CRC32 0xfa941cd4 Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855966/*!*/;BEGIN/*!*/;# at 906# at 938#170908 15:32:46 server id 1 end_log_pos 938 CRC32 0xd52d2aa8 IntvarSET INSERT_ID=2/*!*/;#170908 15:32:46 server id 1 end_log_pos 1058 CRC32 0x64a1e64e Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855966/*!*/;insert into t1(name,uuids) values('jack',uuid())/*!*/;# at 1058#170908 15:32:46 server id 1 end_log_pos 1089 CRC32 0xa1d6ce2d Xid = 736COMMIT/*!*/;--------------------------------------------------------------# at 1089#170908 15:33:03 server id 1 end_log_pos 1154 CRC32 0x5d070075 Anonymous_GTID last_committed=3 sequence_number=4SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 1154#170908 15:33:03 server id 1 end_log_pos 1231 CRC32 0x7778ba6a Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855983/*!*/;BEGIN/*!*/;# at 1231#170908 15:33:03 server id 1 end_log_pos 1330 CRC32 0xd2a967f2 Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504855983/*!*/;delete from t1 where id = 2/*!*/;# at 1330#170908 15:33:03 server id 1 end_log_pos 1361 CRC32 0x5a49cde4 Xid = 737COMMIT/*!*/;-----------------------------------------------------------# at 1361#170908 15:33:21 server id 1 end_log_pos 1426 CRC32 0xf7074dba Anonymous_GTID last_committed=4 sequence_number=5SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 1426#170908 15:33:21 server id 1 end_log_pos 1539 CRC32 0xbe802308 Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504856001/*!*/;DROP TABLE `t1` /* generated by server *//*!*/;SET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 是不是好多，看的眼晕。但是我相信耐心的你一定可以看明白的，我已经把每个事物中间用间隔线分开处理。比如第一个事物insert（你可能奇怪，第一个为什么不是create呢，哈哈，我是创建表之后执行的flush logs，所以并未把create语句记录到当前的bin-log，应该在上一个编码的bin-log中）是用明文记录在bin-log中的。 结论当binlog_format=statement的时候，DDL及DML都是明文按照SQL记录存储对复制的影响。 某系统参数由于在不同时间不同服务器，执行结果不一致，这会给复制的主从带来数据不一致的严重影响。如LOAD_FILE()，UUID()，USER()，FOUND_ROWS()，defaults，now()及用户自定义函数等。 同步到从库的binlog都是SQL语句，在slave端再跑一遍，假设一个update语句性能很差，但是最终只修改了一行数据，那么在从库也会同样执行这个性能差的SQL，而对于 insert tb select * from tbname 这类型的SQL，则只需要同步一行SQL语句即可。 binlog_format=row环境准备123456789101112131415161718192021222324252627282930313233343536373839mysql&gt; set binlog_format = 'row';Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like '%binlog_format%'\G;*************************** 1. row ***************************Variable_name: binlog_format Value: ROW1 row in set (0.01 sec)mysql&gt; flush logs;Query OK, 0 rows affected (0.02 sec)mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000008 Position: 154 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec)mysql&gt; create table t2 ( -&gt; id int auto_increment primary key, -&gt; name varchar(20) not null, -&gt; uuids varchar(45) not null -&gt; ) engine = InnoDB;Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into t2(name,uuids) values ('jack',uuid());Query OK, 1 row affected (0.01 sec)mysql&gt; show master status\G;*************************** 1. row *************************** File: mysql-bin.000008 Position: 714 Binlog_Do_DB: Binlog_Ignore_DB: Executed_Gtid_Set: 1 row in set (0.00 sec) 分析日志1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071[root@localhost mysql]# mysqlbinlog --no-defaults --start-position=154 --stop-position=714 mysql-bin.000008/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#170908 16:20:01 server id 1 end_log_pos 123 CRC32 0x6f2a48ed Start: binlog v 4, server v 5.7.14-log created 170908 16:20:01# Warning: this binlog is either in use or was not closed properly.BINLOG 'sVKyWQ8BAAAAdwAAAHsAAAABAAQANS43LjE0LWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQAAe1IKm8='/*!*/;# at 154#170908 16:20:52 server id 1 end_log_pos 219 CRC32 0x73d82462 Anonymous_GTID last_committed=0 sequence_number=1SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;------------------------------------------------------------# at 219#170908 16:20:52 server id 1 end_log_pos 415 CRC32 0xdb01c4e3 Query thread_id=24 exec_time=0 error_code=0use `db2`/*!*/;SET TIMESTAMP=1504858852/*!*/;SET @@session.pseudo_thread_id=24/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1436549152/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\C utf8 *//*!*/;SET @@session.character_set_client=192,@@session.collation_connection=192,@@session.collation_server=192/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;create table t2 (id int auto_increment primary key,name varchar(20) not null,uuids varchar(45) not null) engine = InnoDB/*!*/;------------------------------------------------------------# at 415#170908 16:21:34 server id 1 end_log_pos 480 CRC32 0x0dff2820 Anonymous_GTID last_committed=1 sequence_number=2SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 480#170908 16:21:34 server id 1 end_log_pos 551 CRC32 0x37c52cbb Query thread_id=24 exec_time=0 error_code=0SET TIMESTAMP=1504858894/*!*/;BEGIN/*!*/;# at 551#170908 16:21:34 server id 1 end_log_pos 601 CRC32 0xecbd95aa Table_map: `db2`.`t2` mapped to number 148# at 601#170908 16:21:34 server id 1 end_log_pos 683 CRC32 0x69b6b96b Write_rows: table id 148 flags: STMT_END_FBINLOG 'DlOyWRMBAAAAMgAAAFkCAAAAAJQAAAAAAAEAA2RiMgACdDIAAwMPDwQ8AIcAAKqVvew=DlOyWR4BAAAAUgAAAKsCAAAAAJQAAAAAAAEAAgAD//gBAAAABGphY2skYmEwYzlmYjctOTQ2ZS0xMWU3LTk5NTQtMDAwYzI5YzM2ODBla7m2aQ=='/*!*/;# at 683#170908 16:21:34 server id 1 end_log_pos 714 CRC32 0xd096ef31 Xid = 747COMMIT/*!*/;--------------------------------------------------------------SET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 解密发现在binlog_format=row的情况下，DDL语句为明文存储，而DML语句都是密文存储，我们利用mysqlbinlog的参数反解来看看 原来是酱紫的 1234BINLOG 'DlOyWRMBAAAAMgAAAFkCAAAAAJQAAAAAAAEAA2RiMgACdDIAAwMPDwQ8AIcAAKqVvew=DlOyWR4BAAAAUgAAAKsCAAAAAJQAAAAAAAEAAgAD//gBAAAABGphY2skYmEwYzlmYjctOTQ2ZS0xMWU3LTk5NTQtMDAwYzI5YzM2ODBla7m2aQ== 反解 1[root@localhost mysql]# mysqlbinlog --no-defaults --start-position=154 --stop-position=714 --base64-output=decode-rows -v mysql-bin.000008 反解之后是酱紫的 12345### INSERT INTO `db2`.`t2`### SET### @1=1### @2='jack'### @3='ba0c9fb7-946e-11e7-9954-000c29c3680e' 结论当binlog_format=row的时候，其他参数默认，DDL明文存储SQL脚本，DML都是加密存储且存储的是每一行的行记录修改情况对复制的影响，它是最安全的同步设置。 同步到从库的binlog都是按行记录修改的SQL，所以假设一个update语句性能很差，但是最终只修改了一行数据，那么在从库不需要执行这个性能差的SQL，只需要直接执行行记录的修改结果即可（注意，使用基于row格式复制的实例，请给所有表格添加主键或者唯一索引，不然每一行记录的修改都需要全表扫，会导致从库性能非常差而且可能延时较长）而对于 update t2 set name = ‘rose’这类型的SQL，statment格式的只需要同步一条sql，但是row的话，则需要同步所有行记录。 binlog_format=mixed理解完statement跟row模式后，mixed混合模式就好理解了。 mixed模式下，大多数情况下，是以statement格式记录binlog日志，当隔离级别为RC模式的时候，则修改为row模式记录。或者语句中使用uuid()或者auto_increment这样的函数的时候，使用row模式记录。 Replication Filters复制过滤可以让你只复制服务器中的一部分数据。有两种复制过滤：在master上过滤二进制日志中的事件；在slave上过滤中继日志中的事件。 my.cnf中配置过滤条件 在master中 12345# 忽略复制的库，也就是不需要复制test库binlog-ignore-db=test# 需要复制的库binlog-do-db=test 在slave中配置 1234replicate-ignore-db=testreplicate-do-db=testreplicate-do-table=t1replicate-ignore-table=t1 注意：一般配置这种过滤规则，在slave中比较合适，因为在master上设置replicate_do_db或replicate_ignore_db时，任何不涉及到数据库相关的写操作都不会被记录到二进制日志当中，那么会造成主服务器上的二进制日志不完整，一旦将来数据库崩溃，不能做及时点还原，所以建议在从服务器上设置，尽管会浪费大量网络IO和磁盘IO。 若只想复制某个库，只需在slave的my.cnf配置文件中[mysqld]段中加一行replicate_do_db = db_name即可。若只想复制某张表，只需在slave的my.cnf配置文件中[mysqld]段中加一行replicate_do_db = tb_name即可。若想使用通配符，则使用replicate_wild_dotable = db[%]，%表示任意长度任意字符，_表示任意单个字符。 在线调整复制的过滤规则在slave中添加过滤规则 停止slave中的SQL_Thread 1stop slave sql_thread; 配置过滤规则 12345678# 过滤多个表，用逗号隔开CHANGE REPLICATION FILTER REPLICATE_DO_DB=(db1,db2);CHANGE REPLICATION FILTER REPLICATE_IGNORE_DB=(db1,db2);CHANGE REPLICATION FILTER REPLICATE_DO_TABLE=(db1.t1);CHANGE REPLICATION FILTER REPLICATE_IGNORE_TABLE=(db2.t2);CHANGE REPLICATION FILTER REPLICATE_WILD_DO_TABLE=('db.t%');CHANGE REPLICATION FILTER REPLICATE_WILD_IGNORE_TABLE=('db%.a%');CHANGE REPLICATION FILTER REPLICATE_REWRITE_DB=((from_db, to_db)); 重启slave中的SQL_Thread 1start slave sql_thread; 清除配置规则 停止slave中的SQL_Thread 1stop slave sql_thread; 配置过滤规则 12change replication filter replicate_ignore_db=();change replication filter replicate_ignore_table=(); 重启slave中的SQL_Thread 1start slave sql_thread; Multi-source ReplicationMySQL 5.7已经开始支持了多源复制，MySQL5.7之前只能实现一主一从、一主多从或者多主多从的复制，如果想实现多主一从的复制，只好使用MariaDB，但是MariaDB又与官方的MySQL版本不兼容的，在MySQL 5.7版本已经可以实现多主一从的复制了。 多源复制应用多源复制说白了就是一个从服务器从多个主服务器中拷贝数据，那它到底啥用呢： 在从服务器进行数据汇总，如果我们的主服务器进行了分库分表的操作，为了实现后期的一些数据统计功能，往往需要把数据汇总在一起再统计。 如果我们想在从服务器时时对主服务器的数据进行备份，在MySQL 5.7之前每一个主服务器都需要一个从服务器，这样很容易造成资源浪费，同时也加大了DBA的维护成本，但MySQL5.7引入多源复制，可以把多个主服务器的数据同步到一个从服务器进行备份。 多源复制搭建环境master和slave的MySQL数据库版本同为5.7.14操作系统：CentOs 3.10.0-514.el7.x86_64IP地址：master-1=’192.168.25.143’master-2=’192.168.25.138’slave=’192.168.25.139’ 具体操作参考前面的吧：环境准备配置master 创建复制账号 在master_1上 12345mysql&gt; grant replication slave on *.* to 'rep_139'@'192.168.25.139' identified by 'Gengsc_123';Query OK, 0 rows affected, 1 warning (0.05 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.02 sec) 在master_2上 12345mysql&gt; grant replication slave on *.* to 'rep_139'@'192.168.25.139' identified by 'Gengsc_123';Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.01 sec) 配置slave 配置二进制日志详细戳我 文件存储改为表存储，修改my.cnf，详细参数 123456master_info_repository=TABLErelay_log_info_repository=TABLE# 别忘了重启加载配置[root@localhost ~]# service mysqld restart;Redirecting to /bin/systemctl restart mysqld.service 可以导入历史数据了，数据备份 启动slave（FOR CHANNEL ‘CHANNEL_NAME’） 在slave中指定master 1234567# master_1，注意后面的"for channel 'master_1'"mysql&gt; change master to master_host='192.168.25.143',master_user='rep_139',master_password='Gengsc_123',master_log_file='mysql-bin.000001',master_log_pos=154 for channel 'master_1';Query OK, 0 rows affected, 2 warnings (0.09 sec)# master_2mysql&gt; change master to master_host='192.168.25.138',master_user='rep_139',master_password='Gengsc_123',master_log_file='mysql-bin.000001',master_log_pos=154 for channel 'master_2';Query OK, 0 rows affected, 2 warnings (0.04 sec) 启动slave 123456# 可以直接start slave开启所有，也可以像下面一样单独启动mysql&gt; start slave for channel 'master_1';Query OK, 0 rows affected (0.38 sec)mysql&gt; start slave for channel 'master_2';Query OK, 0 rows affected (0.02 sec) 查看同步状态 1234567891011121314151617181920212223242526272829# 可以查看所有，也可用for channel 'channel_name'单独查看mysql&gt; show slave status\G;*************************** 2. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.25.143 Master_User: rep_139 Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 154 Relay_Log_File: mysql-relay-bin-master_1.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes*************************** 3. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.25.138 Master_User: rep_139 Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 154 Relay_Log_File: mysql-relay-bin-master_2.000002 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes3 rows in set (0.00 sec) 测试下吧 在master-1上创建db_master_1 12mysql&gt; create database db_master_1;Query OK, 1 row affected (0.01 sec) 在master-2上创建db_master_2 12mysql&gt; create database db_master_2;Query OK, 1 row affected (0.01 sec) 在slave中查看 1234567891011121314151617mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || db1 || db2 || db3 || db_master_1 || db_master_2 || mysql || performance_schema || sys || test || test2 |+--------------------+11 rows in set (0.00 sec) 成了！ 参考官方文档 高性能Mysql主从架构的复制原理及配置详解（博客） 关于binary log那些事——认真码了好长一篇，binary那些事（博客） MySQL主从复制原理及配置实现（博客） MySQL5.7的多源复制（博客）]]></content>
      <categories>
        <category>MySQL优化</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化（一）--- MySQL锁机制]]></title>
    <url>%2F2017%2F08%2F29%2FMySQL%E9%94%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[为了保证数据的一致完整性，任何一个数据库都存在锁定机制。锁定机制的优劣直接响应到一个数据库系统的并发处理能力和性能，所以锁定机制的实现也就成为了各种数据库的核心技术之一。本章将对MySQL中两种使用最为频繁的存储引擎MyISAM和Innodb各自的锁定机制进行较为详细的分析。 理论基础总的来说，划分锁类型要依赖两种标准。按照对数据操作的类型分：读锁，写锁。按照数据操作的粒度：表锁，行锁，页锁（本文不作介绍）。 读锁也称为共享锁。 共享锁的代号是S，是Share的缩写。针对同一资源，多个并发读操作可以并行执行，并且互不影响,不能写。 写锁也称排它锁。排它锁的代号是X，是eXclusive的缩写。当前线程写数据的时候，会阻塞其它线程来读取或者写数据。 表锁就是锁住整个表，主要在myisam表存储引擎中出现，myisam默认表锁。表级别的锁定是MySQL各存储引擎中最大颗粒度的锁定机制。该锁定机制最大的特点是实现逻辑简单，带来的系统负面影响最小。所以获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所以可以很好的避免死锁问题。当然，锁定颗粒度大所带来最大的负面影响就是出现锁定资源争用的概率也会最高，致使并发度较低。 行锁锁定单独的某个表中的某一行记录，主要用于innodb存储引擎，innodb默认行锁。行级锁是目前各大数据库管理软件所实现的锁定颗粒度最小的,所以发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能。 但是由于锁定资源的颗粒度很小，所以每次获取锁和释放锁消耗的资源也更多，带来的消耗自然也就更大了。此外，行级锁定也最容易发生死锁。 实践测试表结构及数据12345678910111213141516171819/* 表锁案例*/create table lock_one( id int primary key auto_increment, col int)engine=myisam;insert into lock_one(col) values (1);insert into lock_one(col) values (2);insert into lock_one(col) values (3);/* 行锁案例*/create table lock_two( id int, col int)engine=innodb;insert into lock_two(id,col) values (1,1);insert into lock_two(id,col) values (2,2);insert into lock_two(id,col) values (3,3); 测试表锁语法： 123456789101112# 手动增加表锁：lock table 表名 [read|write]，表名 [read|write]…# 查看锁状态show open tables; # 解开所有锁unlock tables;# 表锁的一些状态查询：show status like 'table_lock%';说明:Table_locks_immediate：表示可以立即获取锁的查询次数，每获取一次锁就增加Table_locks_waited：锁等待的次数 测试全表读锁 开两个会话session1和session2 在session1中锁定lock_one表 MySQL&gt; lock table lock_one read; Query OK, 0 rows affected (0.00 sec) 在session1中对lock_one执行查询，成功 MySQL&gt; select * from lock_one\G;*************************** 1. row ***************************id: 1col: 1*************************** 2. row ***************************id: 2col: 2*************************** 3. row ***************************id: 3col: 33 rows in set (0.00 sec) 在session1中对lock_one执行修改，报错 MySQL&gt; update lock_one set col = 11 where id = 1;ERROR 1099 (HY000): Table ‘lock_one’ was locked with a READ lock and can’t be updated 在session1中对lock_two执行查询，报错 MySQL&gt; update lock_two set col = 11 where id = 1;ERROR 1100 (HY000): Table ‘lock_two’ was not locked with LOCK TABLES 在session1中对lock_two执行修改，报错 MySQL&gt; update lock_two set col = 11 where id = 1;ERROR 1100 (HY000): Table ‘lock_two’ was not locked with LOCK TABLES 在session2中对lock_one执行查询，成功 MySQL&gt; select * from lock_one\G;*************************** 1. row ***************************id: 1col: 1*************************** 2. row ***************************id: 2col: 2*************************** 3. row ***************************id: 3col: 33 rows in set (0.00 sec) 在session2中对lock_one执行修改，阻塞。 MySQL&gt; update lock_one set col = 22 where id = 2; 在session1中解锁 MySQL&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) session2中阻塞更新操作执行 MySQL&gt; update lock_one set col = 22 where id = 2;Query OK, 1 row affected (17.71 sec)Rows matched: 1 Changed: 1 Warnings: 0 在session2中对lock_two执行查询，成功 MySQL&gt; select * from lock_two\G;*************************** 1. row ***************************id: 1col: 1*************************** 2. row ***************************id: 2col: 2*************************** 3. row ***************************id: 3col: 33 rows in set (0.01 sec) 在session2中对lock_two执行修改，成功 MySQL&gt; update lock_two set col = 2;Query OK, 2 rows affected (0.01 sec)Rows matched: 3 Changed: 2 Warnings: 0 据以上测试，结果如下： session1 session2 发送锁表语句lock table t1 read; 连接 可以查询当前锁定的表t1 可以查询t1 更新t1表，报错 更新t1表，阻塞 查询其他表，报错 可以查询其他表 更新其他表，报错 可以查询其他表 执行unlock tables 执行等待的更新操作 分析：读锁是共享锁。在全表上添加读锁时，本线程被锁定，只能进行被锁定表的读操作。其他线程可以对共享表进行读操作，但是要等待锁释放才能进行写操作。 测试全表写锁 开两个会话session1和session2 在session1中锁定lock_one表 MySQL&gt; lock table lock_one write;Query OK, 0 rows affected (0.00 sec) 在session1中对lock_one执行查询，成功 MySQL&gt; select * from lock_one\G*************************** 1. row ***************************id: 1col: 2*************************** 2. row ***************************id: 2col: 22*************************** 3. row ***************************id: 3col: 23 rows in set (0.00 sec) 在session1中对lock_one执行修改，成功 MySQL&gt; update lock_one set col = 3;Query OK, 3 rows affected (0.00 sec)Rows matched: 3 Changed: 3 Warnings: 0 在session1中对lock_two执行查询，报错 MySQL&gt; select * from lock_two;ERROR 1100 (HY000): Table ‘lock_two’ was not locked with LOCK TABLES 在session1中对lock_two执行修改，报错 MySQL&gt; update lock_two set col = 2;ERROR 1100 (HY000): Table ‘lock_two’ was not locked with LOCK TABLES 在session2中对lock_one执行查询，阻塞 MySQL&gt; select * from lock_one\G; 在session1中执行 MySQL&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) session2中查询执行 MySQL&gt; select * from lock_one\G;*************************** 1. row ***************************id: 1col: 2*************************** 2. row ***************************id: 2col: 2*************************** 3. row ***************************id: 3col: 23 rows in set (0.00 sec) 在session2中对lock_one执行修改，阻塞。 MySQL&gt; update lock_one set col = 22 where id = 2; 在session1中解锁 MySQL&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) session2中阻塞更新操作执行 MySQL&gt; update lock_one set col = 22 where id = 2;Query OK, 1 row affected (17.71 sec)Rows matched: 1 Changed: 1 Warnings: 0 在session2中对lock_two执行查询，成功 MySQL&gt; select * from lock_two\G;*************************** 1. row ***************************id: 1col: 1*************************** 2. row ***************************id: 2col: 2*************************** 3. row ***************************id: 3col: 33 rows in set (0.01 sec) 在session2中对lock_two执行修改，成功 MySQL&gt; update lock_two set col = 2;Query OK, 2 rows affected (0.01 sec)Rows matched: 3 Changed: 2 Warnings: 0 据以上测试，结果如下： session1 session2 发送锁表语句lock table t1 write; 连接 可以查询当前锁定的表t1 查询t1,阻塞 可以更新t1表 更新t1表，阻塞 查询其他表，报错 可以查询其他表 更新其他表，报错 可以查询其他表 执行unlock tables 执行等待的操作 分析：写锁是排他锁。在全表上添加写锁时，本线程被锁定，只能进行被锁定表的读写操作。其他线程等待本线程释放排他锁，才能进行读写操作。 MYISAM存储引擎中锁的特点执行select语句的时候，会自动给涉及的表加上读锁，在执行更新操作时，会自动给表加上写锁。 myisam存储引擎比较适合作为以查询为主的表存储引擎，不适合写为主的表存储引擎，因为加写锁后，是锁住整个表，其他用户线程不能做任何操作，这样会导致大量用户线程堵塞的情况。 测试行锁语法12345678910111213141516171819202122232425262728293031323334# 隔离级别show variables like '%iso%';# 查看自动提交参数show variables like '%autocommit%';# 关闭自动提交set autocommit = 0;# 手动锁一行记录begin; select \* from lock_two where id=2 for update；# 查看行锁的信息show status like '%innodb_row_lock%'\G;输出结果：*************************** 1. row ***************************Variable_name: Innodb_row_lock_current_waits Value: 0*************************** 2. row ***************************Variable_name: Innodb_row_lock_time Value: 147166*************************** 3. row ***************************Variable_name: Innodb_row_lock_time_avg Value: 21023*************************** 4. row ***************************Variable_name: Innodb_row_lock_time_max Value: 51044*************************** 5. row ***************************Variable_name: Innodb_row_lock_waits Value: 75 rows in set (0.00 sec)说明：Innodb_row_lock_current_waits ：当前正在等待的数量Innodb_row_lock_time: 从启动到现在锁定的总时长，单位是msInnodb_row_lock_time_avg :锁等待的平均时长Innodb_row_lock_time_max：等待锁时间最长的一个时间Innodb_row_lock_waits：总共的等待次数 开始测试 开启两个会话session1、session2 在两个会话中设置自动提交为手动提交 MySQL&gt; set autocommit=0;Query OK, 0 rows affected (0.00 sec) 在session1中执行update，没有提交事物 MySQL&gt; update lock_two set col = 2 where id = 2;Query OK, 0 rows affected (0.00 sec)Rows matched: 1 Changed: 0 Warnings: 0 在session2中update同一行记录，发生阻塞 MySQL&gt; update lock_two set col = 2 where id = 2; 提交session1和session2中的事物 MySQL&gt; commit; Query OK, 0 rows affected (0.00 sec) 分析：InnoDB自动加行级锁，修改时改行记录已被锁定，其他会话不能修改。 在session1中执行update,没有提交事物 MySQL&gt; MySQL&gt; update lock_two set col = 3 where id = 3;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0 在session2中执行update，操作非同行记录，发生阻塞 MySQL&gt; update lock_two set col = 22 where id = 2; 提交session1和session2中的事物 MySQL&gt; commit;Query OK, 0 rows affected (0.00 sec) 为嘛啊，为嘛啊，说好的行锁呢。分析：实际上，因为MySQL不确定哪行记录被修改，会在全表的范围上加上读锁，然后其他会话就不能更新该表记录。 在lock_two上建立索引 MySQL&gt; create index idx_id on lock_two(id);Query OK, 0 rows affected (0.03 sec)Records: 0 Duplicates: 0 Warnings: 0 执行第4步的操作： 在session1中执行update,没有提交事物 MySQL&gt;update lock_two set col = 3 where id = 3;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0 在session2中执行update，操作非同行记录，操作成功 MySQL&gt; MySQL&gt; update lock_two set col = 22 where id = 2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0 提交session1和session2中的事物 MySQL&gt; commit;Query OK, 0 rows affected (0.00 sec) 为嘛啊，为嘛啊，又和说好的不一样。分析：大概，也许，因为MySQL能通过索引快速的锁定被修改的行，所以只会在被操作范围的记录上加上行锁，然后其他会话就能更新非此范围记录。 间隙锁 在session1中修改范围记录，不提交 MySQL&gt; update lock_two set col = 1 where id &gt; 2 and id &lt; 8;Query OK, 2 rows affected (0.00 sec)Rows matched: 2 Changed: 2 Warnings: 0 在session2中插入id在session1修改where范围的记录，发生阻塞 MySQL&gt; insert into lock_two values(4,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction 分析：在范围查找的情况下，innodb会给范围条件中的数据加上锁，无论数据是否是否真实存在。建议：在innodb中，因为有间隙锁的存在，最好在where中少使用这种范围查找 测试结果结论：如果没有用上索引，行锁变成表锁原因：在不使用索引的情况下，更新表要全表扫描查询定位更新记录的位置，所以会在表上加全表读锁。在有索引的情况下，会走索引查询记录，只使用行锁即可。 InnoDB存储引擎中锁的特点InnoDB存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。支持事务，开销大，加锁慢；会出现死锁；锁的粒度小，并发情况下，产生锁等待的概率比较低，所以支持的并发数比较高]]></content>
      <categories>
        <category>MySQL优化</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化（二）--- MySQL库表设计]]></title>
    <url>%2F2017%2F08%2F28%2FMySQL%E5%BA%93%E8%A1%A8%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[MySQL 数据库是被广泛应用的关系型数据库，其体积小、支持多处理器、开源并免费的特性使其在Internet中小型网站中的使用率尤其高。在使用 MySQL 的过程中不规范的SQL编写、非最优的策略选择都可能导致系统性能甚至功能上的缺陷。本文主要对数据库库表设计上的一些规范做出总结，希望能有助于各位同行解决工作中的相关问题。 作为软件工程师对数据库的定位以下对软件工程师在数据库方面的主要工作做出总结： 业务驱动表的设计 如何写出sql，既满足业务，又高效 从数据库角度会分析抓取慢sql，并优化 掌握复杂业务或者大数据表的设计思路 MySQL逻辑架构了解MySQL的第一步，就要先了解MySQL的功能组件和执行流程。如下就是MySQL逻辑架构图： 从架构图分析，MySQL的执行流程： 库表设计MySQL存储引擎的选择在 MySQL 5.1 中，引入了新的插件式存储引擎体系结构，允许将存储引擎加载到正在运新的MySQL服务器中。使用MySQL插件式存储引擎体系结构，允许数据库专业人员或者设计库表的软件开发人员为特定的应用需求选择专门的存储引擎，完全不需要管理任何特殊的应用编码要求，也无需考虑所有的底层实施细节。因此，尽管不同的存储引擎具有不同的能力，应用程序是与之分离的。此外，使用者可以在服务器、数据库和表格三个层级中存储引擎，提供了极大的灵活性。 MySQL 常用的存储引擎包括MYISAM、Innodb和Memory。还有其他种类，这里不做赘述。那么从哪些方面来评判选择搜索引擎呢？ 是否支持事务 :ACID 检索和添加速度 锁机制 缓存 是否支持全文索引 是否支持外键 空间占用 其中各自的特点对比如下： 评判标准 MYISAM Innodb Memory 事物 不支持 支持 锁 全表锁 行级锁 全表锁 缓存 缓存索引，不缓存数据 缓存索引和数据 检索、添加速度 有较高 MYISAM 速度快 全文索引 支持 不支持 外键 不支持 支持 占用空间 较小 MYISAM 的 2.5 和数据量成正比的内存空间，且重启丢失 关注 性能 事物 性能 注：MYISAM : 并发性能差，MySQL 5.5 及以下仅 MYISAM 支持全文索引，不支持事务。在表有读取查询的同时，支持往表中插入新纪录Innodb：，并发能力相对强不支持全文索引（5.6开始支持），支持事务。在innodb存储引擎中应用比较多，支持事务，开销大，加锁慢；会出现死锁；锁的粒度小，并发情况下，产生锁等待的概率比较低，所以支持的并发数比较高 总体来讲，MyISAM适合SELECT密集型的表，而InnoDB适合INSERT和UPDATE密集型的表 基于以上特性，建议绝大部份都设置为innodb引擎，特殊的业务再考虑选用 MYISAM 或 Memory ，如全文索引支持或极高的执行效率等。 范式化设计1NF：原子性，列不可分。每一列都是不可分割的基本数据项2NF：1NF的基础上面，非主属性完全依赖于主关键字3NF：属性不依赖于其它非主属性 , 消除传递依赖 。一个非关键属性不应该依赖一个关键属性 使用范式会有哪些优缺点？ 优点： 避免数据冗余 减少数据的空间 减轻维护数据完整性的麻烦 范式设计的表通常比较小，可以更好的利用内存的优势，提高我们的检索速度 缺点： 经过范式设计出来的表，会很多，越严格来遵循，表就越多 多表关联会慢，可能会导致索引失效 范式越高，对操作性能可能就越低 简单来说就是单表快，多表慢，这里就可以运用到反范式化设计 反范式化设计不符合3NF的设计就是反范式，适当的增加冗余减少表的关联优化查询效率，以空间换时间，在NOSQL中大量运用 运用场景：检索性能要求高对冗余字段很少做更新操作]]></content>
      <categories>
        <category>MySQL优化</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化（一）--- MySQL环境准备]]></title>
    <url>%2F2017%2F08%2F28%2FMySQL%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87%2F</url>
    <content type="text"><![CDATA[最近系统看了下MySQL，决定写系列文章做个总结，为自己做个梳理，也为以后有新的idea或者收获都有个修正和添加记录的地方。先说一点，实际上网上的资料和本文在MySQL官网上都有，英语好的推荐直接阅读官方文档，英语不好先学好英语去阅读官方文档。 开始搭建Linux环境首先，需要linux环境，本文环境 Linux CentOs 3.10.0-514.el7.x86_64 MySQL下载然后，下载MySQL,本文环境 Mysql 5.7.14-1.el7.x86_64 进入官网下载页面，进入如下页面，选择操作系统并点击下载 MySQL安装 root用户登录 在root目录下面新建env目录，上传安装包到env目录，并创建mysql-install.sh脚本 [root@localhost env]# pwd &amp;&amp; ll /root/env 总用量 556004 -rw-r–r–. 1 root root 569344000 8月 25 19:49 mysql-5.7.14-1.el7.x86_64.rpm-bundle.tar -rw-r–r–. 1 root root 465 8月 25 19:48 mysql-install.sh 其中mysql-install.sh 中的命令为（注意替换为自己数据库版本）： 123456789101112#!/bin/bashmkdir mysqltar -xvf mysql-5.7.14-1.el7.x86_64.rpm-bundle.tar -C ./mysqlcd mysql &amp;&amp; yum remove mysql-libs -yrpm -ivh mysql-community-common-5.7.14-1.el7.x86_64.rpmrpm -ivh mysql-community-libs-5.7.14-1.el7.x86_64.rpm rpm -ivh mysql-community-client-5.7.14-1.el7.x86_64.rpm rpm -ivh mysql-community-server-5.7.14-1.el7.x86_64.rpmrpm -ivh mysql-community-devel-5.7.14-1.el7.x86_64.rpmcd ../#cp binary_log_types.h /usr/include/mysql/rm -rf mysql 运行完毕之后目录结构为： [root@localhost env]# pwd &amp;&amp; ll /root/env 总用量 556004 -rw-r–r–. 1 root root 569344000 8月 25 19:49 mysql-5.7.14-1.el7.x86_64.rpm-bundle.tar -rw-r–r–. 1 root root 465 8月 25 19:48 mysql-install.sh 安装好之后，按如下配置： 编辑MySQL配置文件my.cnf vi /etc/my.cnf #编辑文件，找到[mysqld]，在下面添加一行skip-grant-tables 123456789# 可通过以下命令查询my.cnf的位置whereis my.cnf# 或mysqld --verbose --help | grep -C 1 'Default opt'# 编辑配置文件[mysqld]skip-grant-tables :wq! #保存退出,重启MySQL服务 1service mysqld restart 进入MySQL控制台 1mysql -uroot -p #直接按回车，这时不需要输入root密码。 修改root密码 12345flush privileges; # 刷新系统授权表 grant all on *.* to 'root'@'localhost' identified by 'newpassword' with grant option;flush privileges; 取消/etc/my.cnf中的skip-grant-tables,编辑文件，找到[mysqld]，删除skip-grant-tables这一行 1service mysqld restart 忘记密码处理 12345678910111213# 设置密码也可用set password for 'root'@'localhost' = password(''); # 如果哪一天忘记密码，执行以下命令更新密码mysql&gt; UPDATE mysql.user SET authentication_string= password('root') WHERE User = 'root' ; Query OK, 1 row affected, 1 warning (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 1mysql&gt; flush privileges;Query OK, 0 rows affected (0.01 sec)# 并重启服务[root@localhost ~]# systemctl restart mysqld.service 配置文件和数据配置文件默认位置: Linux: /etc/my.cnfWindows: my.ini 在mysql安装的home目录 数据文件位置 命令：show variables like &#39;%datadir%&#39; ; 数据文件格式 InnoDB frm : 存储表结构 ibd：存储数据和索引 MyISAM frm： 存储表结构 MYD：存储数据 MYI：存储索引 字符集设置查看当前字符集 1mysql&gt; show variables like 'character%'; 输出结果如下： 123456789101112 +--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+ 名词解释： character_set_client：客户端请求数据的字符集 character_set_connection：客户机/服务器连接的字符集 character_set_database：默认数据库的字符集，无论默认数据库如何改变，都是这个字符集；如果没有默认数据库，那就使用 character_set_server指定的字符集，这个变量建议由系统自己管理，不要人为定义。 character_set_filesystem：把os上文件名转化成此字符集，即把 character_set_client转换character_set_filesystem， 默认binary是不做任何转换的 character_set_results：结果集，返回给客户端的字符集 character_set_server：数据库服务器的默认字符集 character_set_system：系统字符集，这个值总是utf8，不需要设置。这个字符集用于数据库对象（如表和列）的名字，也用于存储在目录表中的函数的名字。 编辑/etc/my.cnf文件，添加如下字符集设置 1234567891011121314[client]#影响参数：character_set_client，character_set_connection和character_set_results。default-character-set=utf8[mysql]default-character-set=utf8[mysqld]#影响参数：character_set_server 和 character_set_databaseinit_connect='SET collation_connection = utf8_unicode_ci'init_connect='SET NAMES utf8'character-set-server=utf8collation-server=utf8_unicode_ciskip-character-set-client-handshake 修改之后重启数据库生效 1service mysqld restart #重启MySQL服务]]></content>
      <categories>
        <category>MySQL优化</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
</search>
